[{"path":"/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to modsem","title":"Contributing to modsem","text":"Thank considering contributing modsem! welcome contributions help improve package estimating interaction effects structural equation modeling (SEM). ensure smooth collaboration, please follow guidelines .","code":""},{"path":[]},{"path":"/CONTRIBUTING.html","id":"fork-and-clone-the-repository","dir":"","previous_headings":"Getting Started","what":"Fork and Clone the Repository","title":"Contributing to modsem","text":"Fork repository GitHub. Clone fork local machine.","code":"git clone https://github.com/your-username/modsem.git cd modsem"},{"path":"/CONTRIBUTING.html","id":"setting-up-your-development-environment","dir":"","previous_headings":"Getting Started","what":"Setting up your Development Environment","title":"Contributing to modsem","text":"Ensure R installed machine. Install package dependencies. Install modsem package local repository.","code":"install.packages(\"devtools\") devtools::install_deps() devtools::install()"},{"path":[]},{"path":"/CONTRIBUTING.html","id":"creating-a-branch","dir":"","previous_headings":"Making Changes","what":"Creating a Branch","title":"Contributing to modsem","text":"Always create new branch work.","code":"git checkout -b your-branch-name"},{"path":"/CONTRIBUTING.html","id":"making-your-changes","dir":"","previous_headings":"Making Changes","what":"Making Your Changes","title":"Contributing to modsem","text":"Make changes codebase. Ensure changes well-documented. Write tests changes applicable.","code":""},{"path":"/CONTRIBUTING.html","id":"contributing-to-vignettes","dir":"","previous_headings":"Making Changes","what":"Contributing to Vignettes","title":"Contributing to modsem","text":"also encourage contributions vignettes. new use case example, feel free add alter vignettes help demonstrate functionality modsem.","code":""},{"path":"/CONTRIBUTING.html","id":"running-tests","dir":"","previous_headings":"Making Changes","what":"Running Tests","title":"Contributing to modsem","text":"Run tests ensure changes break existing functionality.","code":"devtools::test()"},{"path":"/CONTRIBUTING.html","id":"submitting-your-changes","dir":"","previous_headings":"","what":"Submitting Your Changes","title":"Contributing to modsem","text":"Push changes fork. Open pull request GitHub main branch original repository.","code":"git push origin your-branch-name"},{"path":"/CONTRIBUTING.html","id":"pull-request-guidelines","dir":"","previous_headings":"Submitting Your Changes","what":"Pull Request Guidelines","title":"Contributing to modsem","text":"Provide clear descriptive title pull request. Describe changes made necessary. Reference related issues pull requests. Ensure tests pass merge conflicts.","code":""},{"path":"/CONTRIBUTING.html","id":"reporting-issues","dir":"","previous_headings":"","what":"Reporting Issues","title":"Contributing to modsem","text":"encounter issues suggestions improvements, please open issue GitHub. Provide much detail possible help us understand address issue.","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 modsem authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/customizing.html","id":"specifying-the-measurement-model","dir":"Articles","previous_headings":"","what":"Specifying the Measurement Model","title":"customizing interaction terms","text":"default, modsem() creates possible combinations product indicators. However, another common approach match indicators order. example, let’s say interaction latent variables X Z: X =~ x1 + x2 Z =~ z1 + z2. default, get XZ =~ x1z1 + x1z2 + x2z1 + x2z2. prefer use matching approach, expect XZ =~ x1z1 + x2z2 instead. achieve , can use match = TRUE argument.","code":"m2 <- ' # Outer Model X =~ x1 + x2 Y =~ y1 + y2 Z =~ z1 + z2  # Inner model Y ~ X + Z + X:Z  '  est2 <- modsem(m2, oneInt, match = TRUE) summary(est2) #> modsem (version 1.0.4, approach = dblcent): #> lavaan 0.6-19 ended normally after 41 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        22 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                                11.355 #>   Degrees of freedom                                14 #>   P-value (Chi-square)                           0.658 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   X =~                                                 #>     x1                1.000                            #>     x2                0.819    0.021   38.127    0.000 #>   Y =~                                                 #>     y1                1.000                            #>     y2                0.807    0.010   82.495    0.000 #>   Z =~                                                 #>     z1                1.000                            #>     z2                0.836    0.024   35.392    0.000 #>   XZ =~                                                #>     x1z1              1.000                            #>     x2z2              0.645    0.024   26.904    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   Y ~                                                  #>     X                 0.688    0.029   23.366    0.000 #>     Z                 0.576    0.029   20.173    0.000 #>     XZ                0.706    0.032   22.405    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>  .x1z1 ~~                                              #>    .x2z2              0.000                            #>   X ~~                                                 #>     Z                 0.202    0.025    8.182    0.000 #>     XZ                0.003    0.026    0.119    0.905 #>   Z ~~                                                 #>     XZ                0.042    0.026    1.621    0.105 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .x1                0.179    0.022    8.029    0.000 #>    .x2                0.151    0.015    9.956    0.000 #>    .y1                0.184    0.021    8.577    0.000 #>    .y2                0.136    0.014    9.663    0.000 #>    .z1                0.197    0.025    7.802    0.000 #>    .z2                0.138    0.018    7.831    0.000 #>    .x1z1              0.319    0.035    9.141    0.000 #>    .x2z2              0.244    0.016   15.369    0.000 #>     X                 0.962    0.042   23.120    0.000 #>    .Y                 0.964    0.042   23.110    0.000 #>     Z                 0.987    0.044   22.260    0.000 #>     XZ                1.041    0.054   19.441    0.000"},{"path":"/articles/customizing.html","id":"more-complicated-models","dir":"Articles","previous_headings":"","what":"More Complicated Models","title":"customizing interaction terms","text":"want even control, can use get_pi_syntax() get_pi_data() functions extract modified syntax data modsem(), allowing modify needed. can particularly useful cases want estimate model using feature lavaan isn’t available modsem(). example, syntax ordered multigroup models (now) isn’t flexible modsem() lavaan. can modify auto-generated syntax (along altered dataset) modsem() suit needs.","code":"m3 <- ' # Outer Model X =~ x1 + x2 Y =~ y1 + y2 Z =~ z1 + z2  # Inner model Y ~ X + Z + X:Z  ' syntax <- get_pi_syntax(m3) cat(syntax) #> X =~ x1 #> X =~ x2 #> Y =~ y1 #> Y =~ y2 #> Z =~ z1 #> Z =~ z2 #> Y ~ X #> Y ~ Z #> Y ~ XZ #> XZ =~ 1*x1z1 #> XZ =~ x2z1 #> XZ =~ x1z2 #> XZ =~ x2z2 #> x1z1 ~~ 0*x2z2 #> x1z2 ~~ 0*x2z1 #> x1z1 ~~ x1z2 #> x1z1 ~~ x2z1 #> x1z2 ~~ x2z2 #> x2z1 ~~ x2z2 data <- get_pi_data(m3, oneInt) head(data) #>           x1         x2         y1         y2         z1         z2       x1z1 #> 1  2.4345722  1.3578655  1.4526897  0.9560888  0.8184825 1.60708140 -0.4823019 #> 2  0.2472734  0.2723201  0.5496756  0.7115311  3.6649148 2.60983102 -2.2680403 #> 3 -1.3647759 -0.5628205 -0.9835467 -0.6697747  1.7249386 2.10981827 -1.9137416 #> 4  3.0432836  2.2153763  6.4641465  4.7805981  2.5697116 3.26335379  2.9385205 #> 5  2.8148841  2.7029616  2.2860280  2.1457643  0.3467850 0.07164577 -1.4009548 #> 6 -0.5453450 -0.7530642  1.1294876  1.1998472 -0.2362958 0.60252657  1.7465860 #>         x2z1       x1z2       x2z2 #> 1 -0.1884837  0.3929380 -0.0730934 #> 2 -2.6637694 -1.2630544 -1.4547433 #> 3 -1.4299711 -2.3329864 -1.7383407 #> 4  1.3971422  3.9837389  1.9273102 #> 5 -1.1495704 -2.2058995 -1.8169042 #> 6  2.2950753  0.7717365  1.0568143"},{"path":"/articles/interaction_two_etas.html","id":"the-problem","dir":"Articles","previous_headings":"","what":"The Problem","title":"interaction effects between endogenous variables","text":"Interaction effects two endogenous (.e., dependent) variables work expect product indicator methods (\"dblcent\", \"rca\", \"ca\", \"uca\"). However, lms qml approaches, straightforward. lms qml approaches can (default) handle interaction effects endogenous exogenous (.e., independent) variables, natively support interaction effects two endogenous variables. interaction effect exists two endogenous variables, equations easily written “reduced” form, meaning normal estimation procedures won’t work.","code":""},{"path":"/articles/interaction_two_etas.html","id":"the-solution","dir":"Articles","previous_headings":"","what":"The Solution","title":"interaction effects between endogenous variables","text":"Despite limitations, workaround lms qml approaches. Essentially, model can split two parts: one linear one non-linear. can replace covariance matrix used estimation non-linear model model-implied covariance matrix linear model. allows treat endogenous variable exogenous—provided can expressed linear model.","code":""},{"path":"/articles/interaction_two_etas.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"interaction effects between endogenous variables","text":"Let’s consider theory planned behavior (TPB), wish estimate quadratic effect INT BEH (INT:INT). can use following model: Since INT endogenous variable, quadratic term (.e., interaction effect ) involve two endogenous variables. result, normally able estimate model using lms qml approaches. However, can split model two parts: one linear one non-linear. INT endogenous variable, can expressed linear model since affected interaction terms: can remove part original model, giving us: Now, can estimate non-linear model since INT treated exogenous variable. However, incorporate structural model INT. address , can instruct modsem replace covariance matrix (phi) (INT, PBC, ATT, SN) model-implied covariance matrix linear model estimating models simultaneously. achieve , use cov.syntax argument modsem:","code":"tpb <- '  # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC    BEH ~ INT:INT ' tpb_linear <- 'INT ~ PBC + ATT + SN' tpb_nonlinear <- '  # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   BEH ~ INT + PBC    BEH ~ INT:INT ' est_lms <- modsem(tpb_nonlinear, data = TPB, cov.syntax = tpb_linear,                    method = \"lms\") #> Warning: It is recommended that you have at least 48 nodes for interaction #> effects between endogenous variables in the lms approach 'nodes = 24' summary(est_lms) #>  #> modsem (version 1.0.4): #>   Estimator                                         LMS #>   Optimization method                         EM-NLMINB #>   Number of observations                           2000 #>   Number of iterations                               82 #>   Loglikelihood                               -23780.84 #>   Akaike (AIC)                                 47669.69 #>   Bayesian (BIC)                               47972.13 #>   #> Numerical Integration: #>   Points of integration (per dim)                    24 #>   Dimensions                                          1 #>   Total points of integration                        24 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -26393 #>   Akaike (AIC)                                 52892.45 #>   Bayesian (BIC)                               53189.29 #>   Chi-square                                      66.27 #>   Degrees of Freedom (Chi-square)                    82 #>   P-value (Chi-square)                            0.897 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                          2612.38 #>   Difference test (D)                           5224.76 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   BEH                                             0.235 #>   INT                                             0.364 #> R-Squared Null-Model (H0): #>   BEH                                             0.210 #>   INT                                             0.367 #> R-Squared Change: #>   BEH                                             0.025 #>   INT                                            -0.002 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  expected #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   INT =~  #>     int1             1.000                              #>     int2             0.915      0.015    59.12    0.000 #>     int3             0.807      0.015    55.24    0.000 #>   ATT =~  #>     att1             1.000                              #>     att2             0.878      0.012    71.35    0.000 #>     att3             0.789      0.012    66.42    0.000 #>     att4             0.695      0.012    60.40    0.000 #>     att5             0.887      0.012    71.52    0.000 #>   SN =~  #>     sn1              1.000                              #>     sn2              0.888      0.017    52.50    0.000 #>   PBC =~  #>     pbc1             1.000                              #>     pbc2             0.913      0.013    69.06    0.000 #>     pbc3             0.801      0.012    66.44    0.000 #>   BEH =~  #>     b1               1.000                              #>     b2               0.959      0.030    32.02    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   BEH ~  #>     INT              0.196      0.025     7.73    0.000 #>     PBC              0.238      0.022    10.64    0.000 #>     INT:INT          0.129      0.017     7.42    0.000 #>   INT ~  #>     PBC              0.219      0.029     7.54    0.000 #>     ATT              0.210      0.026     8.23    0.000 #>     SN               0.171      0.027     6.35    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     int1             1.006      0.022    46.74    0.000 #>     int2             1.006      0.020    50.40    0.000 #>     int3             0.999      0.018    54.45    0.000 #>     att1             1.010      0.025    40.53    0.000 #>     att2             1.003      0.022    45.18    0.000 #>     att3             1.013      0.020    49.78    0.000 #>     att4             0.996      0.019    53.61    0.000 #>     att5             0.989      0.022    44.03    0.000 #>     sn1              1.002      0.025    39.86    0.000 #>     sn2              1.007      0.023    44.70    0.000 #>     pbc1             0.994      0.025    40.54    0.000 #>     pbc2             0.981      0.023    43.00    0.000 #>     pbc3             0.988      0.020    48.47    0.000 #>     b1               0.996      0.024    41.66    0.000 #>     b2               1.015      0.022    45.20    0.000 #>     BEH              0.000                              #>     INT              0.000                              #>     ATT              0.000                              #>     SN               0.000                              #>     PBC              0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC ~~  #>     ATT              0.673      0.028    23.77    0.000 #>     SN               0.673      0.029    22.98    0.000 #>   ATT ~~  #>     SN               0.624      0.029    21.64    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     int1             0.161      0.009    18.34    0.000 #>     int2             0.161      0.008    20.89    0.000 #>     int3             0.170      0.007    23.47    0.000 #>     att1             0.167      0.007    23.28    0.000 #>     att2             0.150      0.006    24.81    0.000 #>     att3             0.160      0.006    26.51    0.000 #>     att4             0.162      0.006    27.45    0.000 #>     att5             0.159      0.006    24.85    0.000 #>     sn1              0.178      0.015    12.02    0.000 #>     sn2              0.157      0.012    13.24    0.000 #>     pbc1             0.145      0.008    18.31    0.000 #>     pbc2             0.160      0.007    21.75    0.000 #>     pbc3             0.154      0.007    23.70    0.000 #>     b1               0.185      0.019     9.76    0.000 #>     b2               0.136      0.017     7.97    0.000 #>     BEH              0.475      0.023    20.47    0.000 #>     PBC              0.956      0.035    27.32    0.000 #>     ATT              0.993      0.037    27.12    0.000 #>     SN               0.983      0.039    24.91    0.000 #>     INT              0.481      0.019    24.99    0.000  est_qml <- modsem(tpb_nonlinear, data = TPB, cov.syntax = tpb_linear,                    method = \"qml\") summary(est_qml) #>  #> modsem (version 1.0.4): #>   Estimator                                         QML #>   Optimization method                            NLMINB #>   Number of observations                           2000 #>   Number of iterations                               76 #>   Loglikelihood                               -26360.52 #>   Akaike (AIC)                                 52829.04 #>   Bayesian (BIC)                               53131.49 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -26393 #>   Akaike (AIC)                                 52892.45 #>   Bayesian (BIC)                               53189.29 #>   Chi-square                                      66.27 #>   Degrees of Freedom (Chi-square)                    82 #>   P-value (Chi-square)                            0.897 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                            32.70 #>   Difference test (D)                             65.41 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   BEH                                             0.239 #>   INT                                             0.370 #> R-Squared Null-Model (H0): #>   BEH                                             0.210 #>   INT                                             0.367 #> R-Squared Change: #>   BEH                                             0.029 #>   INT                                             0.003 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   INT =~  #>     int1             1.000                              #>     int2             0.914      0.015    59.04    0.000 #>     int3             0.807      0.015    55.65    0.000 #>   ATT =~  #>     att1             1.000                              #>     att2             0.878      0.012    71.56    0.000 #>     att3             0.789      0.012    66.37    0.000 #>     att4             0.695      0.011    61.00    0.000 #>     att5             0.887      0.013    70.85    0.000 #>   SN =~  #>     sn1              1.000                              #>     sn2              0.888      0.017    52.62    0.000 #>   PBC =~  #>     pbc1             1.000                              #>     pbc2             0.913      0.013    69.38    0.000 #>     pbc3             0.801      0.012    66.08    0.000 #>   BEH =~  #>     b1               1.000                              #>     b2               0.960      0.032    29.91    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   BEH ~  #>     INT              0.197      0.025     7.76    0.000 #>     PBC              0.239      0.023    10.59    0.000 #>     INT:INT          0.128      0.016     7.88    0.000 #>   INT ~  #>     PBC              0.222      0.030     7.51    0.000 #>     ATT              0.213      0.026     8.17    0.000 #>     SN               0.175      0.028     6.33    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     int1             1.014      0.022    46.96    0.000 #>     int2             1.012      0.020    50.41    0.000 #>     int3             1.005      0.018    54.80    0.000 #>     att1             1.014      0.024    42.01    0.000 #>     att2             1.007      0.021    46.97    0.000 #>     att3             1.016      0.020    51.45    0.000 #>     att4             0.999      0.018    55.65    0.000 #>     att5             0.992      0.022    45.67    0.000 #>     sn1              1.006      0.024    41.66    0.000 #>     sn2              1.010      0.022    46.71    0.000 #>     pbc1             0.998      0.024    42.41    0.000 #>     pbc2             0.985      0.022    44.93    0.000 #>     pbc3             0.991      0.020    50.45    0.000 #>     b1               0.999      0.023    42.64    0.000 #>     b2               1.017      0.022    46.25    0.000 #>     BEH              0.000                              #>     INT              0.000                              #>     ATT              0.000                              #>     SN               0.000                              #>     PBC              0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC ~~  #>     ATT              0.678      0.029    23.45    0.000 #>     SN               0.678      0.029    23.08    0.000 #>   ATT ~~  #>     SN               0.629      0.029    21.70    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     int1             0.158      0.009    18.22    0.000 #>     int2             0.160      0.008    20.38    0.000 #>     int3             0.168      0.007    23.63    0.000 #>     att1             0.167      0.007    23.53    0.000 #>     att2             0.150      0.006    24.71    0.000 #>     att3             0.160      0.006    26.38    0.000 #>     att4             0.162      0.006    27.64    0.000 #>     att5             0.159      0.006    24.93    0.000 #>     sn1              0.178      0.015    12.09    0.000 #>     sn2              0.157      0.012    13.26    0.000 #>     pbc1             0.145      0.008    18.44    0.000 #>     pbc2             0.160      0.007    21.42    0.000 #>     pbc3             0.154      0.006    23.80    0.000 #>     b1               0.185      0.020     9.42    0.000 #>     b2               0.135      0.018     7.60    0.000 #>     BEH              0.475      0.024    19.74    0.000 #>     PBC              0.962      0.036    27.04    0.000 #>     ATT              0.998      0.037    26.93    0.000 #>     SN               0.988      0.039    25.23    0.000 #>     INT              0.488      0.020    24.59    0.000"},{"path":"/articles/lms_qml.html","id":"the-latent-moderated-structural-equations-lms-and-the-quasi-maximum-likelihood-qml-approach","dir":"Articles","previous_headings":"","what":"The Latent Moderated Structural Equations (LMS) and the Quasi Maximum Likelihood (QML) Approach","title":"LMS and QML approaches","text":"LMS QML approaches work models, interaction effects endogenous variables can tricky estimate (see vignette). approaches, particularly LMS approach, computationally intensive partially implemented C++ (using Rcpp RcppArmadillo). Additionally, starting parameters estimated using double-centering approach, means observed variables used generate good starting parameters faster convergence. want monitor progress estimation process, can use verbose = TRUE.","code":""},{"path":"/articles/lms_qml.html","id":"a-simple-example","dir":"Articles","previous_headings":"The Latent Moderated Structural Equations (LMS) and the Quasi Maximum Likelihood (QML) Approach","what":"A Simple Example","title":"LMS and QML approaches","text":"example LMS approach simple model. default, summary() function calculates fit measures compared null model (.e., model without interaction term). example using QML approach:","code":"library(modsem) m1 <- ' # Outer Model   X =~ x1   X =~ x2 + x3   Z =~ z1 + z2 + z3   Y =~ y1 + y2 + y3  # Inner Model   Y ~ X + Z   Y ~ X:Z '  lms1 <- modsem(m1, oneInt, method = \"lms\") summary(lms1, standardized = TRUE) # Standardized estimates #>  #> modsem (version 1.0.4): #>   Estimator                                         LMS #>   Optimization method                         EM-NLMINB #>   Number of observations                           2000 #>   Number of iterations                               92 #>   Loglikelihood                               -14687.85 #>   Akaike (AIC)                                 29437.71 #>   Bayesian (BIC)                               29611.34 #>   #> Numerical Integration: #>   Points of integration (per dim)                    24 #>   Dimensions                                          1 #>   Total points of integration                        24 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -17832 #>   Akaike (AIC)                                 35723.75 #>   Bayesian (BIC)                               35891.78 #>   Chi-square                                      17.52 #>   Degrees of Freedom (Chi-square)                    24 #>   P-value (Chi-square)                            0.826 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                          3144.02 #>   Difference test (D)                           6288.04 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   Y                                               0.596 #> R-Squared Null-Model (H0): #>   Y                                               0.395 #> R-Squared Change: #>   Y                                               0.201 #>  #> Parameter Estimates: #>   Coefficients                             standardized #>   Information                                  expected #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X =~  #>     x1               0.926                              #>     x2               0.891      0.014    65.27    0.000 #>     x3               0.912      0.013    68.77    0.000 #>   Z =~  #>     z1               0.927                              #>     z2               0.898      0.014    65.55    0.000 #>     z3               0.913      0.013    69.05    0.000 #>   Y =~  #>     y1               0.969                              #>     y2               0.954      0.009   106.30    0.000 #>     y3               0.961      0.009   112.47    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   Y ~  #>     X                0.427      0.020    20.89    0.000 #>     Z                0.370      0.019    19.53    0.000 #>     X:Z              0.454      0.017    26.72    0.000 #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X ~~  #>     Z                0.199      0.028     7.23    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               0.142      0.007    19.63    0.000 #>     x2               0.206      0.009    24.10    0.000 #>     x3               0.169      0.008    21.53    0.000 #>     z1               0.141      0.008    18.74    0.000 #>     z2               0.193      0.009    22.64    0.000 #>     z3               0.167      0.008    20.78    0.000 #>     y1               0.061      0.003    17.98    0.000 #>     y2               0.090      0.004    22.74    0.000 #>     y3               0.077      0.004    20.73    0.000 #>     X                1.000      0.032    30.84    0.000 #>     Z                1.000      0.038    26.66    0.000 #>     Y                0.404      0.015    27.12    0.000 qml1 <- modsem(m1, oneInt, method = \"qml\") summary(qml1) #>  #> modsem (version 1.0.4): #>   Estimator                                         QML #>   Optimization method                            NLMINB #>   Number of observations                           2000 #>   Number of iterations                              111 #>   Loglikelihood                               -17496.22 #>   Akaike (AIC)                                 35054.43 #>   Bayesian (BIC)                               35228.06 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -17832 #>   Akaike (AIC)                                 35723.75 #>   Bayesian (BIC)                               35891.78 #>   Chi-square                                      17.52 #>   Degrees of Freedom (Chi-square)                    24 #>   P-value (Chi-square)                            0.826 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                           335.66 #>   Difference test (D)                            671.32 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   Y                                               0.607 #> R-Squared Null-Model (H0): #>   Y                                               0.395 #> R-Squared Change: #>   Y                                               0.211 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X =~  #>     x1               1.000                              #>     x2               0.803      0.013    63.96    0.000 #>     x3               0.914      0.013    67.80    0.000 #>   Z =~  #>     z1               1.000                              #>     z2               0.810      0.012    65.12    0.000 #>     z3               0.881      0.013    67.62    0.000 #>   Y =~  #>     y1               1.000                              #>     y2               0.798      0.007   107.57    0.000 #>     y3               0.899      0.008   112.55    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   Y ~  #>     X                0.674      0.032    20.94    0.000 #>     Z                0.566      0.030    18.96    0.000 #>     X:Z              0.712      0.028    25.45    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               1.023      0.024    42.89    0.000 #>     x2               1.215      0.020    60.99    0.000 #>     x3               0.919      0.022    41.48    0.000 #>     z1               1.012      0.024    41.57    0.000 #>     z2               1.206      0.020    59.27    0.000 #>     z3               0.916      0.022    42.06    0.000 #>     y1               1.038      0.033    31.45    0.000 #>     y2               1.221      0.027    45.49    0.000 #>     y3               0.955      0.030    31.86    0.000 #>     Y                0.000                              #>     X                0.000                              #>     Z                0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X ~~  #>     Z                0.200      0.024     8.24    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               0.158      0.009    18.14    0.000 #>     x2               0.162      0.007    23.19    0.000 #>     x3               0.165      0.008    20.82    0.000 #>     z1               0.166      0.009    18.34    0.000 #>     z2               0.159      0.007    22.62    0.000 #>     z3               0.158      0.008    20.71    0.000 #>     y1               0.159      0.009    17.98    0.000 #>     y2               0.154      0.007    22.67    0.000 #>     y3               0.164      0.008    20.71    0.000 #>     X                0.983      0.036    26.99    0.000 #>     Z                1.019      0.038    26.95    0.000 #>     Y                0.943      0.038    24.87    0.000"},{"path":"/articles/lms_qml.html","id":"a-more-complicated-example","dir":"Articles","previous_headings":"The Latent Moderated Structural Equations (LMS) and the Quasi Maximum Likelihood (QML) Approach","what":"A More Complicated Example","title":"LMS and QML approaches","text":"example complex model based theory planned behavior (TPB), includes two endogenous variables interaction endogenous exogenous variable. estimating complex models LMS approach, recommended increase number nodes used numerical integration. default, number nodes set 16, can increased using nodes argument. nodes argument effect QML approach. interaction effect endogenous exogenous variable, recommended use least 32 nodes LMS approach. can also obtain robust standard errors setting robust.se = TRUE modsem() function. Note: want LMS approach produce results similar possible Mplus, increase number nodes (e.g., nodes = 100).","code":"# ATT = Attitude # PBC = Perceived Behavioral Control # INT = Intention # SN = Subjective Norms # BEH = Behavior tpb <- '  # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC    BEH ~ INT:PBC   '  lms2 <- modsem(tpb, TPB, method = \"lms\", nodes = 32) summary(lms2) #>  #> modsem (version 1.0.4): #>   Estimator                                         LMS #>   Optimization method                         EM-NLMINB #>   Number of observations                           2000 #>   Number of iterations                               70 #>   Loglikelihood                               -23439.02 #>   Akaike (AIC)                                 46986.04 #>   Bayesian (BIC)                               47288.49 #>   #> Numerical Integration: #>   Points of integration (per dim)                    32 #>   Dimensions                                          1 #>   Total points of integration                        32 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -26393 #>   Akaike (AIC)                                 52892.45 #>   Bayesian (BIC)                               53189.29 #>   Chi-square                                      66.27 #>   Degrees of Freedom (Chi-square)                    82 #>   P-value (Chi-square)                            0.897 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                          2954.20 #>   Difference test (D)                           5908.41 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   INT                                             0.364 #>   BEH                                             0.259 #> R-Squared Null-Model (H0): #>   INT                                             0.367 #>   BEH                                             0.210 #> R-Squared Change: #>   INT                                            -0.003 #>   BEH                                             0.049 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  expected #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC =~  #>     pbc1             1.000                              #>     pbc2             0.914      0.013    69.02    0.000 #>     pbc3             0.802      0.012    65.40    0.000 #>   ATT =~  #>     att1             1.000                              #>     att2             0.878      0.012    70.82    0.000 #>     att3             0.789      0.012    65.78    0.000 #>     att4             0.695      0.011    61.10    0.000 #>     att5             0.887      0.013    70.28    0.000 #>   SN =~  #>     sn1              1.000                              #>     sn2              0.889      0.017    52.14    0.000 #>   INT =~  #>     int1             1.000                              #>     int2             0.913      0.015    58.98    0.000 #>     int3             0.807      0.014    55.84    0.000 #>   BEH =~  #>     b1               1.000                              #>     b2               0.959      0.030    31.77    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   INT ~  #>     PBC              0.218      0.030     7.32    0.000 #>     ATT              0.214      0.026     8.18    0.000 #>     SN               0.176      0.027     6.42    0.000 #>   BEH ~  #>     PBC              0.233      0.023    10.24    0.000 #>     INT              0.188      0.025     7.59    0.000 #>     PBC:INT          0.205      0.019    11.04    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     pbc1             0.990      0.023    43.17    0.000 #>     pbc2             0.978      0.021    45.79    0.000 #>     pbc3             0.985      0.019    51.31    0.000 #>     att1             1.009      0.024    41.46    0.000 #>     att2             1.002      0.022    46.30    0.000 #>     att3             1.012      0.020    51.24    0.000 #>     att4             0.995      0.018    55.01    0.000 #>     att5             0.988      0.022    44.94    0.000 #>     sn1              1.001      0.024    40.93    0.000 #>     sn2              1.006      0.022    46.05    0.000 #>     int1             1.010      0.022    44.93    0.000 #>     int2             1.009      0.021    48.14    0.000 #>     int3             1.002      0.019    52.81    0.000 #>     b1               0.999      0.022    45.57    0.000 #>     b2               1.017      0.021    49.38    0.000 #>     INT              0.000                              #>     BEH              0.000                              #>     PBC              0.000                              #>     ATT              0.000                              #>     SN               0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC ~~  #>     ATT              0.668      0.028    23.93    0.000 #>     SN               0.668      0.029    23.44    0.000 #>   ATT ~~  #>     SN               0.623      0.029    21.63    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     pbc1             0.148      0.008    18.92    0.000 #>     pbc2             0.159      0.007    21.70    0.000 #>     pbc3             0.155      0.007    23.70    0.000 #>     att1             0.167      0.007    23.64    0.000 #>     att2             0.150      0.006    24.73    0.000 #>     att3             0.159      0.006    26.68    0.000 #>     att4             0.162      0.006    27.71    0.000 #>     att5             0.159      0.006    25.12    0.000 #>     sn1              0.178      0.015    11.99    0.000 #>     sn2              0.156      0.012    13.23    0.000 #>     int1             0.157      0.009    18.36    0.000 #>     int2             0.160      0.008    20.57    0.000 #>     int3             0.168      0.007    24.33    0.000 #>     b1               0.185      0.019     9.96    0.000 #>     b2               0.136      0.017     8.13    0.000 #>     PBC              0.947      0.034    28.02    0.000 #>     ATT              0.992      0.037    27.11    0.000 #>     SN               0.981      0.039    24.99    0.000 #>     INT              0.491      0.020    25.00    0.000 #>     BEH              0.456      0.023    20.13    0.000  qml2 <- modsem(tpb, TPB, method = \"qml\") summary(qml2, standardized = TRUE) # Standardized estimates #>  #> modsem (version 1.0.4): #>   Estimator                                         QML #>   Optimization method                            NLMINB #>   Number of observations                           2000 #>   Number of iterations                               73 #>   Loglikelihood                               -26326.25 #>   Akaike (AIC)                                  52760.5 #>   Bayesian (BIC)                               53062.95 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -26393 #>   Akaike (AIC)                                 52892.45 #>   Bayesian (BIC)                               53189.29 #>   Chi-square                                      66.27 #>   Degrees of Freedom (Chi-square)                    82 #>   P-value (Chi-square)                            0.897 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                            66.97 #>   Difference test (D)                            133.95 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   INT                                             0.366 #>   BEH                                             0.263 #> R-Squared Null-Model (H0): #>   INT                                             0.367 #>   BEH                                             0.210 #> R-Squared Change: #>   INT                                             0.000 #>   BEH                                             0.053 #>  #> Parameter Estimates: #>   Coefficients                             standardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC =~  #>     pbc1             0.933                              #>     pbc2             0.913      0.013    69.47    0.000 #>     pbc3             0.894      0.014    66.10    0.000 #>   ATT =~  #>     att1             0.925                              #>     att2             0.915      0.013    71.56    0.000 #>     att3             0.892      0.013    66.38    0.000 #>     att4             0.865      0.014    61.00    0.000 #>     att5             0.912      0.013    70.85    0.000 #>   SN =~  #>     sn1              0.921                              #>     sn2              0.913      0.017    52.61    0.000 #>   INT =~  #>     int1             0.912                              #>     int2             0.895      0.015    59.05    0.000 #>     int3             0.866      0.016    55.73    0.000 #>   BEH =~  #>     b1               0.877                              #>     b2               0.900      0.028    31.71    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   INT ~  #>     PBC              0.243      0.033     7.35    0.000 #>     ATT              0.242      0.030     8.16    0.000 #>     SN               0.199      0.031     6.37    0.000 #>   BEH ~  #>     PBC              0.289      0.028    10.37    0.000 #>     INT              0.212      0.028     7.69    0.000 #>     PBC:INT          0.227      0.020    11.32    0.000 #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC ~~  #>     ATT              0.692      0.030    23.45    0.000 #>     SN               0.695      0.030    23.08    0.000 #>   ATT ~~  #>     SN               0.634      0.029    21.70    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     pbc1             0.130      0.007    18.39    0.000 #>     pbc2             0.166      0.008    21.43    0.000 #>     pbc3             0.201      0.008    23.89    0.000 #>     att1             0.144      0.006    23.53    0.000 #>     att2             0.164      0.007    24.71    0.000 #>     att3             0.204      0.008    26.38    0.000 #>     att4             0.252      0.009    27.65    0.000 #>     att5             0.168      0.007    24.93    0.000 #>     sn1              0.153      0.013    12.09    0.000 #>     sn2              0.167      0.013    13.26    0.000 #>     int1             0.168      0.009    18.11    0.000 #>     int2             0.199      0.010    20.41    0.000 #>     int3             0.249      0.011    23.55    0.000 #>     b1               0.231      0.023    10.12    0.000 #>     b2               0.191      0.024     8.10    0.000 #>     PBC              1.000      0.037    27.07    0.000 #>     ATT              1.000      0.037    26.93    0.000 #>     SN               1.000      0.040    25.22    0.000 #>     INT              0.634      0.026    24.64    0.000 #>     BEH              0.737      0.037    20.17    0.000"},{"path":"/articles/methods.html","id":"product-indicator-pi-approaches","dir":"Articles","previous_headings":"","what":"Product Indicator (PI) Approaches:","title":"methods","text":"Note constraints can become quite complicated complex models, particularly interaction including enodgenous variables. method can therefore quite slow. \"uca\" = unconstrained approach (Marsh, 2004) \"rca\" = residual centering approach (Little et al., 2006) default \"pind\" = basic product indicator approach (recommended)","code":""},{"path":"/articles/methods.html","id":"distribution-analytic-da-approaches","dir":"Articles","previous_headings":"","what":"Distribution Analytic (DA) Approaches","title":"methods","text":"\"lms\" = Latent Moderated Structural equations (LMS) approach, see vignette \"qml\" = Quasi Maximum Likelihood (QML) approach, see vignette estimates model Mplus, installed","code":"m1 <- ' # Outer Model X =~ x1 + x2 + x3 Y =~ y1 + y2 + y3 Z =~ z1 + z2 + z3  # Inner model Y ~ X + Z + X:Z  '  # Product Indicator Approaches modsem(m1, data = oneInt, method = \"ca\") modsem(m1, data = oneInt, method = \"uca\") modsem(m1, data = oneInt, method = \"rca\") modsem(m1, data = oneInt, method = \"dblcent\")  # Distribution Analytic Approaches modsem(m1, data = oneInt, method = \"mplus\") modsem(m1, data = oneInt, method = \"lms\") modsem(m1, data = oneInt, method = \"qml\")"},{"path":"/articles/modsem.html","id":"the-basic-syntax","dir":"Articles","previous_headings":"","what":"The Basic Syntax","title":"modsem","text":"modsem introduces new feature lavaan syntax—semicolon operator (:). semicolon operator works way lm() function. specify interaction effect two variables, join Var1:Var2. Models can estimated using one product indicator approaches (\"ca\", \"rca\", \"dblcent\", \"pind\") using latent moderated structural equations approach (\"lms\") quasi maximum likelihood approach (\"qml\"). product indicator approaches estimated via lavaan, lms qml approaches estimated via modsem .","code":""},{"path":"/articles/modsem.html","id":"a-simple-example","dir":"Articles","previous_headings":"The Basic Syntax","what":"A Simple Example","title":"modsem","text":"simple example specify interaction effect two latent variables lavaan. default, model estimated using \"dblcent\" method. want use another method, can change using method argument.","code":"m1 <- '   # Outer Model   X =~ x1 + x2 + x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3      # Inner Model   Y ~ X + Z + X:Z  '  est1 <- modsem(m1, oneInt) summary(est1) #> modsem (version 1.0.4, approach = dblcent): #> lavaan 0.6-19 ended normally after 159 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        60 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                               122.924 #>   Degrees of freedom                               111 #>   P-value (Chi-square)                           0.207 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   X =~                                                 #>     x1                1.000                            #>     x2                0.804    0.013   63.612    0.000 #>     x3                0.916    0.014   67.144    0.000 #>   Y =~                                                 #>     y1                1.000                            #>     y2                0.798    0.007  107.428    0.000 #>     y3                0.899    0.008  112.453    0.000 #>   Z =~                                                 #>     z1                1.000                            #>     z2                0.812    0.013   64.763    0.000 #>     z3                0.882    0.013   67.014    0.000 #>   XZ =~                                                #>     x1z1              1.000                            #>     x2z1              0.805    0.013   60.636    0.000 #>     x3z1              0.877    0.014   62.680    0.000 #>     x1z2              0.793    0.013   59.343    0.000 #>     x2z2              0.646    0.015   43.672    0.000 #>     x3z2              0.706    0.016   44.292    0.000 #>     x1z3              0.887    0.014   63.700    0.000 #>     x2z3              0.716    0.016   45.645    0.000 #>     x3z3              0.781    0.017   45.339    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   Y ~                                                  #>     X                 0.675    0.027   25.379    0.000 #>     Z                 0.561    0.026   21.606    0.000 #>     XZ                0.702    0.027   26.360    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>  .x1z1 ~~                                              #>    .x2z2              0.000                            #>    .x2z3              0.000                            #>    .x3z2              0.000                            #>    .x3z3              0.000                            #>  .x2z1 ~~                                              #>    .x1z2              0.000                            #>  .x1z2 ~~                                              #>    .x2z3              0.000                            #>  .x3z1 ~~                                              #>    .x1z2              0.000                            #>  .x1z2 ~~                                              #>    .x3z3              0.000                            #>  .x2z1 ~~                                              #>    .x1z3              0.000                            #>  .x2z2 ~~                                              #>    .x1z3              0.000                            #>  .x3z1 ~~                                              #>    .x1z3              0.000                            #>  .x3z2 ~~                                              #>    .x1z3              0.000                            #>  .x2z1 ~~                                              #>    .x3z2              0.000                            #>    .x3z3              0.000                            #>  .x3z1 ~~                                              #>    .x2z2              0.000                            #>  .x2z2 ~~                                              #>    .x3z3              0.000                            #>  .x3z1 ~~                                              #>    .x2z3              0.000                            #>  .x3z2 ~~                                              #>    .x2z3              0.000                            #>  .x1z1 ~~                                              #>    .x1z2              0.115    0.008   14.802    0.000 #>    .x1z3              0.114    0.008   13.947    0.000 #>    .x2z1              0.125    0.008   16.095    0.000 #>    .x3z1              0.140    0.009   16.135    0.000 #>  .x1z2 ~~                                              #>    .x1z3              0.103    0.007   14.675    0.000 #>    .x2z2              0.128    0.006   20.850    0.000 #>    .x3z2              0.146    0.007   21.243    0.000 #>  .x1z3 ~~                                              #>    .x2z3              0.116    0.007   17.818    0.000 #>    .x3z3              0.135    0.007   18.335    0.000 #>  .x2z1 ~~                                              #>    .x2z2              0.135    0.006   20.905    0.000 #>    .x2z3              0.145    0.007   21.145    0.000 #>    .x3z1              0.114    0.007   16.058    0.000 #>  .x2z2 ~~                                              #>    .x2z3              0.117    0.006   20.419    0.000 #>    .x3z2              0.116    0.006   20.586    0.000 #>  .x2z3 ~~                                              #>    .x3z3              0.109    0.006   18.059    0.000 #>  .x3z1 ~~                                              #>    .x3z2              0.138    0.007   19.331    0.000 #>    .x3z3              0.158    0.008   20.269    0.000 #>  .x3z2 ~~                                              #>    .x3z3              0.131    0.007   19.958    0.000 #>   X ~~                                                 #>     Z                 0.201    0.024    8.271    0.000 #>     XZ                0.016    0.025    0.628    0.530 #>   Z ~~                                                 #>     XZ                0.062    0.025    2.449    0.014 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .x1                0.160    0.009   17.871    0.000 #>    .x2                0.162    0.007   22.969    0.000 #>    .x3                0.163    0.008   20.161    0.000 #>    .y1                0.159    0.009   17.896    0.000 #>    .y2                0.154    0.007   22.640    0.000 #>    .y3                0.164    0.008   20.698    0.000 #>    .z1                0.168    0.009   18.143    0.000 #>    .z2                0.158    0.007   22.264    0.000 #>    .z3                0.158    0.008   20.389    0.000 #>    .x1z1              0.311    0.014   22.227    0.000 #>    .x2z1              0.292    0.011   27.287    0.000 #>    .x3z1              0.327    0.012   26.275    0.000 #>    .x1z2              0.290    0.011   26.910    0.000 #>    .x2z2              0.239    0.008   29.770    0.000 #>    .x3z2              0.270    0.009   29.117    0.000 #>    .x1z3              0.272    0.012   23.586    0.000 #>    .x2z3              0.245    0.009   27.979    0.000 #>    .x3z3              0.297    0.011   28.154    0.000 #>     X                 0.981    0.036   26.895    0.000 #>    .Y                 0.990    0.038   25.926    0.000 #>     Z                 1.016    0.038   26.856    0.000 #>     XZ                1.045    0.044   24.004    0.000 est1 <- modsem(m1, oneInt, method = \"lms\") summary(est1) #>  #> modsem (version 1.0.4): #>   Estimator                                         LMS #>   Optimization method                         EM-NLMINB #>   Number of observations                           2000 #>   Number of iterations                               92 #>   Loglikelihood                               -14687.85 #>   Akaike (AIC)                                 29437.71 #>   Bayesian (BIC)                               29611.34 #>   #> Numerical Integration: #>   Points of integration (per dim)                    24 #>   Dimensions                                          1 #>   Total points of integration                        24 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -17832 #>   Akaike (AIC)                                 35723.75 #>   Bayesian (BIC)                               35891.78 #>   Chi-square                                      17.52 #>   Degrees of Freedom (Chi-square)                    24 #>   P-value (Chi-square)                            0.826 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                          3144.02 #>   Difference test (D)                           6288.04 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   Y                                               0.596 #> R-Squared Null-Model (H0): #>   Y                                               0.395 #> R-Squared Change: #>   Y                                               0.201 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  expected #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X =~  #>     x1               1.000                              #>     x2               0.804      0.012    65.27    0.000 #>     x3               0.915      0.013    68.77    0.000 #>   Z =~  #>     z1               1.000                              #>     z2               0.810      0.012    65.55    0.000 #>     z3               0.881      0.013    69.05    0.000 #>   Y =~  #>     y1               1.000                              #>     y2               0.799      0.008   106.30    0.000 #>     y3               0.899      0.008   112.47    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   Y ~  #>     X                0.676      0.032    20.89    0.000 #>     Z                0.572      0.029    19.53    0.000 #>     X:Z              0.712      0.027    26.72    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               1.025      0.021    48.95    0.000 #>     x2               1.218      0.018    68.87    0.000 #>     x3               0.922      0.020    47.18    0.000 #>     z1               1.016      0.028    36.17    0.000 #>     z2               1.209      0.023    51.86    0.000 #>     z3               0.920      0.025    36.75    0.000 #>     y1               1.046      0.035    29.91    0.000 #>     y2               1.227      0.029    42.98    0.000 #>     y3               0.962      0.032    30.17    0.000 #>     Y                0.000                              #>     X                0.000                              #>     Z                0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X ~~  #>     Z                0.198      0.027     7.23    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               0.160      0.008    19.63    0.000 #>     x2               0.163      0.007    24.10    0.000 #>     x3               0.165      0.008    21.53    0.000 #>     z1               0.166      0.009    18.74    0.000 #>     z2               0.160      0.007    22.64    0.000 #>     z3               0.158      0.008    20.78    0.000 #>     y1               0.160      0.009    17.98    0.000 #>     y2               0.154      0.007    22.74    0.000 #>     y3               0.163      0.008    20.73    0.000 #>     X                0.972      0.032    30.84    0.000 #>     Z                1.017      0.038    26.66    0.000 #>     Y                0.984      0.036    27.12    0.000"},{"path":"/articles/modsem.html","id":"interactions-between-two-observed-variables","dir":"Articles","previous_headings":"The Basic Syntax","what":"Interactions Between Two Observed Variables","title":"modsem","text":"modsem allows estimate interactions latent variables also observed variables. , first run regression observed variables, interaction x1 z2, run equivalent model using modsem().","code":""},{"path":"/articles/modsem.html","id":"using-a-regression","dir":"Articles","previous_headings":"The Basic Syntax > Interactions Between Two Observed Variables","what":"Using a Regression","title":"modsem","text":"","code":"reg1 <- lm(y1 ~ x1*z1, oneInt) summary(reg1) #>  #> Call: #> lm(formula = y1 ~ x1 * z1, data = oneInt) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -3.7155 -0.8087 -0.0367  0.8078  4.6531  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  0.51422    0.04618  11.135   <2e-16 *** #> x1           0.05477    0.03387   1.617   0.1060     #> z1          -0.06575    0.03461  -1.900   0.0576 .   #> x1:z1        0.54361    0.02272  23.926   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 1.184 on 1996 degrees of freedom #> Multiple R-squared:  0.4714, Adjusted R-squared:  0.4706  #> F-statistic: 593.3 on 3 and 1996 DF,  p-value: < 2.2e-16"},{"path":"/articles/modsem.html","id":"using-modsem","dir":"Articles","previous_headings":"The Basic Syntax > Interactions Between Two Observed Variables","what":"Using modsem","title":"modsem","text":"interactions observed variables, generally recommended use method = \"pind\". Interaction effects observed variables supported LMS QML approaches. cases, can define latent variable single indicator estimate interaction effect two observed variables LMS QML approaches, generally recommended.","code":"# Using \"pind\" as the method (see Chapter 3) est2 <- modsem('y1 ~ x1 + z1 + x1:z1', data = oneInt, method = \"pind\") summary(est2) #> modsem (version 1.0.4, approach = pind): #> lavaan 0.6-19 ended normally after 1 iteration #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                         4 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                                 0.000 #>   Degrees of freedom                                 0 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   y1 ~                                                 #>     x1                0.055    0.034    1.619    0.105 #>     z1               -0.066    0.035   -1.902    0.057 #>     x1z1              0.544    0.023   23.950    0.000 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .y1                1.399    0.044   31.623    0.000"},{"path":"/articles/modsem.html","id":"interactions-between-latent-and-observed-variables","dir":"Articles","previous_headings":"The Basic Syntax","what":"Interactions Between Latent and Observed Variables","title":"modsem","text":"modsem also allows estimate interaction effects latent observed variables. , simply join latent observed variable colon (e.g., 'latent:observer'). interactions observed variables, generally recommended use method = \"pind\" estimating effect latent observed variables.","code":"m3 <- '   # Outer Model   X =~ x1 + x2 + x3   Y =~ y1 + y2 + y3      # Inner Model   Y ~ X + z1 + X:z1  '  est3 <- modsem(m3, oneInt, method = \"pind\") summary(est3) #> modsem (version 1.0.4, approach = pind): #> lavaan 0.6-19 ended normally after 45 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        22 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                              4468.171 #>   Degrees of freedom                                32 #>   P-value (Chi-square)                           0.000 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   X =~                                                 #>     x1                1.000                            #>     x2                0.803    0.013   63.697    0.000 #>     x3                0.915    0.014   67.548    0.000 #>   Y =~                                                 #>     y1                1.000                            #>     y2                0.798    0.007  115.375    0.000 #>     y3                0.899    0.007  120.783    0.000 #>   Xz1 =~                                               #>     x1z1              1.000                            #>     x2z1              0.947    0.010   96.034    0.000 #>     x3z1              0.902    0.009   99.512    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   Y ~                                                  #>     X                 0.021    0.034    0.614    0.540 #>     z1               -0.185    0.023   -8.096    0.000 #>     Xz1               0.646    0.017   37.126    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   X ~~                                                 #>     Xz1               1.243    0.055   22.523    0.000 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .x1                0.158    0.009   17.976    0.000 #>    .x2                0.164    0.007   23.216    0.000 #>    .x3                0.162    0.008   20.325    0.000 #>    .y1                0.158    0.009   17.819    0.000 #>    .y2                0.154    0.007   22.651    0.000 #>    .y3                0.164    0.008   20.744    0.000 #>    .x1z1              0.315    0.017   18.328    0.000 #>    .x2z1              0.428    0.019   22.853    0.000 #>    .x3z1              0.337    0.016   21.430    0.000 #>     X                 0.982    0.036   26.947    0.000 #>    .Y                 1.112    0.040   27.710    0.000 #>     Xz1               3.965    0.136   29.217    0.000"},{"path":"/articles/modsem.html","id":"quadratic-effects","dir":"Articles","previous_headings":"The Basic Syntax","what":"Quadratic Effects","title":"modsem","text":"Quadratic effects essentially special case interaction effects. Thus, modsem can also used estimate quadratic effects.","code":"m4 <- ' # Outer Model X =~ x1 + x2 + x3 Y =~ y1 + y2 + y3 Z =~ z1 + z2 + z3  # Inner Model Y ~ X + Z + Z:X + X:X '  est4 <- modsem(m4, oneInt, method = \"qml\") summary(est4) #>  #> modsem (version 1.0.4): #>   Estimator                                         QML #>   Optimization method                            NLMINB #>   Number of observations                           2000 #>   Number of iterations                              123 #>   Loglikelihood                                -17496.2 #>   Akaike (AIC)                                  35056.4 #>   Bayesian (BIC)                               35235.63 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -17832 #>   Akaike (AIC)                                 35723.75 #>   Bayesian (BIC)                               35891.78 #>   Chi-square                                      17.52 #>   Degrees of Freedom (Chi-square)                    24 #>   P-value (Chi-square)                            0.826 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                           335.68 #>   Difference test (D)                            671.35 #>   Degrees of freedom (D)                              2 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   Y                                               0.607 #> R-Squared Null-Model (H0): #>   Y                                               0.395 #> R-Squared Change: #>   Y                                               0.212 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X =~  #>     x1               1.000                              #>     x2               0.803      0.013   63.961    0.000 #>     x3               0.914      0.013   67.797    0.000 #>   Z =~  #>     z1               1.000                              #>     z2               0.810      0.012   65.124    0.000 #>     z3               0.881      0.013   67.621    0.000 #>   Y =~  #>     y1               1.000                              #>     y2               0.798      0.007  107.567    0.000 #>     y3               0.899      0.008  112.542    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   Y ~  #>     X                0.674      0.032   20.888    0.000 #>     Z                0.566      0.030   18.948    0.000 #>     X:X             -0.005      0.023   -0.207    0.836 #>     X:Z              0.713      0.029   24.554    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               1.023      0.024   42.894    0.000 #>     x2               1.216      0.020   60.996    0.000 #>     x3               0.919      0.022   41.484    0.000 #>     z1               1.012      0.024   41.576    0.000 #>     z2               1.206      0.020   59.271    0.000 #>     z3               0.916      0.022   42.063    0.000 #>     y1               1.042      0.038   27.684    0.000 #>     y2               1.224      0.030   40.159    0.000 #>     y3               0.958      0.034   28.101    0.000 #>     Y                0.000                              #>     X                0.000                              #>     Z                0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X ~~  #>     Z                0.200      0.024    8.239    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               0.158      0.009   18.145    0.000 #>     x2               0.162      0.007   23.188    0.000 #>     x3               0.165      0.008   20.821    0.000 #>     z1               0.166      0.009   18.341    0.000 #>     z2               0.159      0.007   22.622    0.000 #>     z3               0.158      0.008   20.714    0.000 #>     y1               0.159      0.009   17.975    0.000 #>     y2               0.154      0.007   22.670    0.000 #>     y3               0.164      0.008   20.711    0.000 #>     X                0.983      0.036   26.994    0.000 #>     Z                1.019      0.038   26.951    0.000 #>     Y                0.943      0.038   24.820    0.000"},{"path":"/articles/modsem.html","id":"more-complicated-examples","dir":"Articles","previous_headings":"The Basic Syntax","what":"More Complicated Examples","title":"modsem","text":"complex example using theory planned behavior (TPB) model. example includes two quadratic effects one interaction effect, using jordan dataset. dataset subset PISA 2006 dataset. Note: approaches also work may quite slow depending number interaction effects, particularly LMS constrained approaches.","code":"tpb <- '  # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC + INT:PBC   '  # The double-centering approach est_tpb <- modsem(tpb, TPB)  # Using the LMS approach est_tpb_lms <- modsem(tpb, TPB, method = \"lms\") #> Warning: It is recommended that you have at least 32 nodes for interaction #> effects between exogenous and endogenous variables in the lms approach 'nodes = #> 24' summary(est_tpb_lms) #>  #> modsem (version 1.0.4): #>   Estimator                                         LMS #>   Optimization method                         EM-NLMINB #>   Number of observations                           2000 #>   Number of iterations                              103 #>   Loglikelihood                               -23463.37 #>   Akaike (AIC)                                 47034.74 #>   Bayesian (BIC)                               47337.19 #>   #> Numerical Integration: #>   Points of integration (per dim)                    24 #>   Dimensions                                          1 #>   Total points of integration                        24 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -26393 #>   Akaike (AIC)                                 52892.45 #>   Bayesian (BIC)                               53189.29 #>   Chi-square                                      66.27 #>   Degrees of Freedom (Chi-square)                    82 #>   P-value (Chi-square)                            0.897 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                          2929.85 #>   Difference test (D)                           5859.70 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   INT                                             0.361 #>   BEH                                             0.248 #> R-Squared Null-Model (H0): #>   INT                                             0.367 #>   BEH                                             0.210 #> R-Squared Change: #>   INT                                            -0.006 #>   BEH                                             0.038 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  expected #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC =~  #>     pbc1             1.000                              #>     pbc2             0.911      0.013    67.91    0.000 #>     pbc3             0.802      0.012    65.67    0.000 #>   ATT =~  #>     att1             1.000                              #>     att2             0.877      0.012    71.32    0.000 #>     att3             0.789      0.012    65.69    0.000 #>     att4             0.695      0.011    60.84    0.000 #>     att5             0.887      0.013    70.49    0.000 #>   SN =~  #>     sn1              1.000                              #>     sn2              0.889      0.017    51.79    0.000 #>   INT =~  #>     int1             1.000                              #>     int2             0.913      0.015    59.42    0.000 #>     int3             0.807      0.014    55.75    0.000 #>   BEH =~  #>     b1               1.000                              #>     b2               0.961      0.030    31.82    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   INT ~  #>     PBC              0.217      0.030     7.29    0.000 #>     ATT              0.213      0.026     8.28    0.000 #>     SN               0.177      0.028     6.34    0.000 #>   BEH ~  #>     PBC              0.228      0.023    10.06    0.000 #>     INT              0.182      0.025     7.37    0.000 #>     PBC:INT          0.204      0.019    10.98    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     pbc1             0.959      0.019    50.31    0.000 #>     pbc2             0.950      0.018    53.08    0.000 #>     pbc3             0.960      0.016    59.11    0.000 #>     att1             0.987      0.022    44.10    0.000 #>     att2             0.983      0.020    49.45    0.000 #>     att3             0.995      0.018    54.27    0.000 #>     att4             0.980      0.017    58.41    0.000 #>     att5             0.969      0.020    48.14    0.000 #>     sn1              0.979      0.023    43.04    0.000 #>     sn2              0.987      0.020    48.23    0.000 #>     int1             0.995      0.022    46.17    0.000 #>     int2             0.995      0.020    49.49    0.000 #>     int3             0.990      0.018    53.60    0.000 #>     b1               0.989      0.022    45.86    0.000 #>     b2               1.008      0.020    50.01    0.000 #>     INT              0.000                              #>     BEH              0.000                              #>     PBC              0.000                              #>     ATT              0.000                              #>     SN               0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC ~~  #>     ATT              0.658      0.025    25.84    0.000 #>     SN               0.657      0.026    25.04    0.000 #>   ATT ~~  #>     SN               0.616      0.027    22.54    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     pbc1             0.147      0.008    19.39    0.000 #>     pbc2             0.164      0.007    22.22    0.000 #>     pbc3             0.154      0.006    24.15    0.000 #>     att1             0.167      0.007    23.38    0.000 #>     att2             0.150      0.006    24.30    0.000 #>     att3             0.159      0.006    26.67    0.000 #>     att4             0.163      0.006    27.66    0.000 #>     att5             0.159      0.006    24.78    0.000 #>     sn1              0.178      0.015    12.12    0.000 #>     sn2              0.156      0.012    13.00    0.000 #>     int1             0.157      0.009    18.18    0.000 #>     int2             0.160      0.008    20.21    0.000 #>     int3             0.168      0.007    23.39    0.000 #>     b1               0.186      0.019    10.00    0.000 #>     b2               0.135      0.017     8.03    0.000 #>     PBC              0.933      0.030    31.16    0.000 #>     ATT              0.985      0.035    27.94    0.000 #>     SN               0.974      0.038    25.45    0.000 #>     INT              0.491      0.020    24.40    0.000 #>     BEH              0.456      0.022    20.28    0.000 m2 <- ' ENJ =~ enjoy1 + enjoy2 + enjoy3 + enjoy4 + enjoy5 CAREER =~ career1 + career2 + career3 + career4 SC =~ academic1 + academic2 + academic3 + academic4 + academic5 + academic6 CAREER ~ ENJ + SC + ENJ:ENJ + SC:SC + ENJ:SC '  est_jordan <- modsem(m2, data = jordan) est_jordan_qml <- modsem(m2, data = jordan, method = \"qml\") summary(est_jordan_qml) #>  #> modsem (version 1.0.4): #>   Estimator                                         QML #>   Optimization method                            NLMINB #>   Number of observations                           6038 #>   Number of iterations                              101 #>   Loglikelihood                              -110520.22 #>   Akaike (AIC)                                221142.45 #>   Bayesian (BIC)                              221484.44 #>   #> Fit Measures for H0: #>   Loglikelihood                                 -110521 #>   Akaike (AIC)                                221138.58 #>   Bayesian (BIC)                              221460.46 #>   Chi-square                                    1016.34 #>   Degrees of Freedom (Chi-square)                    87 #>   P-value (Chi-square)                            0.000 #>   RMSEA                                           0.005 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                             1.07 #>   Difference test (D)                              2.13 #>   Degrees of freedom (D)                              3 #>   P-value (D)                                     0.546 #>   #> R-Squared: #>   CAREER                                          0.512 #> R-Squared Null-Model (H0): #>   CAREER                                          0.510 #> R-Squared Change: #>   CAREER                                          0.002 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   ENJ =~  #>     enjoy1           1.000                              #>     enjoy2           1.002      0.020   50.587    0.000 #>     enjoy3           0.894      0.020   43.669    0.000 #>     enjoy4           0.999      0.021   48.227    0.000 #>     enjoy5           1.047      0.021   50.400    0.000 #>   SC =~  #>     academic1        1.000                              #>     academic2        1.104      0.028   38.946    0.000 #>     academic3        1.235      0.030   41.720    0.000 #>     academic4        1.254      0.030   41.828    0.000 #>     academic5        1.113      0.029   38.647    0.000 #>     academic6        1.198      0.030   40.356    0.000 #>   CAREER =~  #>     career1          1.000                              #>     career2          1.040      0.016   65.180    0.000 #>     career3          0.952      0.016   57.838    0.000 #>     career4          0.818      0.017   48.358    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   CAREER ~  #>     ENJ              0.523      0.020   26.286    0.000 #>     SC               0.467      0.023   19.884    0.000 #>     ENJ:ENJ          0.026      0.022    1.206    0.228 #>     ENJ:SC          -0.039      0.046   -0.851    0.395 #>     SC:SC           -0.002      0.035   -0.058    0.953 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     enjoy1           0.000      0.013   -0.008    0.994 #>     enjoy2           0.000      0.015    0.010    0.992 #>     enjoy3           0.000      0.013   -0.023    0.982 #>     enjoy4           0.000      0.014    0.008    0.993 #>     enjoy5           0.000      0.014    0.025    0.980 #>     academic1        0.000      0.016   -0.009    0.993 #>     academic2        0.000      0.014   -0.009    0.993 #>     academic3        0.000      0.015   -0.028    0.978 #>     academic4        0.000      0.016   -0.015    0.988 #>     academic5       -0.001      0.014   -0.044    0.965 #>     academic6        0.001      0.015    0.048    0.962 #>     career1         -0.004      0.017   -0.204    0.838 #>     career2         -0.004      0.018   -0.248    0.804 #>     career3         -0.004      0.017   -0.214    0.830 #>     career4         -0.004      0.016   -0.232    0.816 #>     CAREER           0.000                              #>     ENJ              0.000                              #>     SC               0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   ENJ ~~  #>     SC               0.218      0.009   25.477    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     enjoy1           0.487      0.011   44.335    0.000 #>     enjoy2           0.488      0.011   44.406    0.000 #>     enjoy3           0.596      0.012   48.233    0.000 #>     enjoy4           0.488      0.011   44.561    0.000 #>     enjoy5           0.442      0.010   42.470    0.000 #>     academic1        0.645      0.013   49.813    0.000 #>     academic2        0.566      0.012   47.864    0.000 #>     academic3        0.473      0.011   44.319    0.000 #>     academic4        0.455      0.010   43.579    0.000 #>     academic5        0.565      0.012   47.695    0.000 #>     academic6        0.502      0.011   45.434    0.000 #>     career1          0.373      0.009   40.392    0.000 #>     career2          0.328      0.009   37.019    0.000 #>     career3          0.436      0.010   43.272    0.000 #>     career4          0.576      0.012   48.372    0.000 #>     ENJ              0.500      0.017   29.547    0.000 #>     SC               0.338      0.015   23.195    0.000 #>     CAREER           0.302      0.010   29.711    0.000"},{"path":"/articles/observed_lms_qml.html","id":"the-latent-moderated-structural-equations-lms-and-the-quasi-maximum-likelihood-qml-approach","dir":"Articles","previous_headings":"","what":"The Latent Moderated Structural Equations (LMS) and the Quasi Maximum Likelihood (QML) Approach","title":"observed variables in the LMS- and QML approach","text":"contrast approaches, LMS QML approaches designed handle latent variables . Thus, observed variables used easily approaches. One way get around specifying observed variable latent variable single indicator. modsem() , default, constrain factor loading 1 residual variance indicator 0. difference latent variable indicator, assuming exogenous variable, zero-mean. approach works LMS QML methods cases, two exceptions.","code":""},{"path":"/articles/observed_lms_qml.html","id":"the-lms-approach","dir":"Articles","previous_headings":"The Latent Moderated Structural Equations (LMS) and the Quasi Maximum Likelihood (QML) Approach","what":"The LMS Approach","title":"observed variables in the LMS- and QML approach","text":"LMS approach, can use -mentioned method almost cases, except using observed variable moderating variable. LMS approach, typically select one variable interaction term moderator. interaction effect estimated via numerical integration n quadrature nodes moderating variable. However, process requires moderating variable error term, distribution moderating variable modeled X∼N(Az,ε)X \\sim N(Az, \\varepsilon), AzAz expected value XX quadrature point k, ε\\varepsilon error term. error term zero, probability observing given value XX computable. instances, first variable interaction term chosen moderator. example, interaction term \"X:Z\", \"X\" usually chosen moderator. Therefore, one variables latent, place latent variable first interaction term. variables observed, must specify measurement error (e.g., \"x1 ~~ 0.1 * x1\") indicator first variable interaction term.","code":"library(modsem)  # Interaction effect between a latent and an observed variable m1 <- ' # Outer Model   X =~ x1 # X is observed   Z =~ z1 + z2 # Z is latent   Y =~ y1 # Y is observed  # Inner model   Y ~ X + Z   Y ~ Z:X '  lms1 <- modsem(m1, oneInt, method = \"lms\")  # Interaction effect between two observed variables m2 <- ' # Outer Model   X =~ x1 # X is observed   Z =~ z1 # Z is observed   Y =~ y1 # Y is observed   x1 ~~ 0.1 * x1 # Specify a variance for the measurement error  # Inner model   Y ~ X + Z   Y ~ X:Z '  lms2 <- modsem(m2, oneInt, method = \"lms\") summary(lms2) #>  #> modsem (version 1.0.4): #>   Estimator                                         LMS #>   Optimization method                         EM-NLMINB #>   Number of observations                           2000 #>   Number of iterations                               38 #>   Loglikelihood                                -6632.86 #>   Akaike (AIC)                                 13285.71 #>   Bayesian (BIC)                               13341.72 #>   #> Numerical Integration: #>   Points of integration (per dim)                    24 #>   Dimensions                                          1 #>   Total points of integration                        24 #>   #> Fit Measures for H0: #>   Loglikelihood                                   -9369 #>   Akaike (AIC)                                 18756.46 #>   Bayesian (BIC)                               18806.87 #>   Chi-square                                       0.00 #>   Degrees of Freedom (Chi-square)                     0 #>   P-value (Chi-square)                            0.000 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                          2736.38 #>   Difference test (D)                           5472.75 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   Y                                               0.494 #> R-Squared Null-Model (H0): #>   Y                                               0.335 #> R-Squared Change: #>   Y                                               0.160 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  expected #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X =~  #>     x1               1.000                              #>   Z =~  #>     z1               1.000                              #>   Y =~  #>     y1               1.000                              #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   Y ~  #>     X                0.663      0.032    20.68    0.000 #>     Z                0.482      0.029    16.55    0.000 #>     X:Z              0.586      0.025    23.89    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               1.023      0.025    40.20    0.000 #>     z1               1.011      0.027    37.67    0.000 #>     y1               1.057      0.036    29.02    0.000 #>     Y                0.000                              #>     X                0.000                              #>     Z                0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X ~~  #>     Z                0.208      0.029     7.21    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               0.100                              #>     z1               0.000                              #>     y1               0.000                              #>     X                1.028      0.035    29.37    0.000 #>     Z                1.184      0.037    31.87    0.000 #>     Y                1.323      0.044    30.17    0.000"},{"path":"/articles/observed_lms_qml.html","id":"the-qml-approach","dir":"Articles","previous_headings":"The Latent Moderated Structural Equations (LMS) and the Quasi Maximum Likelihood (QML) Approach","what":"The QML Approach","title":"observed variables in the LMS- and QML approach","text":"estimation process QML approach differs LMS approach, encounter issue LMS approach. Therefore, don’t need specify measurement error moderating variables.","code":"m3 <- ' # Outer Model   X =~ x1 # X is observed   Z =~ z1 # Z is observed   Y =~ y1 # Y is observed  # Inner model   Y ~ X + Z   Y ~ X:Z '  qml3 <- modsem(m3, oneInt, method = \"qml\") summary(qml3) #>  #> modsem (version 1.0.4): #>   Estimator                                         QML #>   Optimization method                            NLMINB #>   Number of observations                           2000 #>   Number of iterations                               11 #>   Loglikelihood                                -9117.07 #>   Akaike (AIC)                                 18254.13 #>   Bayesian (BIC)                               18310.14 #>   #> Fit Measures for H0: #>   Loglikelihood                                   -9369 #>   Akaike (AIC)                                 18756.46 #>   Bayesian (BIC)                               18806.87 #>   Chi-square                                       0.00 #>   Degrees of Freedom (Chi-square)                     0 #>   P-value (Chi-square)                            0.000 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                           252.17 #>   Difference test (D)                            504.33 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   Y                                               0.470 #> R-Squared Null-Model (H0): #>   Y                                               0.320 #> R-Squared Change: #>   Y                                               0.150 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X =~  #>     x1               1.000                              #>   Z =~  #>     z1               1.000                              #>   Y =~  #>     y1               1.000                              #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   Y ~  #>     X                0.605      0.028    21.26    0.000 #>     Z                0.490      0.028    17.55    0.000 #>     X:Z              0.544      0.023    23.95    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               1.023      0.024    42.83    0.000 #>     z1               1.011      0.024    41.56    0.000 #>     y1               1.066      0.034    31.64    0.000 #>     Y                0.000                              #>     X                0.000                              #>     Z                0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X ~~  #>     Z                0.210      0.026     7.95    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               0.000                              #>     z1               0.000                              #>     y1               0.000                              #>     X                1.141      0.036    31.62    0.000 #>     Z                1.184      0.037    31.62    0.000 #>     Y                1.399      0.044    31.62    0.000"},{"path":"/articles/plot_interactions.html","id":"plotting-interaction-effects","dir":"Articles","previous_headings":"","what":"Plotting Interaction Effects","title":"plotting interaction effects","text":"Interaction effects can plotted using included plot_interaction() function. function takes fitted model object names two variables interacting. function plot interaction effect two variables, : x-variable plotted x-axis. y-variable plotted y-axis. z-variable determines points effect x y plotted. function also plot 95% confidence interval interaction effect. simple example using double-centering approach:  different example using lms approach theory planned behavior model:","code":"m1 <- \" # Outer Model   X =~ x1   X =~ x2 + x3   Z =~ z1 + z2 + z3   Y =~ y1 + y2 + y3  # Inner Model   Y ~ X + Z + X:Z \" est1 <- modsem(m1, data = oneInt) plot_interaction(\"X\", \"Z\", \"Y\", \"X:Z\", vals_z = -3:3, range_y = c(-0.2, 0), model = est1) tpb <- \" # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ PBC:INT \"  est2 <- modsem(tpb, TPB, method = \"lms\") #> Warning: It is recommended that you have at least 32 nodes for interaction #> effects between exogenous and endogenous variables in the lms approach 'nodes = #> 24' plot_interaction(x = \"INT\", z = \"PBC\", y = \"BEH\", xz = \"PBC:INT\",                   vals_z = c(-0.5, 0.5), model = est2)"},{"path":"/articles/quadratic.html","id":"quadratic-effects-and-interaction-effects","dir":"Articles","previous_headings":"","what":"Quadratic Effects and Interaction Effects","title":"quadratic effects","text":"Quadratic effects essentially special case interaction effects—variable interacts . , methods modsem can also used estimate quadratic effects. simple example using LMS approach. example, simple model two quadratic effects one interaction effect. estimate model using QML double-centering approaches, data subset PISA 2006 dataset. Note: approaches (e.g., LMS constrained methods) can also used may slower depending number interaction effects, especially LMS constrained approaches.","code":"library(modsem) m1 <- ' # Outer Model X =~ x1 + x2 + x3 Y =~ y1 + y2 + y3 Z =~ z1 + z2 + z3  # Inner model Y ~ X + Z + Z:X + X:X '  est1Lms <- modsem(m1, data = oneInt, method = \"lms\") summary(est1Lms) #>  #> modsem (version 1.0.4): #>   Estimator                                         LMS #>   Optimization method                         EM-NLMINB #>   Number of observations                           2000 #>   Number of iterations                              119 #>   Loglikelihood                               -14687.61 #>   Akaike (AIC)                                 29439.22 #>   Bayesian (BIC)                               29618.45 #>   #> Numerical Integration: #>   Points of integration (per dim)                    24 #>   Dimensions                                          1 #>   Total points of integration                        24 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -17832 #>   Akaike (AIC)                                 35723.75 #>   Bayesian (BIC)                               35891.78 #>   Chi-square                                      17.52 #>   Degrees of Freedom (Chi-square)                    24 #>   P-value (Chi-square)                            0.826 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                          3144.26 #>   Difference test (D)                           6288.52 #>   Degrees of freedom (D)                              2 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   Y                                               0.596 #> R-Squared Null-Model (H0): #>   Y                                               0.395 #> R-Squared Change: #>   Y                                               0.200 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  expected #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X =~  #>     x1               1.000                              #>     x2               0.804      0.013   64.190    0.000 #>     x3               0.915      0.014   67.500    0.000 #>   Z =~  #>     z1               1.000                              #>     z2               0.810      0.012   66.234    0.000 #>     z3               0.881      0.013   67.522    0.000 #>   Y =~  #>     y1               1.000                              #>     y2               0.798      0.007  107.740    0.000 #>     y3               0.899      0.008  111.483    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   Y ~  #>     X                0.673      0.031   21.599    0.000 #>     Z                0.570      0.028   20.328    0.000 #>     X:X             -0.007      0.019   -0.383    0.702 #>     X:Z              0.715      0.028   25.965    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               1.023      0.020   50.450    0.000 #>     x2               1.215      0.017   70.631    0.000 #>     x3               0.919      0.019   48.572    0.000 #>     z1               1.013      0.026   38.625    0.000 #>     z2               1.207      0.022   55.387    0.000 #>     z3               0.917      0.023   39.276    0.000 #>     y1               1.046      0.036   28.900    0.000 #>     y2               1.228      0.029   41.630    0.000 #>     y3               0.962      0.033   29.308    0.000 #>     Y                0.000                              #>     X                0.000                              #>     Z                0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X ~~  #>     Z                0.199      0.026    7.622    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               0.160      0.008   19.221    0.000 #>     x2               0.163      0.007   23.851    0.000 #>     x3               0.165      0.008   21.316    0.000 #>     z1               0.167      0.009   18.868    0.000 #>     z2               0.160      0.007   23.152    0.000 #>     z3               0.158      0.007   21.175    0.000 #>     y1               0.160      0.009   18.085    0.000 #>     y2               0.154      0.007   22.840    0.000 #>     y3               0.163      0.008   20.870    0.000 #>     X                0.972      0.033   29.230    0.000 #>     Z                1.017      0.038   26.630    0.000 #>     Y                0.983      0.035   28.200    0.000 m2 <- ' ENJ =~ enjoy1 + enjoy2 + enjoy3 + enjoy4 + enjoy5 CAREER =~ career1 + career2 + career3 + career4 SC =~ academic1 + academic2 + academic3 + academic4 + academic5 + academic6 CAREER ~ ENJ + SC + ENJ:ENJ + SC:SC + ENJ:SC '  est2Dblcent <- modsem(m2, data = jordan) est2Qml <- modsem(m2, data = jordan, method = \"qml\") summary(est2Qml) #>  #> modsem (version 1.0.4): #>   Estimator                                         QML #>   Optimization method                            NLMINB #>   Number of observations                           6038 #>   Number of iterations                              101 #>   Loglikelihood                              -110520.22 #>   Akaike (AIC)                                221142.45 #>   Bayesian (BIC)                              221484.44 #>   #> Fit Measures for H0: #>   Loglikelihood                                 -110521 #>   Akaike (AIC)                                221138.58 #>   Bayesian (BIC)                              221460.46 #>   Chi-square                                    1016.34 #>   Degrees of Freedom (Chi-square)                    87 #>   P-value (Chi-square)                            0.000 #>   RMSEA                                           0.005 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                             1.07 #>   Difference test (D)                              2.13 #>   Degrees of freedom (D)                              3 #>   P-value (D)                                     0.546 #>   #> R-Squared: #>   CAREER                                          0.512 #> R-Squared Null-Model (H0): #>   CAREER                                          0.510 #> R-Squared Change: #>   CAREER                                          0.002 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   ENJ =~  #>     enjoy1           1.000                              #>     enjoy2           1.002      0.020   50.587    0.000 #>     enjoy3           0.894      0.020   43.669    0.000 #>     enjoy4           0.999      0.021   48.227    0.000 #>     enjoy5           1.047      0.021   50.400    0.000 #>   SC =~  #>     academic1        1.000                              #>     academic2        1.104      0.028   38.946    0.000 #>     academic3        1.235      0.030   41.720    0.000 #>     academic4        1.254      0.030   41.828    0.000 #>     academic5        1.113      0.029   38.647    0.000 #>     academic6        1.198      0.030   40.356    0.000 #>   CAREER =~  #>     career1          1.000                              #>     career2          1.040      0.016   65.180    0.000 #>     career3          0.952      0.016   57.838    0.000 #>     career4          0.818      0.017   48.358    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   CAREER ~  #>     ENJ              0.523      0.020   26.286    0.000 #>     SC               0.467      0.023   19.884    0.000 #>     ENJ:ENJ          0.026      0.022    1.206    0.228 #>     ENJ:SC          -0.039      0.046   -0.851    0.395 #>     SC:SC           -0.002      0.035   -0.058    0.953 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     enjoy1           0.000      0.013   -0.008    0.994 #>     enjoy2           0.000      0.015    0.010    0.992 #>     enjoy3           0.000      0.013   -0.023    0.982 #>     enjoy4           0.000      0.014    0.008    0.993 #>     enjoy5           0.000      0.014    0.025    0.980 #>     academic1        0.000      0.016   -0.009    0.993 #>     academic2        0.000      0.014   -0.009    0.993 #>     academic3        0.000      0.015   -0.028    0.978 #>     academic4        0.000      0.016   -0.015    0.988 #>     academic5       -0.001      0.014   -0.044    0.965 #>     academic6        0.001      0.015    0.048    0.962 #>     career1         -0.004      0.017   -0.204    0.838 #>     career2         -0.004      0.018   -0.248    0.804 #>     career3         -0.004      0.017   -0.214    0.830 #>     career4         -0.004      0.016   -0.232    0.816 #>     CAREER           0.000                              #>     ENJ              0.000                              #>     SC               0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   ENJ ~~  #>     SC               0.218      0.009   25.477    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     enjoy1           0.487      0.011   44.335    0.000 #>     enjoy2           0.488      0.011   44.406    0.000 #>     enjoy3           0.596      0.012   48.233    0.000 #>     enjoy4           0.488      0.011   44.561    0.000 #>     enjoy5           0.442      0.010   42.470    0.000 #>     academic1        0.645      0.013   49.813    0.000 #>     academic2        0.566      0.012   47.864    0.000 #>     academic3        0.473      0.011   44.319    0.000 #>     academic4        0.455      0.010   43.579    0.000 #>     academic5        0.565      0.012   47.695    0.000 #>     academic6        0.502      0.011   45.434    0.000 #>     career1          0.373      0.009   40.392    0.000 #>     career2          0.328      0.009   37.019    0.000 #>     career3          0.436      0.010   43.272    0.000 #>     career4          0.576      0.012   48.372    0.000 #>     ENJ              0.500      0.017   29.547    0.000 #>     SC               0.338      0.015   23.195    0.000 #>     CAREER           0.302      0.010   29.711    0.000"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kjell Solem Slupphaug. Author, maintainer. Matthias Mittner. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Slupphaug, K. S., Mehmetoglu, M., & Mittner, M. (2024). modsem: R package estimating latent interactions quadratic effects. https://doi.org/10.31219/osf.io/h3rpw","code":"@Article{,   title = {modsem: An R package for estimating latent interactions and quadratic effects},   author = {Kjell Solem Slupphaug and Mehmet Mehmetoglu and Matthias Mittner},   journal = {Preprint: Open Science Foundation},   year = {2024},   doi = {https://doi.org/10.31219/osf.io/h3rpw}, }"},{"path":[]},{"path":"/index.html","id":"to-install","dir":"","previous_headings":"","what":"To Install","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"","code":"# From CRAN install.packages(\"modsem\")  # Latest version from GitHub install.packages(\"devtools\") devtools::install_github(\"kss2k/modsem\", build_vignettes = TRUE)"},{"path":"/index.html","id":"methodsapproaches","dir":"","previous_headings":"","what":"Methods/Approaches","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"number approaches estimating interaction effects SEM. modsem(), method = \"method\" argument allows choose use. Different approaches can categorized two groups: Product Indicator (PI) Distribution Analytic (DA) approaches.","code":""},{"path":"/index.html","id":"product-indicator-pi-approaches","dir":"","previous_headings":"","what":"Product Indicator (PI) Approaches:","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"Note constraints can become quite complicated complex models, particularly interaction including enodgenous variables. method can therefore quite slow. \"uca\" = unconstrained approach (Marsh, 2004) \"rca\" = residual centering approach (Little et al., 2006) default \"pind\" = basic product indicator approach (recommended)","code":""},{"path":"/index.html","id":"distribution-analytic-da-approaches","dir":"","previous_headings":"","what":"Distribution Analytic (DA) Approaches","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"\"lms\" = Latent Moderated Structural equations (LMS) approach, see vignette \"qml\" = Quasi Maximum Likelihood (QML) approach, see vignette estimates model Mplus, installed","code":""},{"path":[]},{"path":"/index.html","id":"elementary-interaction-model-kenny--judd-1984-jaccard--wan-1995","dir":"","previous_headings":"","what":"Elementary Interaction Model (Kenny & Judd, 1984; Jaccard & Wan, 1995)","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"","code":"library(modsem) m1 <- '   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z '  # Double centering approach est1_dca <- modsem(m1, oneInt) summary(est1_dca)  # Constrained approach est1_ca <- modsem(m1, oneInt, method = \"ca\") summary(est1_ca)  # QML approach est1_qml <- modsem(m1, oneInt, method = \"qml\") summary(est1_qml, standardized = TRUE)  # LMS approach est1_lms <- modsem(m1, oneInt, method = \"lms\") summary(est1_lms)"},{"path":"/index.html","id":"theory-of-planned-behavior","dir":"","previous_headings":"","what":"Theory Of Planned Behavior","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"","code":"tpb <- \" # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ PBC:INT \"  # double centering approach est_tpb_dca <- modsem(tpb, data = TPB, method = \"dblcent\") summary(est_tpb_dca)  # Constrained approach using Wrigths path tracing rules for generating # the appropriate constraints est_tpb_ca <- modsem(tpb, data = TPB, method = \"ca\") summary(est_tpb_ca)  # LMS approach est_tpb_lms <- modsem(tpb, data = TPB, method = \"lms\") summary(est_tpb_lms, standardized = TRUE)  # QML approach est_tpb_qml <- modsem(tpb, data = TPB, method = \"qml\") summary(est_tpb_qml, standardized = TRUE)"},{"path":"/index.html","id":"interactions-between-two-observed-variables","dir":"","previous_headings":"","what":"Interactions between two observed variables","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"","code":"est2 <- modsem('y1 ~ x1 + z1 + x1:z1', data = oneInt, method = \"pind\") summary(est2)"},{"path":"/index.html","id":"interaction-between-an-obsereved-and-a-latent-variable","dir":"","previous_headings":"","what":"Interaction between an obsereved and a latent variable","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"","code":"m3 <- '   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3    # Inner model   Y ~ X + z1 + X:z1 '  est3 <- modsem(m3, oneInt, method = \"pind\") summary(est3)"},{"path":"/reference/TPB.html","id":null,"dir":"Reference","previous_headings":"","what":"TPB — TPB","title":"TPB — TPB","text":"simulated dataset based Theory Planned Behaviour","code":""},{"path":"/reference/TPB.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"TPB — TPB","text":"","code":"tpb <- ' # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC + INT:PBC '  est <- modsem(tpb, data = TPB)"},{"path":"/reference/TPB_UK.html","id":null,"dir":"Reference","previous_headings":"","what":"TPB_UK — TPB_UK","title":"TPB_UK — TPB_UK","text":"dataset based Theory Planned Behaviour UK sample. 4 variables high communality selected latent variable (ATT, SN, PBC, INT, BEH), two time points (t1 t2).","code":""},{"path":"/reference/TPB_UK.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"TPB_UK — TPB_UK","text":"Gathered replciation study original Hagger et al. (2023). Obtained https://doi.org/10.23668/psycharchives.12187","code":""},{"path":"/reference/TPB_UK.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"TPB_UK — TPB_UK","text":"","code":"tpb_uk <- ' # Outer Model (Based on Hagger et al., 2007)  ATT =~ att3 + att2 + att1 + att4  SN =~ sn4 + sn2 + sn3 + sn1  PBC =~ pbc2 + pbc1 + pbc3 + pbc4  INT =~ int2 + int1 + int3 + int4  BEH =~ beh3 + beh2 + beh1 + beh4  # Inner Model (Based on Steinmetz et al., 2011)  # Causal Relationsships  INT ~ ATT + SN + PBC  BEH ~ INT + PBC  BEH ~ INT:PBC '  est <- modsem(tpb_uk, data = TPB_UK)"},{"path":"/reference/coef_modsem_da.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper for coef — coef_modsem_da","title":"Wrapper for coef — coef_modsem_da","text":"wrapper coef, used modsem::coef_modsem_da, since coef namespace modsem, stats","code":""},{"path":"/reference/coef_modsem_da.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper for coef — coef_modsem_da","text":"","code":"coef_modsem_da(object, ...)"},{"path":"/reference/coef_modsem_da.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper for coef — coef_modsem_da","text":"object fittet model inspect ... additional arguments","code":""},{"path":"/reference/compare_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"compare model fit for qml and lms models — compare_fit","title":"compare model fit for qml and lms models — compare_fit","text":"Compare fit two models using likelihood ratio test. `estH0` representing null hypothesis model, `estH1` alternative hypothesis model. Importantly, function assumes `estH0` free parameters (.e., degrees freedom) `estH1`. alternative hypothesis model","code":""},{"path":"/reference/compare_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"compare model fit for qml and lms models — compare_fit","text":"","code":"compare_fit(estH0, estH1)"},{"path":"/reference/compare_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"compare model fit for qml and lms models — compare_fit","text":"estH0 object class `modsem_da` representing null hypothesis model estH1 object class `modsem_da` representing ","code":""},{"path":"/reference/compare_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"compare model fit for qml and lms models — compare_fit","text":"","code":"if (FALSE) { # \\dontrun{ H0 <- \"  # Outer Model  X =~ x1 + x2 + x3  Y =~ y1 + y2 + y3  Z =~ z1 + z2 + z3   # Inner model  Y ~ X + Z \"  estH0 <- modsem(m1, oneInt, \"lms\")  H1 <- \"  # Outer Model  X =~ x1 + x2 + x3  Y =~ y1 + y2 + y3  Z =~ z1 + z2 + z3   # Inner model  Y ~ X + Z + X:Z \"  estH1 <- modsem(m1, oneInt, \"lms\") compare_fit(estH0, estH1) } # }"},{"path":"/reference/default_settings_da.html","id":null,"dir":"Reference","previous_headings":"","what":"default arguments fro LMS and QML approach — default_settings_da","title":"default arguments fro LMS and QML approach — default_settings_da","text":"function returns default settings LMS QML approach.","code":""},{"path":"/reference/default_settings_da.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"default arguments fro LMS and QML approach — default_settings_da","text":"","code":"default_settings_da(method = c(\"lms\", \"qml\"))"},{"path":"/reference/default_settings_da.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"default arguments fro LMS and QML approach — default_settings_da","text":"method method get settings ","code":""},{"path":"/reference/default_settings_da.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"default arguments fro LMS and QML approach — default_settings_da","text":"list","code":""},{"path":"/reference/default_settings_da.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"default arguments fro LMS and QML approach — default_settings_da","text":"","code":"library(modsem) default_settings_da() #> $lms #> $lms$verbose #> [1] FALSE #>  #> $lms$optimize #> [1] TRUE #>  #> $lms$nodes #> [1] 24 #>  #> $lms$convergence #> [1] 1e-04 #>  #> $lms$optimizer #> [1] \"nlminb\" #>  #> $lms$center.data #> [1] FALSE #>  #> $lms$standardize.data #> [1] FALSE #>  #> $lms$standardize.out #> [1] FALSE #>  #> $lms$standardize #> [1] FALSE #>  #> $lms$mean.observed #> [1] TRUE #>  #> $lms$double #> [1] FALSE #>  #> $lms$calc.se #> [1] TRUE #>  #> $lms$FIM #> [1] \"expected\" #>  #> $lms$OFIM.hessian #> [1] FALSE #>  #> $lms$EFIM.S #> [1] 30000 #>  #> $lms$EFIM.parametric #> [1] TRUE #>  #> $lms$robust.se #> [1] FALSE #>  #> $lms$max.iter #> [1] 500 #>  #> $lms$max.step #> [1] 1 #>  #> $lms$fix.estep #> [1] TRUE #>  #> $lms$epsilon #> [1] 1e-04 #>  #> $lms$quad.range #> [1] Inf #>  #> $lms$n.threads #> NULL #>  #>  #> $qml #> $qml$verbose #> [1] FALSE #>  #> $qml$optimize #> [1] TRUE #>  #> $qml$nodes #> [1] 0 #>  #> $qml$convergence #> [1] 1e-06 #>  #> $qml$optimizer #> [1] \"nlminb\" #>  #> $qml$center.data #> [1] FALSE #>  #> $qml$standardize #> [1] FALSE #>  #> $qml$standardize.data #> [1] FALSE #>  #> $qml$standardize.out #> [1] FALSE #>  #> $qml$mean.observed #> [1] TRUE #>  #> $qml$double #> [1] FALSE #>  #> $qml$calc.se #> [1] TRUE #>  #> $qml$FIM #> [1] \"observed\" #>  #> $qml$OFIM.hessian #> [1] TRUE #>  #> $qml$EFIM.S #> [1] 30000 #>  #> $qml$EFIM.parametric #> [1] TRUE #>  #> $qml$robust.se #> [1] FALSE #>  #> $qml$max.iter #> [1] 500 #>  #> $qml$max.step #> NULL #>  #> $qml$fix.estep #> NULL #>  #> $qml$epsilon #> [1] 1e-08 #>  #> $qml$quad.range #> [1] Inf #>  #> $qml$n.threads #> NULL #>  #>"},{"path":"/reference/default_settings_pi.html","id":null,"dir":"Reference","previous_headings":"","what":"default arguments for product indicator approaches — default_settings_pi","title":"default arguments for product indicator approaches — default_settings_pi","text":"function returns default settings product indicator approaches","code":""},{"path":"/reference/default_settings_pi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"default arguments for product indicator approaches — default_settings_pi","text":"","code":"default_settings_pi(method = c(\"rca\", \"uca\", \"pind\", \"dblcent\", \"ca\"))"},{"path":"/reference/default_settings_pi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"default arguments for product indicator approaches — default_settings_pi","text":"method method get settings ","code":""},{"path":"/reference/default_settings_pi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"default arguments for product indicator approaches — default_settings_pi","text":"list","code":""},{"path":"/reference/default_settings_pi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"default arguments for product indicator approaches — default_settings_pi","text":"","code":"library(modsem) default_settings_pi() #> $rca #> $rca$center.before #> [1] FALSE #>  #> $rca$center.after #> [1] FALSE #>  #> $rca$residuals.prods #> [1] TRUE #>  #> $rca$residual.cov.syntax #> [1] TRUE #>  #> $rca$constrained.prod.mean #> [1] FALSE #>  #> $rca$constrained.loadings #> [1] FALSE #>  #> $rca$constrained.var #> [1] FALSE #>  #> $rca$constrained.res.cov.method #> [1] \"simple\" #>  #> $rca$match #> [1] FALSE #>  #>  #> $uca #> $uca$center.before #> [1] TRUE #>  #> $uca$center.after #> [1] FALSE #>  #> $uca$residuals.prods #> [1] FALSE #>  #> $uca$residual.cov.syntax #> [1] TRUE #>  #> $uca$constrained.prod.mean #> [1] TRUE #>  #> $uca$constrained.loadings #> [1] FALSE #>  #> $uca$constrained.var #> [1] FALSE #>  #> $uca$constrained.res.cov.method #> [1] \"simple\" #>  #> $uca$match #> [1] FALSE #>  #>  #> $pind #> $pind$center.before #> [1] FALSE #>  #> $pind$center.after #> [1] FALSE #>  #> $pind$residuals.prods #> [1] FALSE #>  #> $pind$residual.cov.syntax #> [1] FALSE #>  #> $pind$constrained.prod.mean #> [1] FALSE #>  #> $pind$constrained.loadings #> [1] FALSE #>  #> $pind$constrained.var #> [1] FALSE #>  #> $pind$constrained.res.cov.method #> [1] \"simple\" #>  #> $pind$match #> [1] FALSE #>  #>  #> $dblcent #> $dblcent$center.before #> [1] TRUE #>  #> $dblcent$center.after #> [1] TRUE #>  #> $dblcent$residuals.prods #> [1] FALSE #>  #> $dblcent$residual.cov.syntax #> [1] TRUE #>  #> $dblcent$constrained.prod.mean #> [1] FALSE #>  #> $dblcent$constrained.loadings #> [1] FALSE #>  #> $dblcent$constrained.var #> [1] FALSE #>  #> $dblcent$constrained.res.cov.method #> [1] \"simple\" #>  #> $dblcent$match #> [1] FALSE #>  #>  #> $ca #> $ca$center.before #> [1] TRUE #>  #> $ca$center.after #> [1] FALSE #>  #> $ca$residuals.prods #> [1] FALSE #>  #> $ca$residual.cov.syntax #> [1] TRUE #>  #> $ca$constrained.prod.mean #> [1] TRUE #>  #> $ca$constrained.loadings #> [1] TRUE #>  #> $ca$constrained.var #> [1] TRUE #>  #> $ca$constrained.res.cov.method #> [1] \"ca\" #>  #> $ca$match #> [1] TRUE #>  #>"},{"path":"/reference/extract_lavaan.html","id":null,"dir":"Reference","previous_headings":"","what":"extract lavaan object from modsem object estimated using product indicators — extract_lavaan","title":"extract lavaan object from modsem object estimated using product indicators — extract_lavaan","text":"extract lavaan object modsem object estimated using product indicators","code":""},{"path":"/reference/extract_lavaan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract lavaan object from modsem object estimated using product indicators — extract_lavaan","text":"","code":"extract_lavaan(object)"},{"path":"/reference/extract_lavaan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract lavaan object from modsem object estimated using product indicators — extract_lavaan","text":"object modsem object","code":""},{"path":"/reference/extract_lavaan.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"extract lavaan object from modsem object estimated using product indicators — extract_lavaan","text":"lavaan object","code":""},{"path":"/reference/extract_lavaan.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"extract lavaan object from modsem object estimated using product indicators — extract_lavaan","text":"","code":"library(modsem) m1 <- '   # Outer Model   X =~ x1 + x2 + x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z ' est <- modsem_pi(m1, oneInt) lav_est <- extract_lavaan(est)"},{"path":"/reference/fit_modsem_da.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit measures for QML and LMS models — fit_modsem_da","title":"Fit measures for QML and LMS models — fit_modsem_da","text":"Calculates chi-sq test p-value, well RMSEA LMS QML models. Note Chi-Square based fit measures calculated baseline model, .e., model without interaction effect","code":""},{"path":"/reference/fit_modsem_da.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit measures for QML and LMS models — fit_modsem_da","text":"","code":"fit_modsem_da(model, chisq = TRUE)"},{"path":"/reference/fit_modsem_da.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit measures for QML and LMS models — fit_modsem_da","text":"model fitted model. Thereafter, can use 'compare_fit()' assess comparative fit models. interaction effect makes model better, e.g., RMSEA good baseline model, interaction model likely good RMSEA well. chisq Chi-Square based fit-measures calculated?","code":""},{"path":"/reference/get_pi_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Get data with product indicators for different approaches — get_pi_data","title":"Get data with product indicators for different approaches — get_pi_data","text":"get_pi_syntax() function creating lavaan syntax used estimating latent interaction models using one product indicators lavaan.","code":""},{"path":"/reference/get_pi_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get data with product indicators for different approaches — get_pi_data","text":"","code":"get_pi_data(model.syntax, data, method = \"dblcent\", match = FALSE, ...)"},{"path":"/reference/get_pi_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get data with product indicators for different approaches — get_pi_data","text":"model.syntax lavaan syntax data data create product indicators method method use: \"rca\" = residual centering approach, \"uca\" = unconstrained approach, \"dblcent\" = double centering approach, \"pind\" = prod ind approach, constraints centering, \"custom\" = use parameters specified function call match product indicators created using match-strategy ... arguments passed functions (e.g., modsem_pi)","code":""},{"path":"/reference/get_pi_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get data with product indicators for different approaches — get_pi_data","text":"data.frame","code":""},{"path":"/reference/get_pi_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get data with product indicators for different approaches — get_pi_data","text":"","code":"library(modsem) library(lavaan) #> This is lavaan 0.6-19 #> lavaan is FREE software! Please report any bugs. m1 <- '   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z ' syntax <- get_pi_syntax(m1) data <- get_pi_data(m1, oneInt) est <- sem(syntax, data)"},{"path":"/reference/get_pi_syntax.html","id":null,"dir":"Reference","previous_headings":"","what":"Get lavaan syntax for product indicator approaches — get_pi_syntax","title":"Get lavaan syntax for product indicator approaches — get_pi_syntax","text":"get_pi_syntax() function creating lavaan syntax used estimating latent interaction models using one product indicators lavaan.","code":""},{"path":"/reference/get_pi_syntax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get lavaan syntax for product indicator approaches — get_pi_syntax","text":"","code":"get_pi_syntax(model.syntax, method = \"dblcent\", match = FALSE, ...)"},{"path":"/reference/get_pi_syntax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get lavaan syntax for product indicator approaches — get_pi_syntax","text":"model.syntax lavaan syntax method method use: \"rca\" = residual centering approach, \"uca\" = unconstrained approach, \"dblcent\" = double centering approach, \"pind\" = prod ind approach, constraints centering, \"custom\" = use parameters specified function call match product indicators created using match-strategy ... arguments passed functions (e.g., modsem_pi)","code":""},{"path":"/reference/get_pi_syntax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get lavaan syntax for product indicator approaches — get_pi_syntax","text":"character vector","code":""},{"path":"/reference/get_pi_syntax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get lavaan syntax for product indicator approaches — get_pi_syntax","text":"","code":"library(modsem) library(lavaan) m1 <- '   # Outer Model   X =~ x1 + x2 + x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z ' syntax <- get_pi_syntax(m1) data <- get_pi_data(m1, oneInt) est <- sem(syntax, data)"},{"path":"/reference/jordan.html","id":null,"dir":"Reference","previous_headings":"","what":"Jordan subset of PISA 2006 data — jordan","title":"Jordan subset of PISA 2006 data — jordan","text":"data stem large-scale assessment study PISA 2006 (Organisation Economic Co-Operation Development, 2009) competencies 15-year-old students reading, mathematics, science assessed using nationally representative samples 3-year cycles. eacademicample, data student background questionnaire Jordan sample PISA 2006 used. data students complete responses 15 items (N = 6,038) considered.","code":""},{"path":"/reference/jordan.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Jordan subset of PISA 2006 data — jordan","text":"data frame fifteen variables 6,038 observations: enjoy1 indicator enjoyment science, item ST16Q01: generally fun learning <broad science> topics. enjoy2 indicator enjoyment science, item ST16Q02: like reading <broad science>. enjoy3 indicator enjoyment science, item ST16Q03: happy <broad science> problems. enjoy4 indicator enjoyment science, item ST16Q04: enjoy acquiring new knowledge <broad science>. enjoy5 indicator enjoyment science, item ST16Q05: interested learning <broad science>. academic1 indicator academic self-concept science, item ST37Q01: can easily understand new ideas <school science>. academic2 indicator academic self-concept science, item ST37Q02: Learning advanced <school science> topics easy . academic3 indicator academic self-concept science, item ST37Q03: can usually give good answers <test questions> <school science> topics. academic4 indicator academic self-concept science, item ST37Q04: learn <school science> topics quickly. academic5 indicator academic self-concept science, item ST37Q05: <School science> topics easy . academic6 indicator academic self-concept science, item ST37Q06: taught <school science>, can understand concepts well. career1 indicator career aspirations science, item ST29Q01: like work career involving <broad science>. career2 indicator career aspirations science, item ST29Q02: like study <broad science> <secondary school>. career3 indicator career aspirations science, item ST29Q03: like spend life advanced <broad science>. career4 indicator career aspirations science, item ST29Q04: like work <broad science> projects adult.","code":""},{"path":"/reference/jordan.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Jordan subset of PISA 2006 data — jordan","text":"version dataset, well description gathered documentation 'nlsem' package (https://cran.r-project.org/package=nlsem), difference names variables changed Originally dataset gathered Organisation Economic Co-Operation Development (2009). Pisa 2006: Science competencies tomorrow's world (Tech. Rep.). Paris, France. Obtained : https://www.oecd.org/pisa/pisaproducts/database-pisa2006.htm","code":""},{"path":"/reference/jordan.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Jordan subset of PISA 2006 data — jordan","text":"","code":"if (FALSE) { # \\dontrun{ m1 <- '   ENJ =~ enjoy1 + enjoy2 + enjoy3 + enjoy4 + enjoy5   CAREER =~ career1 + career2 + career3 + career4   SC =~ academic1 + academic2 + academic3 + academic4 + academic5 + academic6   CAREER ~ ENJ + SC + ENJ:ENJ + SC:SC + ENJ:SC '  est <- modsem(m1, data = jordan) } # }"},{"path":"/reference/modsem-package.html","id":null,"dir":"Reference","previous_headings":"","what":"modsem: Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM) — modsem-package","title":"modsem: Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM) — modsem-package","text":"Estimation interaction (.e., moderation) effects latent variables structural equation models (SEM). supported methods : constrained approach (Algina & Moulder, 2001). unconstrained approach (Marsh et al., 2004). residual centering approach (Little et al., 2006). double centering approach (Lin et al., 2010). latent moderated structural equations (LMS) approach (Klein & Moosbrugger, 2000). quasi-maximum likelihood (QML) approach (Klein & Muthén, 2007) (temporarily unavailable) constrained- unconstrained, residual- double centering- approaches estimated via 'lavaan' (Rosseel, 2012), whilst LMS- QML- approaches estimated via modsem self. Alternatively model can estimated via 'Mplus' (Muthén & Muthén, 1998-2017). References: Algina, J., & Moulder, B. C. (2001). doi:10.1207/S15328007SEM0801_3 . \"note estimating Jöreskog-Yang model latent variable interaction using 'LISREL' 8.3.\" Klein, ., & Moosbrugger, H. (2000). doi:10.1007/BF02296338 . \"Maximum likelihood estimation latent interaction effects LMS method.\" Klein, . G., & Muthén, B. O. (2007). doi:10.1080/00273170701710205 . \"Quasi-maximum likelihood estimation structural equation models multiple interaction quadratic effects.\" Lin, G. C., Wen, Z., Marsh, H. W., & Lin, H. S. (2010). doi:10.1080/10705511.2010.488999 . \"Structural equation models latent interactions: Clarification orthogonalizing double-mean-centering strategies.\" Little, T. D., Bovaird, J. ., & Widaman, K. F. (2006). doi:10.1207/s15328007sem1304_1 . \"merits orthogonalizing powered product terms: Implications modeling interactions among latent variables.\" Marsh, H. W., Wen, Z., & Hau, K. T. (2004). doi:10.1037/1082-989X.9.3.275 . \"Structural equation models latent interactions: evaluation alternative estimation strategies indicator construction.\" Muthén, L.K. Muthén, B.O. (1998-2017). \"'Mplus' User’s Guide. Eighth Edition.\" https://www.statmodel.com/. Rosseel Y (2012). doi:10.18637/jss.v048.i02 . \"'lavaan': R Package Structural Equation Modeling.\"","code":""},{"path":[]},{"path":"/reference/modsem-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"modsem: Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM) — modsem-package","text":"Maintainer: Kjell Solem Slupphaug slupphaugkjell@gmail.com (ORCID) contributors: Matthias Mittner matthias.mittner@uit.(ORCID) [contributor]","code":""},{"path":"/reference/modsem.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate interaction effects in structural equation models (SEMs) — modsem","title":"Estimate interaction effects in structural equation models (SEMs) — modsem","text":"modsem() function estimating interaction effects latent variables structural equation models (SEMs). Methods estimating interaction effects SEMs can basically split two frameworks: 1. Product Indicator-based approaches (\"dblcent\", \"rca\", \"uca\", \"ca\", \"pind\") 2. Distributionally based approaches (\"lms\", \"qml\"). product indicator-based approaches, modsem() essentially fancy wrapper lavaan::sem() generates necessary syntax variables estimation models latent product indicators. distributionally based approaches implemented separately estimated using lavaan::sem(), rather using custom functions (largely written C++ performance reasons). greater control, advised use one sub-functions (modsem_pi, modsem_da, modsem_mplus) directly, passing additional arguments via modsem() can lead unexpected behavior.","code":""},{"path":"/reference/modsem.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate interaction effects in structural equation models (SEMs) — modsem","text":"","code":"modsem(model.syntax = NULL, data = NULL, method = \"dblcent\", ...)"},{"path":"/reference/modsem.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate interaction effects in structural equation models (SEMs) — modsem","text":"model.syntax lavaan syntax data dataframe method method use: \"rca\" = residual centering approach (passed lavaan), \"uca\" = unconstrained approach (passed lavaan), \"dblcent\" = double centering approach (passed lavaan), \"pind\" = prod ind approach, constraints centering (passed lavaan), \"lms\" = latent model structural equations (passed lavaan), \"qml\" = quasi maximum likelihood estimation latent model structural equations (passed lavaan), \"custom\" = use parameters specified function call (passed lavaan). ... arguments passed functions depending method (see modsem_pi, modsem_da, modsem_mplus)","code":""},{"path":"/reference/modsem.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate interaction effects in structural equation models (SEMs) — modsem","text":"modsem object class modsem_pi, modsem_da, modsem_mplus","code":""},{"path":"/reference/modsem.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate interaction effects in structural equation models (SEMs) — modsem","text":"","code":"library(modsem) # For more examples, check README and/or GitHub. # One interaction m1 <- '   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z '  # Double centering approach est1 <- modsem(m1, oneInt) summary(est1) #> modsem (version 1.0.4, approach = dblcent): #> lavaan 0.6-19 ended normally after 159 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        60 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                               122.924 #>   Degrees of freedom                               111 #>   P-value (Chi-square)                           0.207 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   X =~                                                 #>     x1                1.000                            #>     x2                0.804    0.013   63.612    0.000 #>     x3                0.916    0.014   67.144    0.000 #>   Y =~                                                 #>     y1                1.000                            #>     y2                0.798    0.007  107.428    0.000 #>     y3                0.899    0.008  112.453    0.000 #>   Z =~                                                 #>     z1                1.000                            #>     z2                0.812    0.013   64.763    0.000 #>     z3                0.882    0.013   67.014    0.000 #>   XZ =~                                                #>     x1z1              1.000                            #>     x2z1              0.805    0.013   60.636    0.000 #>     x3z1              0.877    0.014   62.680    0.000 #>     x1z2              0.793    0.013   59.343    0.000 #>     x2z2              0.646    0.015   43.672    0.000 #>     x3z2              0.706    0.016   44.292    0.000 #>     x1z3              0.887    0.014   63.700    0.000 #>     x2z3              0.716    0.016   45.645    0.000 #>     x3z3              0.781    0.017   45.339    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   Y ~                                                  #>     X                 0.675    0.027   25.379    0.000 #>     Z                 0.561    0.026   21.606    0.000 #>     XZ                0.702    0.027   26.360    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>  .x1z1 ~~                                              #>    .x2z2              0.000                            #>    .x2z3              0.000                            #>    .x3z2              0.000                            #>    .x3z3              0.000                            #>  .x2z1 ~~                                              #>    .x1z2              0.000                            #>  .x1z2 ~~                                              #>    .x2z3              0.000                            #>  .x3z1 ~~                                              #>    .x1z2              0.000                            #>  .x1z2 ~~                                              #>    .x3z3              0.000                            #>  .x2z1 ~~                                              #>    .x1z3              0.000                            #>  .x2z2 ~~                                              #>    .x1z3              0.000                            #>  .x3z1 ~~                                              #>    .x1z3              0.000                            #>  .x3z2 ~~                                              #>    .x1z3              0.000                            #>  .x2z1 ~~                                              #>    .x3z2              0.000                            #>    .x3z3              0.000                            #>  .x3z1 ~~                                              #>    .x2z2              0.000                            #>  .x2z2 ~~                                              #>    .x3z3              0.000                            #>  .x3z1 ~~                                              #>    .x2z3              0.000                            #>  .x3z2 ~~                                              #>    .x2z3              0.000                            #>  .x1z1 ~~                                              #>    .x1z2              0.115    0.008   14.802    0.000 #>    .x1z3              0.114    0.008   13.947    0.000 #>    .x2z1              0.125    0.008   16.095    0.000 #>    .x3z1              0.140    0.009   16.135    0.000 #>  .x1z2 ~~                                              #>    .x1z3              0.103    0.007   14.675    0.000 #>    .x2z2              0.128    0.006   20.850    0.000 #>    .x3z2              0.146    0.007   21.243    0.000 #>  .x1z3 ~~                                              #>    .x2z3              0.116    0.007   17.818    0.000 #>    .x3z3              0.135    0.007   18.335    0.000 #>  .x2z1 ~~                                              #>    .x2z2              0.135    0.006   20.905    0.000 #>    .x2z3              0.145    0.007   21.145    0.000 #>    .x3z1              0.114    0.007   16.058    0.000 #>  .x2z2 ~~                                              #>    .x2z3              0.117    0.006   20.419    0.000 #>    .x3z2              0.116    0.006   20.586    0.000 #>  .x2z3 ~~                                              #>    .x3z3              0.109    0.006   18.059    0.000 #>  .x3z1 ~~                                              #>    .x3z2              0.138    0.007   19.331    0.000 #>    .x3z3              0.158    0.008   20.269    0.000 #>  .x3z2 ~~                                              #>    .x3z3              0.131    0.007   19.958    0.000 #>   X ~~                                                 #>     Z                 0.201    0.024    8.271    0.000 #>     XZ                0.016    0.025    0.628    0.530 #>   Z ~~                                                 #>     XZ                0.062    0.025    2.449    0.014 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .x1                0.160    0.009   17.871    0.000 #>    .x2                0.162    0.007   22.969    0.000 #>    .x3                0.163    0.008   20.161    0.000 #>    .y1                0.159    0.009   17.896    0.000 #>    .y2                0.154    0.007   22.640    0.000 #>    .y3                0.164    0.008   20.698    0.000 #>    .z1                0.168    0.009   18.143    0.000 #>    .z2                0.158    0.007   22.264    0.000 #>    .z3                0.158    0.008   20.389    0.000 #>    .x1z1              0.311    0.014   22.227    0.000 #>    .x2z1              0.292    0.011   27.287    0.000 #>    .x3z1              0.327    0.012   26.275    0.000 #>    .x1z2              0.290    0.011   26.910    0.000 #>    .x2z2              0.239    0.008   29.770    0.000 #>    .x3z2              0.270    0.009   29.117    0.000 #>    .x1z3              0.272    0.012   23.586    0.000 #>    .x2z3              0.245    0.009   27.979    0.000 #>    .x3z3              0.297    0.011   28.154    0.000 #>     X                 0.981    0.036   26.895    0.000 #>    .Y                 0.990    0.038   25.926    0.000 #>     Z                 1.016    0.038   26.856    0.000 #>     XZ                1.045    0.044   24.004    0.000 #>   if (FALSE) { # \\dontrun{ # The Constrained Approach est1_ca <- modsem(m1, oneInt, method = \"ca\") summary(est1_ca)  # LMS approach est1_lms <- modsem(m1, oneInt, method = \"lms\") summary(est1_lms)  # QML approach est1_qml <- modsem(m1, oneInt, method = \"qml\") summary(est1_qml) } # }  # Theory Of Planned Behavior tpb <- ' # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ INT:PBC '  # Double centering approach est_tpb <- modsem(tpb, data = TPB) summary(est_tpb) #> modsem (version 1.0.4, approach = dblcent): #> lavaan 0.6-19 ended normally after 171 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        78 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                               207.615 #>   Degrees of freedom                               222 #>   P-value (Chi-square)                           0.747 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   ATT =~                                               #>     att1              1.000                            #>     att2              0.878    0.012   71.509    0.000 #>     att3              0.789    0.012   66.368    0.000 #>     att4              0.695    0.011   61.017    0.000 #>     att5              0.887    0.013   70.884    0.000 #>   SN =~                                                #>     sn1               1.000                            #>     sn2               0.889    0.017   52.553    0.000 #>   PBC =~                                               #>     pbc1              1.000                            #>     pbc2              0.912    0.013   69.500    0.000 #>     pbc3              0.801    0.012   65.830    0.000 #>   INT =~                                               #>     int1              1.000                            #>     int2              0.914    0.016   58.982    0.000 #>     int3              0.808    0.015   55.547    0.000 #>   BEH =~                                               #>     b1                1.000                            #>     b2                0.960    0.030   31.561    0.000 #>   INTPBC =~                                            #>     int1pbc1          1.000                            #>     int2pbc1          0.931    0.015   63.809    0.000 #>     int3pbc1          0.774    0.013   60.107    0.000 #>     int1pbc2          0.893    0.013   68.173    0.000 #>     int2pbc2          0.826    0.017   48.845    0.000 #>     int3pbc2          0.690    0.015   45.300    0.000 #>     int1pbc3          0.799    0.012   67.008    0.000 #>     int2pbc3          0.738    0.015   47.809    0.000 #>     int3pbc3          0.622    0.014   45.465    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   INT ~                                                #>     ATT               0.213    0.026    8.170    0.000 #>     SN                0.177    0.028    6.416    0.000 #>     PBC               0.217    0.030    7.340    0.000 #>   BEH ~                                                #>     INT               0.191    0.024    7.817    0.000 #>     PBC               0.230    0.022   10.507    0.000 #>     INTPBC            0.204    0.018   11.425    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>  .int1pbc1 ~~                                          #>    .int2pbc2          0.000                            #>    .int2pbc3          0.000                            #>    .int3pbc2          0.000                            #>    .int3pbc3          0.000                            #>  .int2pbc1 ~~                                          #>    .int1pbc2          0.000                            #>  .int1pbc2 ~~                                          #>    .int2pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int1pbc2          0.000                            #>  .int1pbc2 ~~                                          #>    .int3pbc3          0.000                            #>  .int2pbc1 ~~                                          #>    .int1pbc3          0.000                            #>  .int2pbc2 ~~                                          #>    .int1pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int1pbc3          0.000                            #>  .int3pbc2 ~~                                          #>    .int1pbc3          0.000                            #>  .int2pbc1 ~~                                          #>    .int3pbc2          0.000                            #>    .int3pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int2pbc2          0.000                            #>  .int2pbc2 ~~                                          #>    .int3pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int2pbc3          0.000                            #>  .int3pbc2 ~~                                          #>    .int2pbc3          0.000                            #>  .int1pbc1 ~~                                          #>    .int1pbc2          0.126    0.009   14.768    0.000 #>    .int1pbc3          0.102    0.007   13.794    0.000 #>    .int2pbc1          0.104    0.007   14.608    0.000 #>    .int3pbc1          0.091    0.006   14.109    0.000 #>  .int1pbc2 ~~                                          #>    .int1pbc3          0.095    0.007   13.852    0.000 #>    .int2pbc2          0.128    0.007   19.320    0.000 #>    .int3pbc2          0.119    0.006   19.402    0.000 #>  .int1pbc3 ~~                                          #>    .int2pbc3          0.110    0.006   19.911    0.000 #>    .int3pbc3          0.097    0.005   19.415    0.000 #>  .int2pbc1 ~~                                          #>    .int2pbc2          0.152    0.008   18.665    0.000 #>    .int2pbc3          0.138    0.007   18.779    0.000 #>    .int3pbc1          0.082    0.006   13.951    0.000 #>  .int2pbc2 ~~                                          #>    .int2pbc3          0.121    0.007   18.361    0.000 #>    .int3pbc2          0.104    0.005   19.047    0.000 #>  .int2pbc3 ~~                                          #>    .int3pbc3          0.087    0.005   19.180    0.000 #>  .int3pbc1 ~~                                          #>    .int3pbc2          0.139    0.007   21.210    0.000 #>    .int3pbc3          0.123    0.006   21.059    0.000 #>  .int3pbc2 ~~                                          #>    .int3pbc3          0.114    0.005   21.021    0.000 #>   ATT ~~                                               #>     SN                0.629    0.029   21.977    0.000 #>     PBC               0.678    0.029   23.721    0.000 #>     INTPBC            0.086    0.024    3.519    0.000 #>   SN ~~                                                #>     PBC               0.678    0.029   23.338    0.000 #>     INTPBC            0.055    0.025    2.230    0.026 #>   PBC ~~                                               #>     INTPBC            0.087    0.024    3.609    0.000 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .att1              0.167    0.007   23.528    0.000 #>    .att2              0.150    0.006   24.693    0.000 #>    .att3              0.160    0.006   26.378    0.000 #>    .att4              0.163    0.006   27.649    0.000 #>    .att5              0.159    0.006   24.930    0.000 #>    .sn1               0.178    0.015   12.110    0.000 #>    .sn2               0.156    0.012   13.221    0.000 #>    .pbc1              0.145    0.008   18.440    0.000 #>    .pbc2              0.160    0.007   21.547    0.000 #>    .pbc3              0.154    0.007   23.716    0.000 #>    .int1              0.158    0.009   18.152    0.000 #>    .int2              0.160    0.008   20.345    0.000 #>    .int3              0.167    0.007   23.414    0.000 #>    .b1                0.186    0.018   10.058    0.000 #>    .b2                0.135    0.017    8.080    0.000 #>    .int1pbc1          0.266    0.013   20.971    0.000 #>    .int2pbc1          0.292    0.012   24.421    0.000 #>    .int3pbc1          0.251    0.010   26.305    0.000 #>    .int1pbc2          0.290    0.012   24.929    0.000 #>    .int2pbc2          0.269    0.010   26.701    0.000 #>    .int3pbc2          0.253    0.009   29.445    0.000 #>    .int1pbc3          0.223    0.009   24.431    0.000 #>    .int2pbc3          0.234    0.008   27.633    0.000 #>    .int3pbc3          0.203    0.007   29.288    0.000 #>     ATT               0.998    0.037   27.138    0.000 #>     SN                0.987    0.039   25.394    0.000 #>     PBC               0.962    0.035   27.260    0.000 #>    .INT               0.490    0.020   24.638    0.000 #>    .BEH               0.455    0.023   20.068    0.000 #>     INTPBC            1.020    0.041   24.612    0.000 #>   if (FALSE) { # \\dontrun{ # The Constrained Approach est_tpb_ca <- modsem(tpb, data = TPB, method = \"ca\") summary(est_tpb_ca)  # LMS approach est_tpb_lms <- modsem(tpb, data = TPB, method = \"lms\") summary(est_tpb_lms)  # QML approach est_tpb_qml <- modsem(tpb, data = TPB, method = \"qml\") summary(est_tpb_qml) } # }"},{"path":"/reference/modsem_da.html","id":null,"dir":"Reference","previous_headings":"","what":"Interaction between latent variables using lms and qml approaches — modsem_da","title":"Interaction between latent variables using lms and qml approaches — modsem_da","text":"modsem_da() function estimating interaction effects latent variables structural equation models (SEMs) using distributional analytic (DA) approaches. Methods estimating interaction effects SEMs can basically split two frameworks: 1. Product Indicator-based approaches (\"dblcent\", \"rca\", \"uca\", \"ca\", \"pind\") 2. Distributionally based approaches (\"lms\", \"qml\"). modsem_da() handles latter can estimate models using QML LMS, necessary syntax, variables estimation models latent product indicators. NOTE: Run default_settings_da see default arguments.","code":""},{"path":"/reference/modsem_da.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interaction between latent variables using lms and qml approaches — modsem_da","text":"","code":"modsem_da(   model.syntax = NULL,   data = NULL,   method = \"lms\",   verbose = NULL,   optimize = NULL,   nodes = NULL,   convergence = NULL,   optimizer = NULL,   center.data = NULL,   standardize.data = NULL,   standardize.out = NULL,   standardize = NULL,   mean.observed = NULL,   cov.syntax = NULL,   double = NULL,   calc.se = NULL,   FIM = NULL,   EFIM.S = NULL,   OFIM.hessian = NULL,   EFIM.parametric = NULL,   robust.se = NULL,   max.iter = NULL,   max.step = NULL,   fix.estep = NULL,   start = NULL,   epsilon = NULL,   quad.range = NULL,   n.threads = NULL,   ... )"},{"path":"/reference/modsem_da.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interaction between latent variables using lms and qml approaches — modsem_da","text":"model.syntax lavaan syntax data dataframe method method use: \"lms\" = latent model structural equations (passed lavaan). \"qml\" = quasi maximum likelihood estimation latent model structural equations (passed lavaan). verbose estimation progress shown optimize starting parameters optimized nodes number quadrature nodes (points integration) used lms, increased number gives better estimates slower computation. many needed depends complexity model. simple models, somewhere 16-24 nodes enough; complex models, higher numbers may needed. models interaction effect endogenous exogenous variable, number nodes least 32, practically (e.g., ordinal/skewed data), 32 recommended. cases data non-normal, might better use qml approach instead. large numbers nodes, might want change 'quad.range' argument. convergence convergence criterion. Lower values give better estimates slower computation. optimizer optimizer use, can either \"nlminb\" \"L-BFGS-B\". LMS, \"nlminb\" recommended. QML, \"L-BFGS-B\" may faster large number iterations, slower iterations. center.data data centered fitting model standardize.data data scaled fitting model, overridden standardize standardize set TRUE. NOTE: recommended estimate model normally standardize output using standardized_estimates. standardize.output standardized (note alter relationships parameter constraints since parameters scaled unevenly, even label). alter estimation model, output. NOTE: recommended estimate model normally standardize output using standardized_estimates. standardize standardize data fitting model, remove mean structure observed variables, standardize output. Note standardize.data, mean.observed, standardize.overridden standardize standardize set TRUE. NOTE: recommended estimate model normally standardize output using standardized_estimates. mean.observed mean structure observed variables estimated? overridden standardize standardize set TRUE. NOTE: recommended unless know . cov.syntax model syntax implied covariance matrix (see vignette(\"interaction_two_etas\", \"modsem\")) double try double number dimensions integration used LMS, extremely slow similar mplus. calc.se standard errors computed? NOTE: FALSE, information matrix computed either. FIM Fisher information matrix calculated using observed expected values? Must either \"observed\" \"expected\". EFIM.S expected Fisher information matrix computed, EFIM.S selects sample size generated data. OFIM.hessian observed Fisher information computed using Hessian? FALSE, computed using gradient. EFIM.parametric data calculating expected Fisher information matrix simulated parametrically (simulated based assumptions implied parameters model), non-parametrically (stochastically sampled)? believe normality assumptions violated, EFIM.parametric = FALSE might better option. robust.se robust standard errors computed? Meant used QML, can unreliable LMS approach. max.iter maximum number iterations. max.step maximum steps M-step EM algorithm (LMS). fix.estep TRUE, E-step fixed, prior probabilities set best prior probabilities, log-likelihood decreases 30 iterations. start starting parameters. epsilon finite difference numerical derivatives. quad.range range z-scores perform numerical integration LMS using Gaussian-Hermite Quadratures. default Inf, f(t) integrated -Inf Inf, likely inefficient pointless large number nodes. Nodes outside +/- quad.range ignored. n.threads number cores use parallel processing. NULL, use <= 2 threads. integer specified, use number threads (e.g., n.threads = 4 use 4 threads). \"default\", use default number threads (2). \"max\", use available threads, \"min\" use 1 thread. ... additional arguments passed estimation function.","code":""},{"path":"/reference/modsem_da.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interaction between latent variables using lms and qml approaches — modsem_da","text":"modsem_da object","code":""},{"path":"/reference/modsem_da.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interaction between latent variables using lms and qml approaches — modsem_da","text":"","code":"library(modsem) # For more examples, check README and/or GitHub. # One interaction m1 <- \"   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z \"  if (FALSE) { # \\dontrun{ # QML Approach est1 <- modsem_da(m1, oneInt, method = \"qml\") summary(est1)  # Theory Of Planned Behavior tpb <- \" # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   # Covariances   ATT ~~ SN + PBC   PBC ~~ SN   # Causal Relationships   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ INT:PBC \"  # LMS Approach estTpb <- modsem_da(tpb, data = TPB, method = lms) summary(estTpb) } # }"},{"path":"/reference/modsem_inspect.html","id":null,"dir":"Reference","previous_headings":"","what":"Inspect model information — modsem_inspect","title":"Inspect model information — modsem_inspect","text":"function used inspect fittet object. similar `lavInspect()` argument '' decides inspect","code":""},{"path":"/reference/modsem_inspect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inspect model information — modsem_inspect","text":"","code":"modsem_inspect(object, what = NULL, ...)"},{"path":"/reference/modsem_inspect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inspect model information — modsem_inspect","text":"object fittet model inspect inspect ... Additional arguments passed functions","code":""},{"path":"/reference/modsem_inspect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inspect model information — modsem_inspect","text":"`modsem_da`, `modsem_lavaan` `modsem_lavaan`, just wrapper `lavInspect()` `modsem_da` “ can either \"\", \"matrices\", \"optim\", just name extract.","code":""},{"path":"/reference/modsem_mplus.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation latent interactions through mplus — modsem_mplus","title":"Estimation latent interactions through mplus — modsem_mplus","text":"Estimation latent interactions mplus","code":""},{"path":"/reference/modsem_mplus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation latent interactions through mplus — modsem_mplus","text":"","code":"modsem_mplus(   model.syntax,   data,   estimator = \"ml\",   type = \"random\",   algorithm = \"integration\",   process = \"8\",   ... )"},{"path":"/reference/modsem_mplus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation latent interactions through mplus — modsem_mplus","text":"model.syntax lavaan/modsem syntax data dataset estimator estimator argument passed mplus type type argument passed mplus algorithm algorithm argument passed mplus process process argument passed mplus ... arguments passed functions","code":""},{"path":"/reference/modsem_mplus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation latent interactions through mplus — modsem_mplus","text":"modsem_mplus object","code":""},{"path":"/reference/modsem_mplus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation latent interactions through mplus — modsem_mplus","text":"","code":"# Theory Of Planned Behavior tpb <- ' # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   # Covariances   ATT ~~ SN + PBC   PBC ~~ SN   # Causal Relationsships   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ INT:PBC '  if (FALSE) { # \\dontrun{ estTpbMplus <- modsem_mplus(tpb, data = TPB) summary(estTpbLMS) } # }"},{"path":"/reference/modsem_pi.html","id":null,"dir":"Reference","previous_headings":"","what":"Interaction between latent variables using product indicators — modsem_pi","title":"Interaction between latent variables using product indicators — modsem_pi","text":"modsem_pi() function estimating interaction effects latent variables, structural equation models (SEMs), using product indicators. Methods estimating interaction effects SEMs can basically split two frameworks: 1. Product Indicator based approaches (\"dblcent\", \"rca\", \"uca\", \"ca\", \"pind\"), 2. Distributionally based approaches (\"lms\", \"qml\"). modsem_pi() essentially fancy wrapper lavaan::sem() generates necessary syntax variables estimation models latent product indicators. Use default_settings_pi() get default settings different methods.","code":""},{"path":"/reference/modsem_pi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interaction between latent variables using product indicators — modsem_pi","text":"","code":"modsem_pi(   model.syntax = NULL,   data = NULL,   method = \"dblcent\",   match = NULL,   standardize.data = FALSE,   center.data = FALSE,   first.loading.fixed = TRUE,   center.before = NULL,   center.after = NULL,   residuals.prods = NULL,   residual.cov.syntax = NULL,   constrained.prod.mean = NULL,   constrained.loadings = NULL,   constrained.var = NULL,   constrained.res.cov.method = NULL,   auto.scale = \"none\",   auto.center = \"none\",   estimator = \"ML\",   group = NULL,   run = TRUE,   suppress.warnings.lavaan = FALSE,   suppress.warnings.match = FALSE,   ... )"},{"path":"/reference/modsem_pi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interaction between latent variables using product indicators — modsem_pi","text":"model.syntax lavaan syntax data dataframe method method use: \"rca\" = residual centering approach (passed lavaan), \"uca\" = unconstrained approach (passed lavaan), \"dblcent\" = double centering approach (passed lavaan), \"pind\" = prod ind approach, constraints centering (passed lavaan), \"custom\" = use parameters specified function call (passed lavaan) match product indicators created using match-strategy standardize.data data scaled fitting model center.data data centered fitting model first.loading.fixed first factor loading latent product fixed one? center.indicators products centered computing products (overwritten method, method != NULL) center.indicator products centered computed? residuals.prods indicator products centered using residuals (overwritten method, method != NULL) residual.cov.syntax syntax residual covariances produced (overwritten method, method != NULL) constrained.prod.mean syntax product mean produced (overwritten method, method != NULL) constrained.loadings syntax constrained loadings produced (overwritten method, method != NULL) constrained.var syntax constrained variances produced (overwritten method, method != NULL) constrained.res.cov.method method constraining residual covariances auto.scale methods scaled automatically (usually useful) auto.center methods centered automatically (usually useful) estimator estimator use lavaan group group variable multigroup analysis run model run via lavaan, FALSE modified syntax data returned suppress.warnings.lavaan warnings lavaan suppressed? suppress.warnings.match warnings match suppressed? ... arguments passed functions, e.g., lavaan","code":""},{"path":"/reference/modsem_pi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interaction between latent variables using product indicators — modsem_pi","text":"modsem object","code":""},{"path":"/reference/modsem_pi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interaction between latent variables using product indicators — modsem_pi","text":"","code":"library(modsem) # For more examples, check README and/or GitHub. # One interaction m1 <- '   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z '  # Double centering approach est1 <- modsem_pi(m1, oneInt) summary(est1) #> modsem (version 1.0.4, approach = dblcent): #> lavaan 0.6-19 ended normally after 159 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        60 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                               122.924 #>   Degrees of freedom                               111 #>   P-value (Chi-square)                           0.207 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   X =~                                                 #>     x1                1.000                            #>     x2                0.804    0.013   63.612    0.000 #>     x3                0.916    0.014   67.144    0.000 #>   Y =~                                                 #>     y1                1.000                            #>     y2                0.798    0.007  107.428    0.000 #>     y3                0.899    0.008  112.453    0.000 #>   Z =~                                                 #>     z1                1.000                            #>     z2                0.812    0.013   64.763    0.000 #>     z3                0.882    0.013   67.014    0.000 #>   XZ =~                                                #>     x1z1              1.000                            #>     x2z1              0.805    0.013   60.636    0.000 #>     x3z1              0.877    0.014   62.680    0.000 #>     x1z2              0.793    0.013   59.343    0.000 #>     x2z2              0.646    0.015   43.672    0.000 #>     x3z2              0.706    0.016   44.292    0.000 #>     x1z3              0.887    0.014   63.700    0.000 #>     x2z3              0.716    0.016   45.645    0.000 #>     x3z3              0.781    0.017   45.339    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   Y ~                                                  #>     X                 0.675    0.027   25.379    0.000 #>     Z                 0.561    0.026   21.606    0.000 #>     XZ                0.702    0.027   26.360    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>  .x1z1 ~~                                              #>    .x2z2              0.000                            #>    .x2z3              0.000                            #>    .x3z2              0.000                            #>    .x3z3              0.000                            #>  .x2z1 ~~                                              #>    .x1z2              0.000                            #>  .x1z2 ~~                                              #>    .x2z3              0.000                            #>  .x3z1 ~~                                              #>    .x1z2              0.000                            #>  .x1z2 ~~                                              #>    .x3z3              0.000                            #>  .x2z1 ~~                                              #>    .x1z3              0.000                            #>  .x2z2 ~~                                              #>    .x1z3              0.000                            #>  .x3z1 ~~                                              #>    .x1z3              0.000                            #>  .x3z2 ~~                                              #>    .x1z3              0.000                            #>  .x2z1 ~~                                              #>    .x3z2              0.000                            #>    .x3z3              0.000                            #>  .x3z1 ~~                                              #>    .x2z2              0.000                            #>  .x2z2 ~~                                              #>    .x3z3              0.000                            #>  .x3z1 ~~                                              #>    .x2z3              0.000                            #>  .x3z2 ~~                                              #>    .x2z3              0.000                            #>  .x1z1 ~~                                              #>    .x1z2              0.115    0.008   14.802    0.000 #>    .x1z3              0.114    0.008   13.947    0.000 #>    .x2z1              0.125    0.008   16.095    0.000 #>    .x3z1              0.140    0.009   16.135    0.000 #>  .x1z2 ~~                                              #>    .x1z3              0.103    0.007   14.675    0.000 #>    .x2z2              0.128    0.006   20.850    0.000 #>    .x3z2              0.146    0.007   21.243    0.000 #>  .x1z3 ~~                                              #>    .x2z3              0.116    0.007   17.818    0.000 #>    .x3z3              0.135    0.007   18.335    0.000 #>  .x2z1 ~~                                              #>    .x2z2              0.135    0.006   20.905    0.000 #>    .x2z3              0.145    0.007   21.145    0.000 #>    .x3z1              0.114    0.007   16.058    0.000 #>  .x2z2 ~~                                              #>    .x2z3              0.117    0.006   20.419    0.000 #>    .x3z2              0.116    0.006   20.586    0.000 #>  .x2z3 ~~                                              #>    .x3z3              0.109    0.006   18.059    0.000 #>  .x3z1 ~~                                              #>    .x3z2              0.138    0.007   19.331    0.000 #>    .x3z3              0.158    0.008   20.269    0.000 #>  .x3z2 ~~                                              #>    .x3z3              0.131    0.007   19.958    0.000 #>   X ~~                                                 #>     Z                 0.201    0.024    8.271    0.000 #>     XZ                0.016    0.025    0.628    0.530 #>   Z ~~                                                 #>     XZ                0.062    0.025    2.449    0.014 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .x1                0.160    0.009   17.871    0.000 #>    .x2                0.162    0.007   22.969    0.000 #>    .x3                0.163    0.008   20.161    0.000 #>    .y1                0.159    0.009   17.896    0.000 #>    .y2                0.154    0.007   22.640    0.000 #>    .y3                0.164    0.008   20.698    0.000 #>    .z1                0.168    0.009   18.143    0.000 #>    .z2                0.158    0.007   22.264    0.000 #>    .z3                0.158    0.008   20.389    0.000 #>    .x1z1              0.311    0.014   22.227    0.000 #>    .x2z1              0.292    0.011   27.287    0.000 #>    .x3z1              0.327    0.012   26.275    0.000 #>    .x1z2              0.290    0.011   26.910    0.000 #>    .x2z2              0.239    0.008   29.770    0.000 #>    .x3z2              0.270    0.009   29.117    0.000 #>    .x1z3              0.272    0.012   23.586    0.000 #>    .x2z3              0.245    0.009   27.979    0.000 #>    .x3z3              0.297    0.011   28.154    0.000 #>     X                 0.981    0.036   26.895    0.000 #>    .Y                 0.990    0.038   25.926    0.000 #>     Z                 1.016    0.038   26.856    0.000 #>     XZ                1.045    0.044   24.004    0.000 #>   if (FALSE) { # \\dontrun{ # The Constrained Approach est1Constrained <- modsem_pi(m1, oneInt, method = \"ca\") summary(est1Constrained) } # }  # Theory Of Planned Behavior tpb <- ' # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   # Covariances   ATT ~~ SN + PBC   PBC ~~ SN   # Causal Relationships   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ INT:PBC '  # Double centering approach estTpb <- modsem_pi(tpb, data = TPB) summary(estTpb) #> modsem (version 1.0.4, approach = dblcent): #> lavaan 0.6-19 ended normally after 169 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        78 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                               207.615 #>   Degrees of freedom                               222 #>   P-value (Chi-square)                           0.747 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   ATT =~                                               #>     att1              1.000                            #>     att2              0.878    0.012   71.509    0.000 #>     att3              0.789    0.012   66.368    0.000 #>     att4              0.695    0.011   61.017    0.000 #>     att5              0.887    0.013   70.884    0.000 #>   SN =~                                                #>     sn1               1.000                            #>     sn2               0.889    0.017   52.553    0.000 #>   PBC =~                                               #>     pbc1              1.000                            #>     pbc2              0.912    0.013   69.500    0.000 #>     pbc3              0.801    0.012   65.830    0.000 #>   INT =~                                               #>     int1              1.000                            #>     int2              0.914    0.016   58.982    0.000 #>     int3              0.808    0.015   55.547    0.000 #>   BEH =~                                               #>     b1                1.000                            #>     b2                0.960    0.030   31.561    0.000 #>   INTPBC =~                                            #>     int1pbc1          1.000                            #>     int2pbc1          0.931    0.015   63.809    0.000 #>     int3pbc1          0.774    0.013   60.107    0.000 #>     int1pbc2          0.893    0.013   68.172    0.000 #>     int2pbc2          0.826    0.017   48.845    0.000 #>     int3pbc2          0.690    0.015   45.300    0.000 #>     int1pbc3          0.799    0.012   67.008    0.000 #>     int2pbc3          0.738    0.015   47.809    0.000 #>     int3pbc3          0.622    0.014   45.465    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   INT ~                                                #>     ATT               0.213    0.026    8.170    0.000 #>     SN                0.177    0.028    6.416    0.000 #>     PBC               0.217    0.030    7.340    0.000 #>   BEH ~                                                #>     INT               0.191    0.024    7.817    0.000 #>     PBC               0.230    0.022   10.507    0.000 #>     INTPBC            0.204    0.018   11.425    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   ATT ~~                                               #>     SN                0.629    0.029   21.977    0.000 #>     PBC               0.678    0.029   23.721    0.000 #>   SN ~~                                                #>     PBC               0.678    0.029   23.338    0.000 #>  .int1pbc1 ~~                                          #>    .int2pbc2          0.000                            #>    .int2pbc3          0.000                            #>    .int3pbc2          0.000                            #>    .int3pbc3          0.000                            #>  .int2pbc1 ~~                                          #>    .int1pbc2          0.000                            #>  .int1pbc2 ~~                                          #>    .int2pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int1pbc2          0.000                            #>  .int1pbc2 ~~                                          #>    .int3pbc3          0.000                            #>  .int2pbc1 ~~                                          #>    .int1pbc3          0.000                            #>  .int2pbc2 ~~                                          #>    .int1pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int1pbc3          0.000                            #>  .int3pbc2 ~~                                          #>    .int1pbc3          0.000                            #>  .int2pbc1 ~~                                          #>    .int3pbc2          0.000                            #>    .int3pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int2pbc2          0.000                            #>  .int2pbc2 ~~                                          #>    .int3pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int2pbc3          0.000                            #>  .int3pbc2 ~~                                          #>    .int2pbc3          0.000                            #>  .int1pbc1 ~~                                          #>    .int1pbc2          0.126    0.009   14.768    0.000 #>    .int1pbc3          0.102    0.007   13.794    0.000 #>    .int2pbc1          0.104    0.007   14.608    0.000 #>    .int3pbc1          0.091    0.006   14.109    0.000 #>  .int1pbc2 ~~                                          #>    .int1pbc3          0.095    0.007   13.852    0.000 #>    .int2pbc2          0.128    0.007   19.320    0.000 #>    .int3pbc2          0.119    0.006   19.402    0.000 #>  .int1pbc3 ~~                                          #>    .int2pbc3          0.110    0.006   19.911    0.000 #>    .int3pbc3          0.097    0.005   19.415    0.000 #>  .int2pbc1 ~~                                          #>    .int2pbc2          0.152    0.008   18.665    0.000 #>    .int2pbc3          0.138    0.007   18.779    0.000 #>    .int3pbc1          0.082    0.006   13.951    0.000 #>  .int2pbc2 ~~                                          #>    .int2pbc3          0.121    0.007   18.361    0.000 #>    .int3pbc2          0.104    0.005   19.047    0.000 #>  .int2pbc3 ~~                                          #>    .int3pbc3          0.087    0.005   19.180    0.000 #>  .int3pbc1 ~~                                          #>    .int3pbc2          0.139    0.007   21.210    0.000 #>    .int3pbc3          0.123    0.006   21.059    0.000 #>  .int3pbc2 ~~                                          #>    .int3pbc3          0.114    0.005   21.021    0.000 #>   ATT ~~                                               #>     INTPBC            0.086    0.024    3.519    0.000 #>   SN ~~                                                #>     INTPBC            0.055    0.025    2.230    0.026 #>   PBC ~~                                               #>     INTPBC            0.087    0.024    3.609    0.000 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .att1              0.167    0.007   23.528    0.000 #>    .att2              0.150    0.006   24.693    0.000 #>    .att3              0.160    0.006   26.378    0.000 #>    .att4              0.163    0.006   27.649    0.000 #>    .att5              0.159    0.006   24.930    0.000 #>    .sn1               0.178    0.015   12.110    0.000 #>    .sn2               0.156    0.012   13.221    0.000 #>    .pbc1              0.145    0.008   18.440    0.000 #>    .pbc2              0.160    0.007   21.547    0.000 #>    .pbc3              0.154    0.007   23.716    0.000 #>    .int1              0.158    0.009   18.152    0.000 #>    .int2              0.160    0.008   20.345    0.000 #>    .int3              0.167    0.007   23.414    0.000 #>    .b1                0.186    0.018   10.058    0.000 #>    .b2                0.135    0.017    8.080    0.000 #>    .int1pbc1          0.266    0.013   20.971    0.000 #>    .int2pbc1          0.292    0.012   24.421    0.000 #>    .int3pbc1          0.251    0.010   26.305    0.000 #>    .int1pbc2          0.290    0.012   24.929    0.000 #>    .int2pbc2          0.269    0.010   26.701    0.000 #>    .int3pbc2          0.253    0.009   29.445    0.000 #>    .int1pbc3          0.223    0.009   24.431    0.000 #>    .int2pbc3          0.234    0.008   27.633    0.000 #>    .int3pbc3          0.203    0.007   29.288    0.000 #>     ATT               0.998    0.037   27.138    0.000 #>     SN                0.987    0.039   25.394    0.000 #>     PBC               0.962    0.035   27.260    0.000 #>    .INT               0.490    0.020   24.638    0.000 #>    .BEH               0.455    0.023   20.068    0.000 #>     INTPBC            1.020    0.041   24.612    0.000 #>   if (FALSE) { # \\dontrun{ # The Constrained Approach estTpbConstrained <- modsem_pi(tpb, data = TPB, method = \"ca\") summary(estTpbConstrained) } # }"},{"path":"/reference/modsemify.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate parameter table for lavaan syntax — modsemify","title":"Generate parameter table for lavaan syntax — modsemify","text":"Generate parameter table lavaan syntax","code":""},{"path":"/reference/modsemify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate parameter table for lavaan syntax — modsemify","text":"","code":"modsemify(syntax)"},{"path":"/reference/modsemify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate parameter table for lavaan syntax — modsemify","text":"syntax model syntax","code":""},{"path":"/reference/modsemify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate parameter table for lavaan syntax — modsemify","text":"data.frame columns lhs, op, rhs, mod","code":""},{"path":"/reference/modsemify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate parameter table for lavaan syntax — modsemify","text":"","code":"library(modsem) m1 <- '   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z ' modsemify(m1) #>    lhs op rhs mod #> 1    X =~  x1     #> 2    X =~  x2     #> 3    X =~  x3     #> 4    Y =~  y1     #> 5    Y =~  y2     #> 6    Y =~  y3     #> 7    Z =~  z1     #> 8    Z =~  z2     #> 9    Z =~  z3     #> 10   Y  ~   X     #> 11   Y  ~   Z     #> 12   Y  ~ X:Z"},{"path":"/reference/multiplyIndicatorsCpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiply indicators — multiplyIndicatorsCpp","title":"Multiply indicators — multiplyIndicatorsCpp","text":"Multiply indicators","code":""},{"path":"/reference/multiplyIndicatorsCpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiply indicators — multiplyIndicatorsCpp","text":"","code":"multiplyIndicatorsCpp(df)"},{"path":"/reference/multiplyIndicatorsCpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiply indicators — multiplyIndicatorsCpp","text":"df data DataFrame","code":""},{"path":"/reference/multiplyIndicatorsCpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiply indicators — multiplyIndicatorsCpp","text":"NumericVector","code":""},{"path":"/reference/oneInt.html","id":null,"dir":"Reference","previous_headings":"","what":"oneInt — oneInt","title":"oneInt — oneInt","text":"simulated dataset one interaction effect","code":""},{"path":"/reference/parameter_estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract parameterEstimates from an estimated model — parameter_estimates","title":"Extract parameterEstimates from an estimated model — parameter_estimates","text":"Extract parameterEstimates estimated model","code":""},{"path":"/reference/parameter_estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract parameterEstimates from an estimated model — parameter_estimates","text":"","code":"parameter_estimates(object, ...)"},{"path":"/reference/parameter_estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract parameterEstimates from an estimated model — parameter_estimates","text":"object object class modsem_pi, modsem_da, modsem_mplus ... Additional arguments passed functions","code":""},{"path":"/reference/plot_interaction.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Interaction Effects — plot_interaction","title":"Plot Interaction Effects — plot_interaction","text":"Plot Interaction Effects","code":""},{"path":"/reference/plot_interaction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Interaction Effects — plot_interaction","text":"","code":"plot_interaction(   x,   z,   y,   xz = NULL,   vals_x = seq(-3, 3, 0.001),   vals_z,   model,   alpha_se = 0.15,   ... )"},{"path":"/reference/plot_interaction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Interaction Effects — plot_interaction","text":"x name variable x-axis z name moderator variable y name outcome variable xz name interaction term. interaction term specified, created using x z. vals_x values x variable plot, values smoother std.error-area vals_z values moderator variable plot. separate regression line (y ~ x | z) plotted value moderator variable model object class modsem_pi, modsem_da, modsem_mplus alpha_se alpha level std.error area ... Additional arguments passed functions","code":""},{"path":"/reference/plot_interaction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Interaction Effects — plot_interaction","text":"ggplot object","code":""},{"path":"/reference/plot_interaction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Interaction Effects — plot_interaction","text":"","code":"library(modsem) if (FALSE) { # \\dontrun{ m1 <- \" # Outer Model   X =~ x1   X =~ x2 + x3   Z =~ z1 + z2 + z3   Y =~ y1 + y2 + y3  # Inner model   Y ~ X + Z + X:Z \" est1 <- modsem(m1, data = oneInt) plot_interaction(\"X\", \"Z\", \"Y\", \"X:Z\", -3:3, c(-0.2, 0), est1)  tpb <- \" # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   # Causal Relationsships   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   # BEH ~ ATT:PBC   BEH ~ PBC:INT   # BEH ~ PBC:PBC \"  est2 <- modsem(tpb, TPB, method = \"lms\") plot_interaction(x = \"INT\", z = \"PBC\", y = \"BEH\", xz = \"PBC:INT\",                  vals_z = c(-0.5, 0.5), model = est2) } # }"},{"path":"/reference/standardized_estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Get standardized estimates — standardized_estimates","title":"Get standardized estimates — standardized_estimates","text":"Get standardized estimates","code":""},{"path":"/reference/standardized_estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get standardized estimates — standardized_estimates","text":"","code":"standardized_estimates(object, ...)"},{"path":"/reference/standardized_estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get standardized estimates — standardized_estimates","text":"object object class modsem_da, modsem_mplus, parTable class data.frame ... Additional arguments passed functions","code":""},{"path":"/reference/standardized_estimates.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get standardized estimates — standardized_estimates","text":"modsem_da, modsem_mplus objects, interaction term standardized var(xz) = 1. interaction term actual variable model, meaning variance. must therefore calculated parameters model. Assuming normality zero-means, variance calculated var(xz) = var(x) * var(z) + cov(x, z)^2. Thus setting variance interaction term 1 'correct' correlation x z zero. means standardized estimates interaction term different using lavaan, since interaction term actual latent variable model, standardized variance 1.","code":""},{"path":"/reference/summary.html","id":null,"dir":"Reference","previous_headings":"","what":"summary for modsem objects — summary.modsem_da","title":"summary for modsem objects — summary.modsem_da","text":"summary modsem objects summary modsem objects summary modsem objects","code":""},{"path":"/reference/summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summary for modsem objects — summary.modsem_da","text":"","code":"# S3 method for class 'modsem_da' summary(   object,   H0 = TRUE,   verbose = interactive(),   r.squared = TRUE,   adjusted.stat = FALSE,   digits = 3,   scientific = FALSE,   ci = FALSE,   standardized = FALSE,   loadings = TRUE,   regressions = TRUE,   covariances = TRUE,   intercepts = !standardized,   variances = TRUE,   var.interaction = FALSE,   ... )  # S3 method for class 'modsem_mplus' summary(   object,   scientific = FALSE,   standardize = FALSE,   ci = FALSE,   digits = 3,   loadings = TRUE,   regressions = TRUE,   covariances = TRUE,   intercepts = TRUE,   variances = TRUE,   ... )  # S3 method for class 'modsem_pi' summary(object, ...)"},{"path":"/reference/summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summary for modsem objects — summary.modsem_da","text":"object modsem object summarized H0 null model estimated (used comparison) verbose print progress estimation null model r.squared calculate R-squared adjusted.stat sample size corrected/adjustes AIC BIC reported? digits number digits print scientific print p-values scientific notation ci print confidence intervals standardized print standardized estimates loadings print loadings regressions print regressions covariances print covariances intercepts print intercepts variances print variances var.interaction FALSE (default) variances interaction terms removed (present) ... arguments passed lavaan::summary() standardize standardize estimates","code":""},{"path":"/reference/summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"summary for modsem objects — summary.modsem_da","text":"","code":"if (FALSE) { # \\dontrun{ m1 <- \"  # Outer Model  X =~ x1 + x2 + x3  Y =~ y1 + y2 + y3  Z =~ z1 + z2 + z3   # Inner model  Y ~ X + Z + X:Z \"  est1 <- modsem(m1, oneInt, \"qml\") summary(est1, ci = TRUE, scientific = TRUE) } # }"},{"path":"/reference/trace_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate formulas for (co-)variance paths using Wright's path tracing rules — trace_path","title":"Estimate formulas for (co-)variance paths using Wright's path tracing rules — trace_path","text":"function estimates path x y using path tracing rules. Note works structural parameters, \"=~\" ignored, unless measurement.model = TRUE. want use measurement model, \"~\" mod column pt.","code":""},{"path":"/reference/trace_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate formulas for (co-)variance paths using Wright's path tracing rules — trace_path","text":"","code":"trace_path(   pt,   x,   y,   parenthesis = TRUE,   missing.cov = FALSE,   measurement.model = FALSE,   maxlen = 100,   ... )"},{"path":"/reference/trace_path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate formulas for (co-)variance paths using Wright's path tracing rules — trace_path","text":"pt data frame columns lhs, op, rhs, mod, modsemify x Source variable y Destination variable parenthesis TRUE, output enclosed parenthesis missing.cov TRUE, covariances missing model syntax added measurement.model TRUE, function use measurement model maxlen Maximum length path aborting ... Additional arguments passed trace_path","code":""},{"path":"/reference/trace_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate formulas for (co-)variance paths using Wright's path tracing rules — trace_path","text":"string estimated path (simplified possible)","code":""},{"path":"/reference/trace_path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate formulas for (co-)variance paths using Wright's path tracing rules — trace_path","text":"","code":"library(modsem) m1 <- '   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z ' pt <- modsemify(m1) trace_path(pt, x = \"Y\", y = \"Y\", missing.cov = TRUE) # variance of Y #> [1] \"(X~~X * Y~X ^ 2 + 2 * X~~Z * Y~X * Y~Z + Y~Z ^ 2 * Z~~Z + Y~~Y)\""},{"path":"/reference/var_interactions.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract or modify parTable from an estimated model with estimated variances of interaction terms — var_interactions","title":"Extract or modify parTable from an estimated model with estimated variances of interaction terms — var_interactions","text":"Extract modify parTable estimated model estimated variances interaction terms","code":""},{"path":"/reference/var_interactions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract or modify parTable from an estimated model with estimated variances of interaction terms — var_interactions","text":"","code":"var_interactions(object, ...)"},{"path":"/reference/var_interactions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract or modify parTable from an estimated model with estimated variances of interaction terms — var_interactions","text":"object object class modsem_da,  modsem_mplus, parTable class data.frame ... Additional arguments passed functions","code":""},{"path":"/reference/vcov_modsem_da.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper for vcov — vcov_modsem_da","title":"Wrapper for vcov — vcov_modsem_da","text":"wrapper vcov, used modsem::vcov_modsem_da, since vcov namespace modsem, stats","code":""},{"path":"/reference/vcov_modsem_da.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper for vcov — vcov_modsem_da","text":"","code":"vcov_modsem_da(object, ...)"},{"path":"/reference/vcov_modsem_da.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper for vcov — vcov_modsem_da","text":"object fittet model inspect ... additional arguments","code":""}]
