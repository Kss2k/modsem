[{"path":"/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to modsem","title":"Contributing to modsem","text":"Thank considering contributing modsem! welcome contributions help improve package estimating interaction effects structural equation modeling (SEM). ensure smooth collaboration, please follow guidelines .","code":""},{"path":[]},{"path":"/CONTRIBUTING.html","id":"fork-and-clone-the-repository","dir":"","previous_headings":"Getting Started","what":"Fork and Clone the Repository","title":"Contributing to modsem","text":"Fork repository GitHub. Clone fork local machine.","code":"git clone https://github.com/your-username/modsem.git cd modsem"},{"path":"/CONTRIBUTING.html","id":"setting-up-your-development-environment","dir":"","previous_headings":"Getting Started","what":"Setting up your Development Environment","title":"Contributing to modsem","text":"Ensure R installed machine. Install package dependencies. Install modsem package local repository.","code":"install.packages(\"devtools\") devtools::install_deps() devtools::install()"},{"path":[]},{"path":"/CONTRIBUTING.html","id":"creating-a-branch","dir":"","previous_headings":"Making Changes","what":"Creating a Branch","title":"Contributing to modsem","text":"Always create new branch work.","code":"git checkout -b your-branch-name"},{"path":"/CONTRIBUTING.html","id":"making-your-changes","dir":"","previous_headings":"Making Changes","what":"Making Your Changes","title":"Contributing to modsem","text":"Make changes codebase. Ensure changes well-documented. Write tests changes applicable.","code":""},{"path":"/CONTRIBUTING.html","id":"contributing-to-vignettes","dir":"","previous_headings":"Making Changes","what":"Contributing to Vignettes","title":"Contributing to modsem","text":"also encourage contributions vignettes. new use case example, feel free add alter vignettes help demonstrate functionality modsem.","code":""},{"path":"/CONTRIBUTING.html","id":"running-tests","dir":"","previous_headings":"Making Changes","what":"Running Tests","title":"Contributing to modsem","text":"Run tests ensure changes break existing functionality.","code":"devtools::test()"},{"path":"/CONTRIBUTING.html","id":"submitting-your-changes","dir":"","previous_headings":"","what":"Submitting Your Changes","title":"Contributing to modsem","text":"Push changes fork. Open pull request GitHub main branch original repository.","code":"git push origin your-branch-name"},{"path":"/CONTRIBUTING.html","id":"pull-request-guidelines","dir":"","previous_headings":"Submitting Your Changes","what":"Pull Request Guidelines","title":"Contributing to modsem","text":"Provide clear descriptive title pull request. Describe changes made necessary. Reference related issues pull requests. Ensure tests pass merge conflicts.","code":""},{"path":"/CONTRIBUTING.html","id":"reporting-issues","dir":"","previous_headings":"","what":"Reporting Issues","title":"Contributing to modsem","text":"encounter issues suggestions improvements, please open issue GitHub. Provide much detail possible help us understand address issue.","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 modsem authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/customizing.html","id":"specifying-the-measurement-model","dir":"Articles","previous_headings":"","what":"Specifying the Measurement Model","title":"customizing interaction terms","text":"default, modsem() creates possible combinations product indicators. However, another common approach match indicators order. example, let’s say interaction latent variables X Z: X =~ x1 + x2 Z =~ z1 + z2. default, get XZ =~ x1z1 + x1z2 + x2z1 + x2z2. prefer use matching approach, expect XZ =~ x1z1 + x2z2 instead. achieve , can use match = TRUE argument.","code":"m2 <- ' # Outer Model X =~ x1 + x2 Y =~ y1 + y2 Z =~ z1 + z2  # Inner model Y ~ X + Z + X:Z  '  est2 <- modsem(m2, oneInt, match = TRUE) summary(est2) #> modsem (version 1.0.9, approach = dblcent): #> lavaan 0.6-19 ended normally after 41 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        22 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                                11.355 #>   Degrees of freedom                                14 #>   P-value (Chi-square)                           0.658 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   X =~                                                 #>     x1                1.000                            #>     x2                0.819    0.021   38.127    0.000 #>   Y =~                                                 #>     y1                1.000                            #>     y2                0.807    0.010   82.495    0.000 #>   Z =~                                                 #>     z1                1.000                            #>     z2                0.836    0.024   35.392    0.000 #>   XZ =~                                                #>     x1z1              1.000                            #>     x2z2              0.645    0.024   26.904    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   Y ~                                                  #>     X                 0.688    0.029   23.366    0.000 #>     Z                 0.576    0.029   20.173    0.000 #>     XZ                0.706    0.032   22.405    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>  .x1z1 ~~                                              #>    .x2z2              0.000                            #>   X ~~                                                 #>     Z                 0.202    0.025    8.182    0.000 #>     XZ                0.003    0.026    0.119    0.905 #>   Z ~~                                                 #>     XZ                0.042    0.026    1.621    0.105 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .x1                0.179    0.022    8.029    0.000 #>    .x2                0.151    0.015    9.956    0.000 #>    .y1                0.184    0.021    8.577    0.000 #>    .y2                0.136    0.014    9.663    0.000 #>    .z1                0.197    0.025    7.802    0.000 #>    .z2                0.138    0.018    7.831    0.000 #>    .x1z1              0.319    0.035    9.141    0.000 #>    .x2z2              0.244    0.016   15.369    0.000 #>     X                 0.962    0.042   23.120    0.000 #>    .Y                 0.964    0.042   23.110    0.000 #>     Z                 0.987    0.044   22.260    0.000 #>     XZ                1.041    0.054   19.441    0.000"},{"path":"/articles/customizing.html","id":"more-complicated-models","dir":"Articles","previous_headings":"","what":"More Complicated Models","title":"customizing interaction terms","text":"want even control, can use get_pi_syntax() get_pi_data() functions extract modified syntax data modsem(), allowing modify needed. can particularly useful cases want estimate model using feature lavaan isn’t available modsem(). example, syntax ordered multigroup models (now) isn’t flexible modsem() lavaan. can modify auto-generated syntax (along altered dataset) modsem() suit needs. generated syntax data can used estimate model using lavaan, giving user control arguments passed onto lavaan::sem(), potentially ability modify generated syntax data.","code":"m3 <- ' # Outer Model X =~ x1 + x2 + x3 Y =~ y1 + y2 + y3 Z =~ z1 + z2 + z3  # Inner model Y ~ X + Z + X:Z  ' syntax <- get_pi_syntax(m3) cat(syntax) #> X =~ x1 #> X =~ x2 #> X =~ x3 #> Y =~ y1 #> Y =~ y2 #> Y =~ y3 #> Z =~ z1 #> Z =~ z2 #> Z =~ z3 #> Y ~ X #> Y ~ Z #> Y ~ XZ #> XZ =~ x1z1 #> XZ =~ x2z1 #> XZ =~ x3z1 #> XZ =~ x1z2 #> XZ =~ x2z2 #> XZ =~ x3z2 #> XZ =~ x1z3 #> XZ =~ x2z3 #> XZ =~ x3z3 #> x1z1 ~~ 0*x2z2 #> x1z1 ~~ 0*x2z3 #> x1z1 ~~ 0*x3z2 #> x1z1 ~~ 0*x3z3 #> x1z2 ~~ 0*x2z1 #> x1z2 ~~ 0*x2z3 #> x1z2 ~~ 0*x3z1 #> x1z2 ~~ 0*x3z3 #> x1z3 ~~ 0*x2z1 #> x1z3 ~~ 0*x2z2 #> x1z3 ~~ 0*x3z1 #> x1z3 ~~ 0*x3z2 #> x2z1 ~~ 0*x3z2 #> x2z1 ~~ 0*x3z3 #> x2z2 ~~ 0*x3z1 #> x2z2 ~~ 0*x3z3 #> x2z3 ~~ 0*x3z1 #> x2z3 ~~ 0*x3z2 #> x1z1 ~~ x1z2 #> x1z1 ~~ x1z3 #> x1z1 ~~ x2z1 #> x1z1 ~~ x3z1 #> x1z2 ~~ x1z3 #> x1z2 ~~ x2z2 #> x1z2 ~~ x3z2 #> x1z3 ~~ x2z3 #> x1z3 ~~ x3z3 #> x2z1 ~~ x2z2 #> x2z1 ~~ x2z3 #> x2z1 ~~ x3z1 #> x2z2 ~~ x2z3 #> x2z2 ~~ x3z2 #> x2z3 ~~ x3z3 #> x3z1 ~~ x3z2 #> x3z1 ~~ x3z3 #> x3z2 ~~ x3z3 data <- get_pi_data(m3, oneInt) head(data) #>           x1         x2          x3         y1         y2           y3 #> 1  2.4345722  1.3578655  1.40700355  1.4526897  0.9560888  1.209581472 #> 2  0.2472734  0.2723201  0.58024125  0.5496756  0.7115311 -0.135737642 #> 3 -1.3647759 -0.5628205 -0.09754199 -0.9835467 -0.6697747  0.007520468 #> 4  3.0432836  2.2153763  1.60846138  6.4641465  4.7805981  5.985944583 #> 5  2.8148841  2.7029616  2.58119575  2.2860280  2.1457643  1.551767464 #> 6 -0.5453450 -0.7530642 -0.63524883  1.1294876  1.1998472  0.362109037 #>           z1         z2          z3       x1z1       x2z1       x3z1       x1z2 #> 1  0.8184825 1.60708140  0.93586992 -0.4823019 -0.1884837 -0.2752638  0.3929380 #> 2  3.6649148 2.60983102  3.15244788 -2.2680403 -2.6637694 -1.0811726 -1.2630544 #> 3  1.7249386 2.10981827  0.90836245 -1.9137416 -1.4299711 -0.9068668 -2.3329864 #> 4  2.5697116 3.26335379  3.38596811  2.9385205  1.3971422  0.8925897  3.9837389 #> 5  0.3467850 0.07164577 -0.01871117 -1.4009548 -1.1495704 -1.2856163 -2.2058995 #> 6 -0.2362958 0.60252657  0.31946813  1.7465860  2.2950753  1.7584641  0.7717365 #>         x2z2        x3z2       x1z3       x2z3       x3z3 #> 1 -0.0730934  0.04749982 -0.1529509 -0.1293463 -0.1414301 #> 2 -1.4547433 -0.62456185 -1.9164521 -2.2419771 -0.9099617 #> 3 -1.7383407 -1.06788128 -0.1643368 -0.1193874 -0.1439739 #> 4  1.9273102  1.26967294  4.8096462  2.3378638  1.5509349 #> 5 -1.8169042 -2.03260698 -1.8558746 -1.5219744 -1.7039365 #> 6  1.0568143  0.78918775  0.7532472  1.0412580  0.7754318 library(lavaan) #> This is lavaan 0.6-19 #> lavaan is FREE software! Please report any bugs. fit <- sem(syntax, data = data, fixed.x = FALSE,             std.lv = TRUE, auto.fix.first = TRUE,             auto.var = TRUE, auto.cov.lv.x = TRUE) summary(fit) #> lavaan 0.6-19 ended normally after 200 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        60 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                               122.924 #>   Degrees of freedom                               111 #>   P-value (Chi-square)                           0.207 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   X =~                                                 #>     x1                0.990    0.018   53.791    0.000 #>     x2                0.796    0.016   50.482    0.000 #>     x3                0.907    0.017   52.468    0.000 #>   Y =~                                                 #>     y1                0.995    0.019   51.851    0.000 #>     y2                0.794    0.016   50.768    0.000 #>     y3                0.895    0.017   51.288    0.000 #>   Z =~                                                 #>     z1                1.008    0.019   53.712    0.000 #>     z2                0.818    0.016   51.138    0.000 #>     z3                0.889    0.017   52.410    0.000 #>   XZ =~                                                #>     x1z1              1.022    0.021   48.007    0.000 #>     x2z1              0.823    0.019   44.481    0.000 #>     x3z1              0.897    0.020   45.052    0.000 #>     x1z2              0.810    0.018   44.153    0.000 #>     x2z2              0.661    0.016   41.964    0.000 #>     x3z2              0.722    0.017   42.568    0.000 #>     x1z3              0.907    0.019   47.031    0.000 #>     x2z3              0.732    0.017   43.902    0.000 #>     x3z3              0.799    0.018   43.671    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   Y ~                                                  #>     X                 0.671    0.031   21.829    0.000 #>     Z                 0.568    0.029   19.352    0.000 #>     XZ                0.721    0.032   22.569    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>  .x1z1 ~~                                              #>    .x2z2              0.000                            #>    .x2z3              0.000                            #>    .x3z2              0.000                            #>    .x3z3              0.000                            #>  .x2z1 ~~                                              #>    .x1z2              0.000                            #>  .x1z2 ~~                                              #>    .x2z3              0.000                            #>  .x3z1 ~~                                              #>    .x1z2              0.000                            #>  .x1z2 ~~                                              #>    .x3z3              0.000                            #>  .x2z1 ~~                                              #>    .x1z3              0.000                            #>  .x2z2 ~~                                              #>    .x1z3              0.000                            #>  .x3z1 ~~                                              #>    .x1z3              0.000                            #>  .x3z2 ~~                                              #>    .x1z3              0.000                            #>  .x2z1 ~~                                              #>    .x3z2              0.000                            #>    .x3z3              0.000                            #>  .x3z1 ~~                                              #>    .x2z2              0.000                            #>  .x2z2 ~~                                              #>    .x3z3              0.000                            #>  .x3z1 ~~                                              #>    .x2z3              0.000                            #>  .x3z2 ~~                                              #>    .x2z3              0.000                            #>  .x1z1 ~~                                              #>    .x1z2              0.115    0.008   14.802    0.000 #>    .x1z3              0.114    0.008   13.947    0.000 #>    .x2z1              0.125    0.008   16.095    0.000 #>    .x3z1              0.140    0.009   16.135    0.000 #>  .x1z2 ~~                                              #>    .x1z3              0.103    0.007   14.675    0.000 #>    .x2z2              0.128    0.006   20.850    0.000 #>    .x3z2              0.146    0.007   21.243    0.000 #>  .x1z3 ~~                                              #>    .x2z3              0.116    0.007   17.818    0.000 #>    .x3z3              0.135    0.007   18.335    0.000 #>  .x2z1 ~~                                              #>    .x2z2              0.135    0.006   20.905    0.000 #>    .x2z3              0.145    0.007   21.145    0.000 #>    .x3z1              0.114    0.007   16.058    0.000 #>  .x2z2 ~~                                              #>    .x2z3              0.117    0.006   20.419    0.000 #>    .x3z2              0.116    0.006   20.586    0.000 #>  .x2z3 ~~                                              #>    .x3z3              0.109    0.006   18.059    0.000 #>  .x3z1 ~~                                              #>    .x3z2              0.138    0.007   19.331    0.000 #>    .x3z3              0.158    0.008   20.269    0.000 #>  .x3z2 ~~                                              #>    .x3z3              0.131    0.007   19.958    0.000 #>   X ~~                                                 #>     Z                 0.201    0.023    8.786    0.000 #>     XZ                0.015    0.024    0.628    0.530 #>   Z ~~                                                 #>     XZ                0.060    0.024    2.462    0.014 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .x1                0.160    0.009   17.871    0.000 #>    .x2                0.162    0.007   22.969    0.000 #>    .x3                0.163    0.008   20.161    0.000 #>    .y1                0.159    0.009   17.896    0.000 #>    .y2                0.154    0.007   22.640    0.000 #>    .y3                0.164    0.008   20.698    0.000 #>    .z1                0.168    0.009   18.143    0.000 #>    .z2                0.158    0.007   22.264    0.000 #>    .z3                0.158    0.008   20.389    0.000 #>    .x1z1              0.311    0.014   22.227    0.000 #>    .x2z1              0.292    0.011   27.287    0.000 #>    .x3z1              0.327    0.012   26.275    0.000 #>    .x1z2              0.290    0.011   26.910    0.000 #>    .x2z2              0.239    0.008   29.770    0.000 #>    .x3z2              0.270    0.009   29.117    0.000 #>    .x1z3              0.272    0.012   23.586    0.000 #>    .x2z3              0.245    0.009   27.979    0.000 #>    .x3z3              0.297    0.011   28.154    0.000 #>     X                 1.000                            #>    .Y                 1.000                            #>     Z                 1.000                            #>     XZ                1.000"},{"path":"/articles/estimation_lms.html","id":"accelerated-em-and-adaptive-quadrature","dir":"Articles","previous_headings":"","what":"Accelerated EM and Adaptive Quadrature","title":"estimation alternatives using the LMS approach","text":"default LMS approach uses standard Expectation-Maximization (EM) algorithm estimate model parameters, along fixed quadrature. However, possible use accelerated EM procedure (\"EMA\") uses Quasi-Newton Fisher Scoring optimization steps needed. also possible use quasi-adaptive quadrature instead fixed quadrature. Due performance reasons, adaptive quadrature fit individual quadrature participant, instead one entire sample (EM iteration), based whole sample densities likelihood function. usually means nodes placed towards center distribution, compared standard fixed Gauss-Hermite quadrature. Using EMA adaptive quadrature might yield estimates closer results Mplus. model struggles converge, can try using accelerated EM procedure setting method = \"EMA\", adaptive.quad = TRUE modsem() function. Additionally possible tweak parameters: max.iter: Maximum number iterations EM algorithm (default 500). max.step: Maximum number steps used Maximization step EM algorithm (default 1). convergence.rel: Relative convergence criterion EM algorithm. convergence.abs: Absolute convergence criterion EM algorithm. nodes: Number nodes numerical integration (default 24). Increasing number can improve accuracy estimates, especially complex models. quad.range: Integration range quadrature. Smaller ranges means integral focused. Applies fixed quasi-adaptive quadratures. adaptive.quad.tol: Relative tolerance determining whether sub-interval adaptive quadrature accurate enough. can see example using TPB_UK dataaset, troublesome estimate simulated TPB dataset.","code":"tpb_uk <- \" # Outer Model (Based on Hagger et al., 2007)   ATT =~ att3 + att2 + att1 + att4   SN =~ sn4 + sn2 + sn3 + sn1   PBC =~ pbc2 + pbc1 + pbc3 + pbc4   INT =~ int2 + int1 + int3 + int4   BEH =~ beh3 + beh2 + beh1 + beh4  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ INT:PBC \"  fit <- modsem(tpb_uk,                data = TPB_UK,                method = \"lms\",                nodes = 32, # Number of nodes for numerical integration               adaptive.quad = TRUE, # Use adaptive quadrature               algorithm =\"EMA\", # Use accelerated EM algorithm               convergence.abs = 1e-4, # Relative convergence criterion               convergence.rel = 1e-10, # Relative convergence criterion               max.iter = 500, # Maximum number of iterations               max.step = 1, # Maximum number of steps in the maximization step               adaptive.quad.tol = 1e-4) # Tolerance when building adaptive quadrature summary(fit) #> Estimating baseline model (H0) #>  #> modsem (version 1.0.9): #>   Estimator                                         LMS #>   Optimization method                        EMA-NLMINB #>   Number of observations                           1169 #>   Number of iterations                              102 #>   Loglikelihood                               -33386.83 #>   Akaike (AIC)                                 66911.65 #>   Bayesian (BIC)                               67261.06 #>   #> Numerical Integration: #>   Points of integration (per dim)                    32 #>   Dimensions                                          1 #>   Total points of integration                        32 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -35523 #>   Akaike (AIC)                                 71181.74 #>   Bayesian (BIC)                               71526.09 #>   Chi-square                                    5519.01 #>   Degrees of Freedom (Chi-square)                   162 #>   P-value (Chi-square)                            0.000 #>   RMSEA                                           0.168 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                          2136.04 #>   Difference test (D)                           4272.09 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   INT                                             0.901 #>   BEH                                             0.920 #> R-Squared Null-Model (H0): #>   INT                                             0.896 #>   BEH                                             0.867 #> R-Squared Change: #>   INT                                             0.005 #>   BEH                                             0.053 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC =~  #>     pbc2             1.000                              #>     pbc1             0.857      0.021    41.28    0.000 #>     pbc3             0.934      0.017    55.38    0.000 #>     pbc4             0.817      0.021    39.72    0.000 #>   ATT =~  #>     att3             1.000                              #>     att2             0.965      0.011    86.33    0.000 #>     att1             0.812      0.017    47.19    0.000 #>     att4             0.870      0.019    45.46    0.000 #>   SN =~  #>     sn4              1.000                              #>     sn2              1.313      0.041    32.30    0.000 #>     sn3              1.350      0.041    32.72    0.000 #>     sn1              1.000      0.038    26.60    0.000 #>   INT =~  #>     int2             1.000                              #>     int1             0.970      0.011    92.12    0.000 #>     int3             0.984      0.010    98.44    0.000 #>     int4             0.992      0.009   104.57    0.000 #>   BEH =~  #>     beh3             1.000                              #>     beh2             0.986      0.013    77.73    0.000 #>     beh1             0.814      0.019    42.72    0.000 #>     beh4             0.803      0.019    41.48    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   INT ~  #>     PBC              1.038      0.036    29.11    0.000 #>     ATT             -0.059      0.029    -2.03    0.042 #>     SN               0.046      0.032     1.44    0.151 #>   BEH ~  #>     PBC              0.391      0.052     7.48    0.000 #>     INT              0.576      0.049    11.80    0.000 #>     PBC:INT          0.141      0.008    17.81    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     pbc2             3.936      0.054    73.54    0.000 #>     pbc1             3.915      0.054    72.51    0.000 #>     pbc3             3.678      0.052    71.25    0.000 #>     pbc4             3.723      0.053    70.83    0.000 #>     att3             3.653      0.055    66.49    0.000 #>     att2             3.771      0.053    70.80    0.000 #>     att1             4.153      0.054    76.80    0.000 #>     att4             3.628      0.059    61.79    0.000 #>     sn4              4.463      0.048    92.12    0.000 #>     sn2              4.299      0.050    86.73    0.000 #>     sn3              4.337      0.050    87.19    0.000 #>     sn1              4.432      0.049    90.11    0.000 #>     int2             3.638      0.054    67.09    0.000 #>     int1             3.786      0.054    70.04    0.000 #>     int3             3.657      0.054    67.47    0.000 #>     int4             3.700      0.054    68.39    0.000 #>     beh3             2.572      0.066    38.87    0.000 #>     beh2             2.491      0.066    37.85    0.000 #>     beh1             2.468      0.066    37.43    0.000 #>     beh4             2.612      0.066    39.60    0.000 #>     INT              0.000                              #>     BEH              0.000                              #>     PBC              0.000                              #>     ATT              0.000                              #>     SN               0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC ~~  #>     ATT              3.719      0.145    25.73    0.000 #>     SN               1.962      0.104    18.78    0.000 #>   ATT ~~  #>     SN               1.698      0.101    16.90    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     pbc2             0.690      0.043    16.17    0.000 #>     pbc1             1.459      0.069    21.03    0.000 #>     pbc3             0.799      0.042    18.86    0.000 #>     pbc4             1.464      0.069    21.27    0.000 #>     att3             0.296      0.023    12.81    0.000 #>     att2             0.306      0.022    13.81    0.000 #>     att1             1.285      0.057    22.58    0.000 #>     att4             1.583      0.071    22.42    0.000 #>     sn4              1.363      0.065    21.03    0.000 #>     sn2              0.491      0.032    15.40    0.000 #>     sn3              0.377      0.032    11.89    0.000 #>     sn1              1.445      0.068    21.13    0.000 #>     int2             0.237      0.014    16.98    0.000 #>     int1             0.404      0.020    20.25    0.000 #>     int3             0.334      0.017    19.35    0.000 #>     int4             0.271      0.015    17.92    0.000 #>     beh3             0.456      0.030    15.27    0.000 #>     beh2             0.513      0.031    16.54    0.000 #>     beh1             1.836      0.082    22.30    0.000 #>     beh4             1.917      0.086    22.40    0.000 #>     PBC              4.421      0.171    25.83    0.000 #>     ATT              4.487      0.178    25.21    0.000 #>     SN               1.727      0.117    14.79    0.000 #>     INT              0.496      0.037    13.37    0.000 #>     BEH              0.447      0.034    13.20    0.000"},{"path":"/articles/fit_measures_da.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"fit measures for LMS and QML","text":"vignette demonstrates evaluate compare model fit latent interaction models estimated via LMS (Latent Moderated Structural Equations) QML (Quasi-Maximum Likelihood) using modsem package (v≥1.0.8). standard Chi-square statistics available LMS/QML, assess fit : Examining fit indices baseline (-interaction) model. Conducting likelihood-ratio difference test compare baseline interaction models (Klein & Moosbrugger, 2000; Klein & Múthen, 2007). baseline model shows acceptable fit adding latent interaction significantly improves fit, interaction model can also deemed well-fitting.","code":""},{"path":"/articles/fit_measures_da.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"fit measures for LMS and QML","text":"define model three latent variables (X, Y, Z) interaction (X:Z):","code":"m1 <- \" # Outer (measurement) model X =~ x1 + x2 + x3 Y =~ y1 + y2 + y3 Z =~ z1 + z2 + z3  # Inner (structural) model Y ~ X + Z + X:Z \"  # Estimate the full (H1) model via LMS est_h1 <- modsem(m1, oneInt, method = \"lms\")  # Estimate the baseline (H0) model without interaction est_h0 <- estimate_h0(est_h1, calc.se = FALSE) # std.errors are not needed"},{"path":"/articles/fit_measures_da.html","id":"fit-measures-baseline-model","dir":"Articles","previous_headings":"","what":"Fit measures baseline model","title":"fit measures for LMS and QML","text":"get fit measures baseline model can use fit_modsem_da() function. can also used get fit measures full model, pared chisq = FALSE avoid Chi-square test. set TRUE calculate Chi-square test ignoring interaction terms model.","code":"fit_modsem_da(est_h0) #> $sigma.observed #>           x1        x2        x3        z1        z2        z3        y1 #> x1 1.1414140 0.7883687 0.8995307 0.2101059 0.1740044 0.1816761 0.7884435 #> x2 0.7883687 0.7969205 0.7227575 0.1611022 0.1303270 0.1323003 0.6405208 #> x3 0.8995307 0.7227575 0.9858399 0.1813015 0.1483665 0.1513961 0.7143555 #> z1 0.2101059 0.1611022 0.1813015 1.1848928 0.8251779 0.8974163 0.7336206 #> z2 0.1740044 0.1303270 0.1483665 0.8251779 0.8282354 0.7268682 0.6114440 #> z3 0.1816761 0.1323003 0.1513961 0.8974163 0.7268682 0.9487013 0.6578085 #> y1 0.7884435 0.6405208 0.7143555 0.7336206 0.6114440 0.6578085 2.6478088 #> y2 0.6253530 0.5123430 0.5569065 0.6010575 0.4998194 0.5413313 1.9878980 #> y3 0.7105927 0.5762476 0.6417552 0.6575885 0.5520473 0.5975011 2.2378289 #>           y2        y3 #> x1 0.6253530 0.7105927 #> x2 0.5123430 0.5762476 #> x3 0.5569065 0.6417552 #> z1 0.6010575 0.6575885 #> z2 0.4998194 0.5520473 #> z3 0.5413313 0.5975011 #> y1 1.9878980 2.2378289 #> y2 1.7403428 1.7841731 #> y3 1.7841731 2.1756928 #>  #> $sigma.expected #>           x1        x2        x3        z1        z2        z3        y1 #> x1 1.1408432 0.7887122 0.8984977 0.2011156 0.1631816 0.1774521 0.7860620 #> x2 0.7887122 0.7965219 0.7223142 0.1616795 0.1311839 0.1426561 0.6319257 #> x3 0.8984977 0.7223142 0.9853469 0.1841846 0.1494441 0.1625132 0.7198871 #> z1 0.2011156 0.1616795 0.1841846 1.1843003 0.8244128 0.8965091 0.7493786 #> z2 0.1631816 0.1311839 0.1494441 0.8244128 0.8278212 0.7274115 0.6080325 #> z3 0.1774521 0.1426561 0.1625132 0.8965091 0.7274115 0.9482269 0.6612059 #> y1 0.7860620 0.6319257 0.7198871 0.7493786 0.6080325 0.6612059 2.6464848 #> y2 0.6269615 0.5040227 0.5741806 0.5977030 0.4849655 0.5273766 1.9868791 #> y3 0.7056902 0.5673138 0.6462815 0.6727576 0.5458636 0.5936002 2.2363752 #>           y2        y3 #> x1 0.6269615 0.7056902 #> x2 0.5040227 0.5673138 #> x3 0.5741806 0.6462815 #> z1 0.5977030 0.6727576 #> z2 0.4849655 0.5458636 #> z3 0.5273766 0.5936002 #> y1 1.9868791 2.2363752 #> y2 1.7394726 1.7837286 #> y3 1.7837286 2.1746048 #>  #> $mu.observed #>        x1        x2        x3        z1        z2        z3        y1        y2  #> 1.0228543 1.2154912 0.9193956 1.0113688 1.2055455 0.9155865 1.1802667 1.3346201  #>        y3  #> 1.0826391  #>  #> $mu.expected #>            1 #> x1 1.0228543 #> x2 1.2154912 #> x3 0.9193956 #> z1 1.0113688 #> z2 1.2055455 #> z3 0.9155865 #> y1 1.1802667 #> y2 1.3346201 #> y3 1.0826391 #>  #> $chisq.value #> [1] 17.5224 #>  #> $chisq.pvalue #> [1] 0.8255439 #>  #> $chisq.df #> [1] 24 #>  #> $AIC #> [1] 35723.75 #>  #> $AICc #> [1] 35724.69 #>  #> $BIC #> [1] 35891.78 #>  #> $aBIC #> [1] 35796.47 #>  #> $RMSEA #> [1] 0 #>  #> $RMSEA.lower #> [1] 0 #>  #> $RMSEA.upper #> [1] 0.01122746 #>  #> $RMSEA.ci.level #> [1] 0.9 #>  #> $RMSEA.pvalue #> [1] 1 #>  #> $RMSEA.close.h0 #> [1] 0.05 fit_modsem_da(est_h1, chisq = FALSE) #> $sigma.observed #>           x1        x2        x3        z1        z2        z3        y1 #> x1 1.1414140 0.7883687 0.8995307 0.2101059 0.1740044 0.1816761 0.7884435 #> x2 0.7883687 0.7969205 0.7227575 0.1611022 0.1303270 0.1323003 0.6405208 #> x3 0.8995307 0.7227575 0.9858399 0.1813015 0.1483665 0.1513961 0.7143555 #> z1 0.2101059 0.1611022 0.1813015 1.1848928 0.8251779 0.8974163 0.7336206 #> z2 0.1740044 0.1303270 0.1483665 0.8251779 0.8282354 0.7268682 0.6114440 #> z3 0.1816761 0.1323003 0.1513961 0.8974163 0.7268682 0.9487013 0.6578085 #> y1 0.7884435 0.6405208 0.7143555 0.7336206 0.6114440 0.6578085 2.6478088 #> y2 0.6253530 0.5123430 0.5569065 0.6010575 0.4998194 0.5413313 1.9878980 #> y3 0.7105927 0.5762476 0.6417552 0.6575885 0.5520473 0.5975011 2.2378289 #>           y2        y3 #> x1 0.6253530 0.7105927 #> x2 0.5123430 0.5762476 #> x3 0.5569065 0.6417552 #> z1 0.6010575 0.6575885 #> z2 0.4998194 0.5520473 #> z3 0.5413313 0.5975011 #> y1 1.9878980 2.2378289 #> y2 1.7403428 1.7841731 #> y3 1.7841731 2.1756928 #>  #> $sigma.expected #> NULL #>  #> $mu.observed #>        x1        x2        x3        z1        z2        z3        y1        y2  #> 1.0228543 1.2154912 0.9193956 1.0113688 1.2055455 0.9155865 1.1802667 1.3346201  #>        y3  #> 1.0826391  #>  #> $mu.expected #> NULL #>  #> $chisq.value #> NULL #>  #> $chisq.pvalue #> NULL #>  #> $chisq.df #> NULL #>  #> $AIC #> [1] 29437.48 #>  #> $AICc #> [1] 29438.49 #>  #> $BIC #> [1] 29611.11 #>  #> $aBIC #> [1] 29512.62 #>  #> $RMSEA #> NULL #>  #> $RMSEA.lower #> NULL #>  #> $RMSEA.upper #> NULL #>  #> $RMSEA.ci.level #> NULL #>  #> $RMSEA.pvalue #> NULL #>  #> $RMSEA.close.h0 #> NULL"},{"path":"/articles/fit_measures_da.html","id":"difference-test-of-fit","dir":"Articles","previous_headings":"","what":"Difference Test of Fit","title":"fit measures for LMS and QML","text":"Compare H0 vs. H1 using log-likelihood ratio test: significant p-value indicates latent interaction term significantly improves model fit.","code":"compare_fit(est_h0, est_h1) #> $D #> [1] 6288.266 #>  #> $df #> [1] 1 #>  #> $p #> [1] 0 #>  #> $llChange #> [1] 3144.133"},{"path":"/articles/fit_measures_da.html","id":"inspecting-fit-indices","dir":"Articles","previous_headings":"","what":"Inspecting Fit Indices","title":"fit measures for LMS and QML","text":"convenience, can also use modsem_inspect() function = \"fit\" get fit indices models, comparative fit one go.","code":"modsem_inspect(est_h1, what = \"fit\") #> $fit.h0 #> $fit.h0$sigma.observed #>           x1        x2        x3        z1        z2        z3        y1 #> x1 1.1414140 0.7883687 0.8995307 0.2101059 0.1740044 0.1816761 0.7884435 #> x2 0.7883687 0.7969205 0.7227575 0.1611022 0.1303270 0.1323003 0.6405208 #> x3 0.8995307 0.7227575 0.9858399 0.1813015 0.1483665 0.1513961 0.7143555 #> z1 0.2101059 0.1611022 0.1813015 1.1848928 0.8251779 0.8974163 0.7336206 #> z2 0.1740044 0.1303270 0.1483665 0.8251779 0.8282354 0.7268682 0.6114440 #> z3 0.1816761 0.1323003 0.1513961 0.8974163 0.7268682 0.9487013 0.6578085 #> y1 0.7884435 0.6405208 0.7143555 0.7336206 0.6114440 0.6578085 2.6478088 #> y2 0.6253530 0.5123430 0.5569065 0.6010575 0.4998194 0.5413313 1.9878980 #> y3 0.7105927 0.5762476 0.6417552 0.6575885 0.5520473 0.5975011 2.2378289 #>           y2        y3 #> x1 0.6253530 0.7105927 #> x2 0.5123430 0.5762476 #> x3 0.5569065 0.6417552 #> z1 0.6010575 0.6575885 #> z2 0.4998194 0.5520473 #> z3 0.5413313 0.5975011 #> y1 1.9878980 2.2378289 #> y2 1.7403428 1.7841731 #> y3 1.7841731 2.1756928 #>  #> $fit.h0$sigma.expected #>           x1        x2        x3        z1        z2        z3        y1 #> x1 1.1408432 0.7887122 0.8984977 0.2011156 0.1631816 0.1774521 0.7860620 #> x2 0.7887122 0.7965219 0.7223142 0.1616795 0.1311839 0.1426561 0.6319257 #> x3 0.8984977 0.7223142 0.9853469 0.1841846 0.1494441 0.1625132 0.7198871 #> z1 0.2011156 0.1616795 0.1841846 1.1843003 0.8244128 0.8965091 0.7493786 #> z2 0.1631816 0.1311839 0.1494441 0.8244128 0.8278212 0.7274115 0.6080325 #> z3 0.1774521 0.1426561 0.1625132 0.8965091 0.7274115 0.9482269 0.6612059 #> y1 0.7860620 0.6319257 0.7198871 0.7493786 0.6080325 0.6612059 2.6464848 #> y2 0.6269615 0.5040227 0.5741806 0.5977030 0.4849655 0.5273766 1.9868791 #> y3 0.7056902 0.5673138 0.6462815 0.6727576 0.5458636 0.5936002 2.2363752 #>           y2        y3 #> x1 0.6269615 0.7056902 #> x2 0.5040227 0.5673138 #> x3 0.5741806 0.6462815 #> z1 0.5977030 0.6727576 #> z2 0.4849655 0.5458636 #> z3 0.5273766 0.5936002 #> y1 1.9868791 2.2363752 #> y2 1.7394726 1.7837286 #> y3 1.7837286 2.1746048 #>  #> $fit.h0$mu.observed #>        x1        x2        x3        z1        z2        z3        y1        y2  #> 1.0228543 1.2154912 0.9193956 1.0113688 1.2055455 0.9155865 1.1802667 1.3346201  #>        y3  #> 1.0826391  #>  #> $fit.h0$mu.expected #>            1 #> x1 1.0228543 #> x2 1.2154912 #> x3 0.9193956 #> z1 1.0113688 #> z2 1.2055455 #> z3 0.9155865 #> y1 1.1802667 #> y2 1.3346201 #> y3 1.0826391 #>  #> $fit.h0$chisq.value #> [1] 17.5224 #>  #> $fit.h0$chisq.pvalue #> [1] 0.8255439 #>  #> $fit.h0$chisq.df #> [1] 24 #>  #> $fit.h0$AIC #> [1] 35723.75 #>  #> $fit.h0$AICc #> [1] 35724.69 #>  #> $fit.h0$BIC #> [1] 35891.78 #>  #> $fit.h0$aBIC #> [1] 35796.47 #>  #> $fit.h0$RMSEA #> [1] 0 #>  #> $fit.h0$RMSEA.lower #> [1] 0 #>  #> $fit.h0$RMSEA.upper #> [1] 0.01122746 #>  #> $fit.h0$RMSEA.ci.level #> [1] 0.9 #>  #> $fit.h0$RMSEA.pvalue #> [1] 1 #>  #> $fit.h0$RMSEA.close.h0 #> [1] 0.05 #>  #>  #> $fit.h1 #> $fit.h1$sigma.observed #>           x1        x2        x3        z1        z2        z3        y1 #> x1 1.1414140 0.7883687 0.8995307 0.2101059 0.1740044 0.1816761 0.7884435 #> x2 0.7883687 0.7969205 0.7227575 0.1611022 0.1303270 0.1323003 0.6405208 #> x3 0.8995307 0.7227575 0.9858399 0.1813015 0.1483665 0.1513961 0.7143555 #> z1 0.2101059 0.1611022 0.1813015 1.1848928 0.8251779 0.8974163 0.7336206 #> z2 0.1740044 0.1303270 0.1483665 0.8251779 0.8282354 0.7268682 0.6114440 #> z3 0.1816761 0.1323003 0.1513961 0.8974163 0.7268682 0.9487013 0.6578085 #> y1 0.7884435 0.6405208 0.7143555 0.7336206 0.6114440 0.6578085 2.6478088 #> y2 0.6253530 0.5123430 0.5569065 0.6010575 0.4998194 0.5413313 1.9878980 #> y3 0.7105927 0.5762476 0.6417552 0.6575885 0.5520473 0.5975011 2.2378289 #>           y2        y3 #> x1 0.6253530 0.7105927 #> x2 0.5123430 0.5762476 #> x3 0.5569065 0.6417552 #> z1 0.6010575 0.6575885 #> z2 0.4998194 0.5520473 #> z3 0.5413313 0.5975011 #> y1 1.9878980 2.2378289 #> y2 1.7403428 1.7841731 #> y3 1.7841731 2.1756928 #>  #> $fit.h1$sigma.expected #> NULL #>  #> $fit.h1$mu.observed #>        x1        x2        x3        z1        z2        z3        y1        y2  #> 1.0228543 1.2154912 0.9193956 1.0113688 1.2055455 0.9155865 1.1802667 1.3346201  #>        y3  #> 1.0826391  #>  #> $fit.h1$mu.expected #> NULL #>  #> $fit.h1$chisq.value #> NULL #>  #> $fit.h1$chisq.pvalue #> NULL #>  #> $fit.h1$chisq.df #> NULL #>  #> $fit.h1$AIC #> [1] 29437.48 #>  #> $fit.h1$AICc #> [1] 29438.49 #>  #> $fit.h1$BIC #> [1] 29611.11 #>  #> $fit.h1$aBIC #> [1] 29512.62 #>  #> $fit.h1$RMSEA #> NULL #>  #> $fit.h1$RMSEA.lower #> NULL #>  #> $fit.h1$RMSEA.upper #> NULL #>  #> $fit.h1$RMSEA.ci.level #> NULL #>  #> $fit.h1$RMSEA.pvalue #> NULL #>  #> $fit.h1$RMSEA.close.h0 #> NULL #>  #>  #> $comparative.fit #> $comparative.fit$D #> [1] 6288.266 #>  #> $comparative.fit$df #> [1] 1 #>  #> $comparative.fit$p #> [1] 0 #>  #> $comparative.fit$llChange #> [1] 3144.133"},{"path":"/articles/fit_measures_da.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"fit measures for LMS and QML","text":"","code":"Klein, A., & Moosbrugger, H. (2000).    <doi:10.1007/BF02296338>.   \"Maximum likelihood estimation of latent interaction effects with the LMS method.\" Klein, A. G., & Muthén, B. O. (2007).    <doi:10.1080/00273170701710205>.   \"Quasi-maximum likelihood estimation of structural equation models with multiple interaction and quadratic effects.\""},{"path":"/articles/higher_order_interactions.html","id":"interaction-between-two-higher-order-constructs","dir":"Articles","previous_headings":"","what":"Interaction between two higher order constructs","title":"higher order interactions","text":"WARNING: Please note literature higher order interactions product indicator approaches virtually non-existant, likely need experiment different approaches find one works. well experiment adding constraints model. modsem two datasets variants Theory Planned Behaviour (TPB) dataset. TPB_2SO contains two second order constructs, INT (intention) second order construct ATT (attitude) SN (subjective norm), PBC (perceived behavioural control) second order construct PC (perceived control) PB (perceived behaviour).","code":"tpb <- '   # First order constructs   ATT =~ att1 + att2 + att3   SN  =~ sn1 + sn2 + sn3   PB =~ pb1 + pb2 + pb3   PC =~ pc1 + pc2 + pc3   BEH =~ b1 + b2    # Higher order constructs   INT =~ ATT + SN   PBC =~ PC + PB    # Higher order interaction   INTxPBC =~ ATT:PC + ATT:PB + SN:PC + SN:PB      # Structural model   BEH ~ PBC + INT + INTxPBC '  est_ca <- modsem(tpb, data = TPB_2SO, method = \"ca\") summary(est_ca) #> modsem (version 1.0.9, approach = ca): #> lavaan 0.6-19 ended normally after 628 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        96 #>   Row rank of the constraints matrix                28 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                              3479.483 #>   Degrees of freedom                               309 #>   P-value (Chi-square)                           0.000 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   ATT =~                                               #>     a      (l_1_A)    1.000                            #>     a      (l_2_A)    0.903    0.010   94.899    0.000 #>     a      (l_3_A)    0.787    0.009   89.747    0.000 #>   SN =~                                                #>     s      (l_1_S)    1.000                            #>     s      (l_2_S)    0.917    0.013   71.403    0.000 #>     s      (l_3_S)    0.804    0.012   67.969    0.000 #>   PB =~                                                #>     p     (l_1_PB)    1.000                            #>     p     (l_2_PB)    0.923    0.010   89.364    0.000 #>     p     (l_3_PB)    0.790    0.009   84.731    0.000 #>   PC =~                                                #>     p     (l_1_PC)    1.000                            #>     p     (l_2_PC)    0.889    0.009  101.651    0.000 #>     p     (l_3_PC)    0.787    0.008   97.811    0.000 #>   BEH =~                                               #>     b      (l_1_B)    1.000                            #>     b      (l_2_B)    0.848    0.043   19.772    0.000 #>   INT =~                                               #>     A     (l_ATT_)    1.000                            #>     S      (l_SN_)    0.646    0.076    8.547    0.000 #>   PBC =~                                               #>     P       (l_PC)    1.000                            #>     P       (l_PB)    0.650    0.081    7.985    0.000 #>   INTxPBC =~                                           #>     A    (l_ATTPC)    1.000                            #>     A    (l_ATTPB)    0.817    0.036   22.725    0.000 #>     S     (l_SNPC)    0.729    0.031   23.234    0.000 #>     S     (l_SNPB)    0.606    0.027   22.365    0.000 #>   ATTPC =~                                             #>     a (l_11_ATTPC)    1.000                            #>     a (l_22_ATTPC)    0.803    0.009   90.729    0.000 #>     a (l_33_ATTPC)    0.620    0.007   86.179    0.000 #>   ATTPB =~                                             #>     a (l_11_ATTPB)    1.000                            #>     a (l_22_ATTPB)    0.834    0.010   83.614    0.000 #>     a (l_33_ATTPB)    0.622    0.008   78.869    0.000 #>   SNPC =~                                              #>     s  (l_11_SNPC)    1.000                            #>     s  (l_22_SNPC)    0.815    0.011   71.600    0.000 #>     s  (l_33_SNPC)    0.633    0.009   68.160    0.000 #>   SNPB =~                                              #>     s  (l_11_SNPB)    1.000                            #>     s  (l_22_SNPB)    0.846    0.012   68.808    0.000 #>     s  (l_33_SNPB)    0.635    0.010   65.238    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   BEH ~                                                #>     PBC     (G_PB)    0.221    0.031    7.155    0.000 #>     INT   (G_INT_)    0.209    0.029    7.224    0.000 #>     INTPB (G_INTP)    0.158    0.019    8.137    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   INT ~~                                               #>     PBC  (C_INT_P)    0.017    0.026    0.669    0.504 #>     INTP (C_INT_I)   -0.002    0.029   -0.083    0.934 #>   PBC ~~                                               #>     INTP    (C_PB)   -0.094    0.035   -2.712    0.007 #>  .att1pc1 ~~                                           #>    .at22              0.000                            #>    .at33              0.000                            #>  .att2pc2 ~~                                           #>    .at33              0.000                            #>  .att1pb1 ~~                                           #>    .at22              0.000                            #>    .at33              0.000                            #>  .att2pb2 ~~                                           #>    .at33              0.000                            #>  .sn1pc1 ~~                                            #>    .sn22              0.000                            #>    .sn33              0.000                            #>  .sn2pc2 ~~                                            #>    .sn33              0.000                            #>  .sn1pb1 ~~                                            #>    .sn22              0.000                            #>    .sn33              0.000                            #>  .sn2pb2 ~~                                            #>    .sn33              0.000                            #>  #> Intercepts: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .ATTP (M_ATTPC)    0.017    0.026    0.669    0.504 #>    .ATTP (M_ATTPB)    0.011    0.017    0.668    0.504 #>    .SNPC  (M_SNPC)    0.011    0.017    0.668    0.504 #>    .SNPB  (M_SNPB)    0.007    0.011    0.667    0.505 #>    .att1              1.008    0.025   40.614    0.000 #>    .att2              1.002    0.023   43.736    0.000 #>    .att3              1.012    0.021   49.282    0.000 #>    .sn1               0.980    0.018   53.085    0.000 #>    .sn2               0.986    0.018   56.087    0.000 #>    .sn3               0.993    0.016   61.749    0.000 #>    .pb1               1.010    0.024   41.515    0.000 #>    .pb2               1.014    0.023   43.981    0.000 #>    .pb3               1.015    0.020   50.248    0.000 #>    .pc1               1.032    0.028   36.550    0.000 #>    .pc2               1.023    0.026   39.909    0.000 #>    .pc3               1.027    0.023   44.819    0.000 #>    .b1                1.000    0.020   50.566    0.000 #>    .b2                0.997    0.018   54.925    0.000 #>    .at11              0.012    0.048    0.242    0.809 #>    .at22             -0.016    0.039   -0.401    0.689 #>    .at33              0.005    0.031    0.170    0.865 #>    .at11              0.031    0.038    0.812    0.417 #>    .at22              0.009    0.033    0.292    0.770 #>    .at33              0.025    0.025    1.013    0.311 #>    .sn11              0.021    0.034    0.605    0.545 #>    .sn22              0.000    0.029    0.008    0.994 #>    .sn33              0.006    0.023    0.282    0.778 #>    .sn11              0.028    0.028    1.031    0.303 #>    .sn22              0.008    0.024    0.344    0.731 #>    .sn33              0.009    0.019    0.467    0.640 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .AT    (Vr_ATT)    0.306    0.088    3.482    0.000 #>    .SN     (Vr_SN)    0.190    0.037    5.088    0.000 #>    .PB     (Vr_PB)    0.619    0.054   11.411    0.000 #>    .PC      (V_PC)    0.469    0.120    3.907    0.000 #>    .BE      (Z_BE)    0.544    0.036   15.260    0.000 #>     IN    (Vr_INT)    0.752    0.091    8.252    0.000 #>     PB     (V_PBC)    0.958    0.123    7.760    0.000 #>     IN    (V_INTP)    1.297    0.089   14.646    0.000 #>    .AT   (V_ATTPC)    1.511    0.041   36.482    0.000 #>    .AT   (V_ATTPB)    1.084    0.031   35.464    0.000 #>    .SN    (V_SNPC)    0.719    0.022   32.194    0.000 #>    .SN    (V_SNPB)    0.516    0.016   31.825    0.000 #>    .a1     (Vr_t1)    0.174    0.008   21.062    0.000 #>    .a2     (Vr_t2)    0.186    0.007   24.851    0.000 #>    .a3     (Vr_t3)    0.187    0.007   28.710    0.000 #>    .s1     (Vr_s1)    0.177    0.007   24.784    0.000 #>    .s2     (Vr_s2)    0.195    0.007   28.844    0.000 #>    .s3     (Vr_s3)    0.192    0.006   32.240    0.000 #>    .p1    (Vr_pb1)    0.161    0.009   18.864    0.000 #>    .p2    (Vr_pb2)    0.191    0.008   23.432    0.000 #>    .p3    (Vr_pb3)    0.178    0.007   26.465    0.000 #>    .p1    (Vr_pc1)    0.167    0.009   18.483    0.000 #>    .p2    (Vr_pc2)    0.185    0.008   22.968    0.000 #>    .p3    (Vr_pc3)    0.165    0.007   24.405    0.000 #>    .b1     (Vr_b1)    0.131    0.031    4.180    0.000 #>    .b2     (Vr_b2)    0.191    0.023    8.211    0.000 #>    .a1 (Vr_tt1pc1)    0.454    0.015   30.377    0.000 #>    .a2 (Vr_tt2pc2)    0.404    0.011   36.058    0.000 #>    .a3 (Vr_tt3pc3)    0.305    0.008   39.382    0.000 #>    .a1 (Vr_tt1pb1)    0.377    0.012   30.603    0.000 #>    .a2 (Vr_tt2pb2)    0.363    0.010   36.293    0.000 #>    .a3 (Vr_tt3pb3)    0.270    0.007   40.454    0.000 #>    .s1 (Vr_sn1pc1)    0.367    0.012   31.101    0.000 #>    .s2 (Vr_sn2pc2)    0.334    0.009   36.194    0.000 #>    .s3 (Vr_sn3pc3)    0.255    0.007   38.970    0.000 #>    .s1 (Vr_sn1pb1)    0.291    0.009   32.171    0.000 #>    .s2 (Vr_sn2pb2)    0.288    0.008   37.329    0.000 #>    .s3 (Vr_sn3pb3)    0.214    0.005   40.765    0.000 #>  #> Constraints: #>                                                |Slack| #>     V_ATTPC-((_ATT_INT^2*V_INT+V_ATT)*(_PC_PB    0.000 #>     V_11-(_1_ATT^2*(_ATT_INT^2*V_INT+V_ATT)*V    0.000 #>     V_22-(_2_ATT^2*(_ATT_INT^2*V_INT+V_ATT)*V    0.000 #>     V_33-(_3_ATT^2*(_ATT_INT^2*V_INT+V_ATT)*V    0.000 #>     V_ATTPB-((_ATT_INT^2*V_INT+V_ATT)*(_PB_PB    0.000 #>     V_11-(_1_ATT^2*(_ATT_INT^2*V_INT+V_ATT)*V    0.000 #>     V_22-(_2_ATT^2*(_ATT_INT^2*V_INT+V_ATT)*V    0.000 #>     V_33-(_3_ATT^2*(_ATT_INT^2*V_INT+V_ATT)*V    0.000 #>     V_SNPC-((_SN_INT^2*V_INT+V_SN)*(_PC_PBC^2    0.000 #>     V_11-(_1_SN^2*(_SN_INT^2*V_INT+V_SN)*V_1+    0.000 #>     V_22-(_2_SN^2*(_SN_INT^2*V_INT+V_SN)*V_2+    0.000 #>     V_33-(_3_SN^2*(_SN_INT^2*V_INT+V_SN)*V_3+    0.000 #>     V_SNPB-((_SN_INT^2*V_INT+V_SN)*(_PB_PBC^2    0.000 #>     V_11-(_1_SN^2*(_SN_INT^2*V_INT+V_SN)*V_1+    0.000 #>     V_22-(_2_SN^2*(_SN_INT^2*V_INT+V_SN)*V_2+    0.000 #>     V_33-(_3_SN^2*(_SN_INT^2*V_INT+V_SN)*V_3+    0.000 #>     lmbd_tt1pc1_ATTPC-(lmbd_tt1_ATT*lmb_1_PC)    0.000 #>     lmbd_tt2pc2_ATTPC-(lmbd_tt2_ATT*lmb_2_PC)    0.000 #>     lmbd_tt3pc3_ATTPC-(lmbd_tt3_ATT*lmb_3_PC)    0.000 #>     lmbd_tt1pb1_ATTPB-(lmbd_tt1_ATT*lmb_1_PB)    0.000 #>     lmbd_tt2pb2_ATTPB-(lmbd_tt2_ATT*lmb_2_PB)    0.000 #>     lmbd_tt3pb3_ATTPB-(lmbd_tt3_ATT*lmb_3_PB)    0.000 #>     lmbd_sn1pc1_SNPC-(lmbd_sn1_SN*lmbd_p1_PC)    0.000 #>     lmbd_sn2pc2_SNPC-(lmbd_sn2_SN*lmbd_p2_PC)    0.000 #>     lmbd_sn3pc3_SNPC-(lmbd_sn3_SN*lmbd_p3_PC)    0.000 #>     lmbd_sn1pb1_SNPB-(lmbd_sn1_SN*lmbd_p1_PB)    0.000 #>     lmbd_sn2pb2_SNPB-(lmbd_sn2_SN*lmbd_p2_PB)    0.000 #>     lmbd_sn3pb3_SNPB-(lmbd_sn3_SN*lmbd_p3_PB)    0.000 #>     Mn_ATTPC-((Cv_INT_PBC*l_ATT_INT*_PC_PBC))    0.000 #>     Mn_ATTPB-((Cv_INT_PBC*l_ATT_INT*_PB_PBC))    0.000 #>     Mn_SNPC-((Cv_INT_PBC*lmb_PC_PBC*_SN_INT))    0.000 #>     Mn_SNPB-((Cv_INT_PBC*lmb_PB_PBC*_SN_INT))    0.000  est_dblcent <- modsem(tpb, data = TPB_2SO, method = \"dblcent\") summary(est_dblcent) #> modsem (version 1.0.9, approach = dblcent): #> lavaan 0.6-19 ended normally after 465 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                       186 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                         #>   Test statistic                              10052.300 #>   Degrees of freedom                               1089 #>   P-value (Chi-square)                            0.000 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   ATT =~                                               #>     att1              1.000                            #>     att2              0.908    0.011   83.766    0.000 #>     att3              0.798    0.010   77.657    0.000 #>   SN =~                                                #>     sn1               1.000                            #>     sn2               0.909    0.016   55.251    0.000 #>     sn3               0.813    0.015   53.511    0.000 #>   PB =~                                                #>     pb1               1.000                            #>     pb2               0.918    0.012   77.166    0.000 #>     pb3               0.789    0.011   72.867    0.000 #>   PC =~                                                #>     pc1               1.000                            #>     pc2               0.891    0.010   89.774    0.000 #>     pc3               0.792    0.009   86.846    0.000 #>   BEH =~                                               #>     b1                1.000                            #>     b2                0.850    0.039   21.738    0.000 #>   INT =~                                               #>     ATT               1.000                            #>     SN                0.670    0.061   11.032    0.000 #>   PBC =~                                               #>     PC                1.000                            #>     PB                0.668    0.072    9.292    0.000 #>   INTxPBC =~                                           #>     ATTPC             1.000                            #>     ATTPB             0.786    0.029   26.650    0.000 #>     SNPC              0.715    0.026   27.124    0.000 #>     SNPB              0.562    0.022   25.714    0.000 #>   ATTPC =~                                             #>     att1pc1           1.000                            #>     att2pc1           0.896    0.012   76.955    0.000 #>     att3pc1           0.784    0.011   71.763    0.000 #>     att1pc2           0.889    0.010   86.420    0.000 #>     att2pc2           0.796    0.014   58.748    0.000 #>     att3pc2           0.688    0.012   55.935    0.000 #>     att1pc3           0.786    0.009   82.801    0.000 #>     att2pc3           0.703    0.012   57.546    0.000 #>     att3pc3           0.610    0.011   54.822    0.000 #>   ATTPB =~                                             #>     att1pb1           1.000                            #>     att2pb1           0.902    0.012   73.281    0.000 #>     att3pb1           0.790    0.011   69.090    0.000 #>     att1pb2           0.911    0.013   69.779    0.000 #>     att2pb2           0.821    0.016   50.353    0.000 #>     att3pb2           0.719    0.015   49.305    0.000 #>     att1pb3           0.769    0.012   63.518    0.000 #>     att2pb3           0.699    0.014   49.233    0.000 #>     att3pb3           0.609    0.013   47.566    0.000 #>   SNPC =~                                              #>     sn1pc1            1.000                            #>     sn2pc1            0.916    0.017   52.984    0.000 #>     sn3pc1            0.773    0.016   48.814    0.000 #>     sn1pc2            0.890    0.011   80.299    0.000 #>     sn2pc2            0.815    0.018   44.884    0.000 #>     sn3pc2            0.684    0.016   42.622    0.000 #>     sn1pc3            0.804    0.010   76.966    0.000 #>     sn2pc3            0.734    0.016   44.770    0.000 #>     sn3pc3            0.624    0.015   42.476    0.000 #>   SNPB =~                                              #>     sn1pb1            1.000                            #>     sn2pb1            0.932    0.018   52.861    0.000 #>     sn3pb1            0.807    0.016   50.349    0.000 #>     sn1pb2            0.921    0.014   67.113    0.000 #>     sn2pb2            0.862    0.020   43.061    0.000 #>     sn3pb2            0.746    0.018   41.358    0.000 #>     sn1pb3            0.782    0.013   61.764    0.000 #>     sn2pb3            0.726    0.018   41.471    0.000 #>     sn3pb3            0.636    0.016   39.286    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   BEH ~                                                #>     PBC               0.211    0.026    8.120    0.000 #>     INT               0.199    0.023    8.696    0.000 #>     INTxPBC           0.139    0.017    8.230    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>  .att1pc1 ~~                                           #>    .att2pc2           0.000                            #>    .att2pc3           0.000                            #>    .att3pc2           0.000                            #>    .att3pc3           0.000                            #>  .att2pc1 ~~                                           #>    .att1pc2           0.000                            #>  .att1pc2 ~~                                           #>    .att2pc3           0.000                            #>  .att3pc1 ~~                                           #>    .att1pc2           0.000                            #>  .att1pc2 ~~                                           #>    .att3pc3           0.000                            #>  .att2pc1 ~~                                           #>    .att1pc3           0.000                            #>  .att2pc2 ~~                                           #>    .att1pc3           0.000                            #>  .att3pc1 ~~                                           #>    .att1pc3           0.000                            #>  .att3pc2 ~~                                           #>    .att1pc3           0.000                            #>  .att2pc1 ~~                                           #>    .att3pc2           0.000                            #>    .att3pc3           0.000                            #>  .att3pc1 ~~                                           #>    .att2pc2           0.000                            #>  .att2pc2 ~~                                           #>    .att3pc3           0.000                            #>  .att3pc1 ~~                                           #>    .att2pc3           0.000                            #>  .att3pc2 ~~                                           #>    .att2pc3           0.000                            #>  .att1pc1 ~~                                           #>    .att1pc2           0.228    0.015   15.643    0.000 #>    .att1pc3           0.202    0.013   15.648    0.000 #>    .att2pc1           0.192    0.012   16.158    0.000 #>    .att3pc1           0.171    0.011   16.161    0.000 #>  .att1pc2 ~~                                           #>    .att1pc3           0.182    0.012   15.689    0.000 #>    .att2pc2           0.206    0.011   19.546    0.000 #>    .att3pc2           0.180    0.009   19.366    0.000 #>  .att1pc3 ~~                                           #>    .att2pc3           0.194    0.009   21.544    0.000 #>    .att3pc3           0.165    0.008   20.892    0.000 #>  .att2pc1 ~~                                           #>    .att2pc2           0.265    0.013   19.849    0.000 #>    .att2pc3           0.231    0.012   19.601    0.000 #>    .att3pc1           0.157    0.010   16.172    0.000 #>  .att2pc2 ~~                                           #>    .att2pc3           0.204    0.011   19.396    0.000 #>    .att3pc2           0.165    0.009   19.366    0.000 #>  .att2pc3 ~~                                           #>    .att3pc3           0.150    0.007   20.763    0.000 #>  .att3pc1 ~~                                           #>    .att3pc2           0.266    0.012   22.627    0.000 #>    .att3pc3           0.238    0.011   22.542    0.000 #>  .att3pc2 ~~                                           #>    .att3pc3           0.208    0.009   22.293    0.000 #>  .att1pb1 ~~                                           #>    .att2pb2           0.000                            #>    .att2pb3           0.000                            #>    .att3pb2           0.000                            #>    .att3pb3           0.000                            #>  .att2pb1 ~~                                           #>    .att1pb2           0.000                            #>  .att1pb2 ~~                                           #>    .att2pb3           0.000                            #>  .att3pb1 ~~                                           #>    .att1pb2           0.000                            #>  .att1pb2 ~~                                           #>    .att3pb3           0.000                            #>  .att2pb1 ~~                                           #>    .att1pb3           0.000                            #>  .att2pb2 ~~                                           #>    .att1pb3           0.000                            #>  .att3pb1 ~~                                           #>    .att1pb3           0.000                            #>  .att3pb2 ~~                                           #>    .att1pb3           0.000                            #>  .att2pb1 ~~                                           #>    .att3pb2           0.000                            #>    .att3pb3           0.000                            #>  .att3pb1 ~~                                           #>    .att2pb2           0.000                            #>  .att2pb2 ~~                                           #>    .att3pb3           0.000                            #>  .att3pb1 ~~                                           #>    .att2pb3           0.000                            #>  .att3pb2 ~~                                           #>    .att2pb3           0.000                            #>  .att1pb1 ~~                                           #>    .att1pb2           0.178    0.011   16.118    0.000 #>    .att1pb3           0.150    0.010   15.776    0.000 #>    .att2pb1           0.196    0.012   16.080    0.000 #>    .att3pb1           0.164    0.011   15.563    0.000 #>  .att1pb2 ~~                                           #>    .att1pb3           0.142    0.009   15.903    0.000 #>    .att2pb2           0.228    0.012   19.763    0.000 #>    .att3pb2           0.195    0.010   19.467    0.000 #>  .att1pb3 ~~                                           #>    .att2pb3           0.212    0.010   22.266    0.000 #>    .att3pb3           0.184    0.008   22.055    0.000 #>  .att2pb1 ~~                                           #>    .att2pb2           0.201    0.010   19.667    0.000 #>    .att2pb3           0.170    0.009   19.380    0.000 #>    .att3pb1           0.151    0.010   15.533    0.000 #>  .att2pb2 ~~                                           #>    .att2pb3           0.158    0.008   19.210    0.000 #>    .att3pb2           0.191    0.010   19.989    0.000 #>  .att2pb3 ~~                                           #>    .att3pb3           0.165    0.008   21.609    0.000 #>  .att3pb1 ~~                                           #>    .att3pb2           0.189    0.009   21.673    0.000 #>    .att3pb3           0.162    0.008   21.467    0.000 #>  .att3pb2 ~~                                           #>    .att3pb3           0.149    0.007   21.111    0.000 #>  .sn1pc1 ~~                                            #>    .sn2pc2            0.000                            #>    .sn2pc3            0.000                            #>    .sn3pc2            0.000                            #>    .sn3pc3            0.000                            #>  .sn2pc1 ~~                                            #>    .sn1pc2            0.000                            #>  .sn1pc2 ~~                                            #>    .sn2pc3            0.000                            #>  .sn3pc1 ~~                                            #>    .sn1pc2            0.000                            #>  .sn1pc2 ~~                                            #>    .sn3pc3            0.000                            #>  .sn2pc1 ~~                                            #>    .sn1pc3            0.000                            #>  .sn2pc2 ~~                                            #>    .sn1pc3            0.000                            #>  .sn3pc1 ~~                                            #>    .sn1pc3            0.000                            #>  .sn3pc2 ~~                                            #>    .sn1pc3            0.000                            #>  .sn2pc1 ~~                                            #>    .sn3pc2            0.000                            #>    .sn3pc3            0.000                            #>  .sn3pc1 ~~                                            #>    .sn2pc2            0.000                            #>  .sn2pc2 ~~                                            #>    .sn3pc3            0.000                            #>  .sn3pc1 ~~                                            #>    .sn2pc3            0.000                            #>  .sn3pc2 ~~                                            #>    .sn2pc3            0.000                            #>  .sn1pc1 ~~                                            #>    .sn1pc2            0.235    0.014   17.052    0.000 #>    .sn1pc3            0.211    0.012   17.095    0.000 #>    .sn2pc1            0.103    0.007   15.796    0.000 #>    .sn3pc1            0.092    0.006   15.750    0.000 #>  .sn1pc2 ~~                                            #>    .sn1pc3            0.178    0.011   16.493    0.000 #>    .sn2pc2            0.106    0.006   18.376    0.000 #>    .sn3pc2            0.091    0.005   18.007    0.000 #>  .sn1pc3 ~~                                            #>    .sn2pc3            0.103    0.005   20.203    0.000 #>    .sn3pc3            0.087    0.004   19.503    0.000 #>  .sn2pc1 ~~                                            #>    .sn2pc2            0.261    0.013   20.103    0.000 #>    .sn2pc3            0.228    0.011   19.894    0.000 #>    .sn3pc1            0.083    0.005   15.378    0.000 #>  .sn2pc2 ~~                                            #>    .sn2pc3            0.206    0.010   20.014    0.000 #>    .sn3pc2            0.087    0.005   18.174    0.000 #>  .sn2pc3 ~~                                            #>    .sn3pc3            0.082    0.004   19.532    0.000 #>  .sn3pc1 ~~                                            #>    .sn3pc2            0.255    0.011   23.013    0.000 #>    .sn3pc3            0.227    0.010   22.859    0.000 #>  .sn3pc2 ~~                                            #>    .sn3pc3            0.198    0.009   22.679    0.000 #>  .sn1pb1 ~~                                            #>    .sn2pb2            0.000                            #>    .sn2pb3            0.000                            #>    .sn3pb2            0.000                            #>    .sn3pb3            0.000                            #>  .sn2pb1 ~~                                            #>    .sn1pb2            0.000                            #>  .sn1pb2 ~~                                            #>    .sn2pb3            0.000                            #>  .sn3pb1 ~~                                            #>    .sn1pb2            0.000                            #>  .sn1pb2 ~~                                            #>    .sn3pb3            0.000                            #>  .sn2pb1 ~~                                            #>    .sn1pb3            0.000                            #>  .sn2pb2 ~~                                            #>    .sn1pb3            0.000                            #>  .sn3pb1 ~~                                            #>    .sn1pb3            0.000                            #>  .sn3pb2 ~~                                            #>    .sn1pb3            0.000                            #>  .sn2pb1 ~~                                            #>    .sn3pb2            0.000                            #>    .sn3pb3            0.000                            #>  .sn3pb1 ~~                                            #>    .sn2pb2            0.000                            #>  .sn2pb2 ~~                                            #>    .sn3pb3            0.000                            #>  .sn3pb1 ~~                                            #>    .sn2pb3            0.000                            #>  .sn3pb2 ~~                                            #>    .sn2pb3            0.000                            #>  .sn1pb1 ~~                                            #>    .sn1pb2            0.163    0.010   16.601    0.000 #>    .sn1pb3            0.143    0.009   16.410    0.000 #>    .sn2pb1            0.104    0.006   16.170    0.000 #>    .sn3pb1            0.093    0.006   15.771    0.000 #>  .sn1pb2 ~~                                            #>    .sn1pb3            0.131    0.008   16.144    0.000 #>    .sn2pb2            0.101    0.006   17.420    0.000 #>    .sn3pb2            0.091    0.005   17.177    0.000 #>  .sn1pb3 ~~                                            #>    .sn2pb3            0.099    0.005   20.252    0.000 #>    .sn3pb3            0.094    0.005   20.442    0.000 #>  .sn2pb1 ~~                                            #>    .sn2pb2            0.192    0.010   19.812    0.000 #>    .sn2pb3            0.166    0.009   19.549    0.000 #>    .sn3pb1            0.082    0.005   15.386    0.000 #>  .sn2pb2 ~~                                            #>    .sn2pb3            0.154    0.008   19.408    0.000 #>    .sn3pb2            0.083    0.005   17.108    0.000 #>  .sn2pb3 ~~                                            #>    .sn3pb3            0.080    0.004   19.531    0.000 #>  .sn3pb1 ~~                                            #>    .sn3pb2            0.177    0.008   21.670    0.000 #>    .sn3pb3            0.158    0.007   21.493    0.000 #>  .sn3pb2 ~~                                            #>    .sn3pb3            0.150    0.007   21.690    0.000 #>   INT ~~                                               #>     PBC               0.034    0.033    1.045    0.296 #>     INTxPBC          -0.003    0.035   -0.099    0.921 #>   PBC ~~                                               #>     INTxPBC          -0.120    0.039   -3.063    0.002 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .att1              0.164    0.009   18.496    0.000 #>    .att2              0.150    0.008   19.739    0.000 #>    .att3              0.161    0.007   23.292    0.000 #>    .sn1               0.159    0.008   18.691    0.000 #>    .sn2               0.172    0.008   21.687    0.000 #>    .sn3               0.160    0.007   23.161    0.000 #>    .pb1               0.146    0.009   16.806    0.000 #>    .pb2               0.168    0.008   20.515    0.000 #>    .pb3               0.159    0.007   23.189    0.000 #>    .pc1               0.165    0.009   17.845    0.000 #>    .pc2               0.165    0.008   20.574    0.000 #>    .pc3               0.150    0.007   22.166    0.000 #>    .b1                0.133    0.029    4.600    0.000 #>    .b2                0.189    0.022    8.768    0.000 #>    .att1pc1           0.495    0.022   22.813    0.000 #>    .att2pc1           0.501    0.019   25.991    0.000 #>    .att3pc1           0.468    0.017   28.208    0.000 #>    .att1pc2           0.459    0.018   25.111    0.000 #>    .att2pc2           0.448    0.016   27.871    0.000 #>    .att3pc2           0.406    0.014   29.875    0.000 #>    .att1pc3           0.397    0.015   26.508    0.000 #>    .att2pc3           0.380    0.013   28.927    0.000 #>    .att3pc3           0.343    0.011   30.642    0.000 #>    .att1pb1           0.426    0.018   23.037    0.000 #>    .att2pb1           0.419    0.016   25.558    0.000 #>    .att3pb1           0.356    0.013   26.825    0.000 #>    .att1pb2           0.427    0.017   25.557    0.000 #>    .att2pb2           0.435    0.015   28.402    0.000 #>    .att3pb2           0.364    0.012   29.496    0.000 #>    .att1pb3           0.387    0.014   28.034    0.000 #>    .att2pb3           0.347    0.012   29.384    0.000 #>    .att3pb3           0.299    0.010   30.764    0.000 #>    .sn1pc1            0.414    0.018   23.103    0.000 #>    .sn2pc1            0.404    0.016   24.941    0.000 #>    .sn3pc1            0.392    0.014   27.841    0.000 #>    .sn1pc2            0.340    0.014   23.817    0.000 #>    .sn2pc2            0.363    0.014   26.739    0.000 #>    .sn3pc2            0.321    0.011   28.764    0.000 #>    .sn1pc3            0.296    0.012   25.044    0.000 #>    .sn2pc3            0.300    0.011   27.459    0.000 #>    .sn3pc3            0.271    0.009   29.358    0.000 #>    .sn1pb1            0.320    0.013   23.685    0.000 #>    .sn2pb1            0.325    0.013   25.720    0.000 #>    .sn3pb1            0.292    0.011   27.314    0.000 #>    .sn1pb2            0.287    0.012   24.298    0.000 #>    .sn2pb2            0.298    0.011   26.547    0.000 #>    .sn3pb2            0.267    0.009   28.196    0.000 #>    .sn1pb3            0.256    0.010   26.436    0.000 #>    .sn2pb3            0.248    0.009   27.882    0.000 #>    .sn3pb3            0.235    0.008   29.850    0.000 #>    .ATT               0.342    0.094    3.641    0.000 #>    .SN                0.229    0.043    5.317    0.000 #>    .PB                0.688    0.062   11.176    0.000 #>    .PC                0.503    0.127    3.970    0.000 #>    .BEH               0.545    0.034   16.237    0.000 #>     INT               1.058    0.104   10.185    0.000 #>     PBC               1.201    0.137    8.775    0.000 #>     INTxPBC           1.520    0.089   17.158    0.000 #>    .ATTPC             0.942    0.055   17.182    0.000 #>    .ATTPB             0.729    0.040   18.024    0.000 #>    .SNPC              0.453    0.030   15.307    0.000 #>    .SNPB              0.385    0.023   16.924    0.000"},{"path":"/articles/higher_order_interactions.html","id":"interaction-between-a-first-order-and-a-higher-order-construct","dir":"Articles","previous_headings":"","what":"Interaction between a first order and a higher order construct","title":"higher order interactions","text":"TPB_1SO dataset, INT construct second order construct ATT, SN PBC. example, estimate interaction INT (higher order construct) PBC (first order construct).","code":"tpb <- '   # First order constructs   ATT =~ att1 + att2 + att3   SN  =~ sn1 + sn2 + sn3   PBC =~ pbc1 + pbc2 + pbc3   BEH =~ b1 + b2    # Higher order constructs   INT =~ ATT + PBC + SN    # Higher order interaction   INTxPBC =~ ATT:PBC + SN:PBC + PBC:PBC      # Structural model   BEH ~ PBC + INT + INTxPBC '  est_ca <- modsem(tpb, data = TPB_1SO, method = \"ca\") summary(est_ca) #> modsem (version 1.0.9, approach = ca): #> lavaan 0.6-19 ended normally after 446 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        73 #>   Row rank of the constraints matrix                21 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                              4246.901 #>   Degrees of freedom                               178 #>   P-value (Chi-square)                           0.000 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   ATT =~                                               #>     att1   (l_1_A)    1.000                            #>     att2   (l_2_A)    0.904    0.010   89.441    0.000 #>     att3   (l_3_A)    0.801    0.009   85.442    0.000 #>   SN =~                                                #>     sn1    (l_1_S)    1.000                            #>     sn2    (l_2_S)    0.879    0.013   66.744    0.000 #>     sn3    (l_3_S)    0.780    0.012   63.639    0.000 #>   PBC =~                                               #>     pbc1   (l_1_P)    1.000                            #>     pbc2   (l_2_P)    0.900    0.007  135.630    0.000 #>     pbc3   (l_3_P)    0.776    0.006  125.111    0.000 #>   BEH =~                                               #>     b1     (l_1_B)    1.000                            #>     b2     (l_2_B)    0.863    0.033   26.043    0.000 #>   INT =~                                               #>     ATT   (l_ATT_)    1.000                            #>     PBC   (l_PBC_)    0.783    0.030   26.191    0.000 #>     SN     (l_SN_)    0.717    0.027   26.257    0.000 #>   INTxPBC =~                                           #>     ATTPB (l_ATTP)    1.000                            #>     SNPBC  (l_SNP)    0.735    0.020   35.914    0.000 #>     PBCPB (l_PBCP)    1.011    0.027   36.926    0.000 #>   ATTPBC =~                                            #>     att11 (l_11_A)    1.000                            #>     att22 (l_22_A)    0.813    0.009   87.006    0.000 #>     att33 (l_33_A)    0.621    0.008   82.373    0.000 #>   SNPBC =~                                             #>     sn1p1 (l_11_S)    1.000                            #>     sn2p2 (l_22_S)    0.792    0.012   68.052    0.000 #>     sn3p3 (l_33_S)    0.605    0.009   64.723    0.000 #>   PBCPBC =~                                            #>     pbc11 (l_11_P)    1.000                            #>     pbc22 (l_22_P)    0.810    0.012   67.815    0.000 #>     pbc33 (l_33_P)    0.602    0.010   62.555    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   BEH ~                                                #>     PBC     (G_PB)    0.249    0.052    4.775    0.000 #>     INT   (G_INT_)    0.160    0.056    2.838    0.005 #>     INTPB (G_INTP)    0.221    0.016   13.492    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   INT ~~                                               #>     INTxPBC (C_IN)   -0.019    0.025   -0.758    0.448 #>  .att1pbc1 ~~                                          #>    .att2pb2           0.000                            #>    .att3pb3           0.000                            #>  .att2pbc2 ~~                                          #>    .att3pb3           0.000                            #>  .sn1pbc1 ~~                                           #>    .sn2pbc2           0.000                            #>    .sn3pbc3           0.000                            #>  .sn2pbc2 ~~                                           #>    .sn3pbc3           0.000                            #>  .pbc1pbc1 ~~                                          #>    .pbc2pb2           0.000                            #>    .pbc3pb3           0.000                            #>  .pbc2pbc2 ~~                                          #>    .pbc3pb3           0.000                            #>  #> Intercepts: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .ATTPBC  (M_AT)    0.422    0.013   32.832    0.000 #>    .SNPBC   (M_SN)    0.302    0.010   30.547    0.000 #>    .PBCPBC  (M_PB)    0.575    0.011   51.528    0.000 #>    .att1              1.001    0.023   44.025    0.000 #>    .att2              1.008    0.021   47.861    0.000 #>    .att3              1.002    0.019   52.974    0.000 #>    .sn1               0.974    0.018   55.116    0.000 #>    .sn2               0.982    0.016   60.802    0.000 #>    .sn3               0.991    0.015   67.883    0.000 #>    .pbc1              0.983    0.021   47.193    0.000 #>    .pbc2              0.988    0.020   49.207    0.000 #>    .pbc3              0.998    0.018   54.375    0.000 #>    .b1                1.150    0.020   57.082    0.000 #>    .b2                1.132    0.018   61.428    0.000 #>    .att1pb1           0.391    0.038   10.186    0.000 #>    .att2pb2           0.330    0.032   10.249    0.000 #>    .att3pb3           0.256    0.025   10.137    0.000 #>    .sn1pbc1           0.262    0.029    9.112    0.000 #>    .sn2pbc2           0.226    0.024    9.516    0.000 #>    .sn3pbc3           0.177    0.019    9.454    0.000 #>    .pbc1pb1           0.553    0.038   14.525    0.000 #>    .pbc2pb2           0.501    0.032   15.560    0.000 #>    .pbc3pb3           0.421    0.025   16.843    0.000 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .ATT   (Vr_ATT)    0.346    0.023   15.014    0.000 #>    .SN     (Vr_SN)    0.179    0.013   13.986    0.000 #>    .PBC   (Vr_PBC)    0.245    0.016   15.052    0.000 #>    .BEH     (Z_BE)    0.513    0.029   18.005    0.000 #>     INT   (Vr_INT)    0.539    0.027   19.889    0.000 #>     INTPB (V_INTP)    1.535    0.076   20.148    0.000 #>    .ATTPB (V_ATTP)    0.687    0.022   30.946    0.000 #>    .SNPBC  (V_SNP)    0.354    0.013   27.980    0.000 #>    .PBCPB (V_PBCP)    0.662    0.026   25.764    0.000 #>    .att1   (Vr_t1)    0.150    0.008   18.624    0.000 #>    .att2   (Vr_t2)    0.165    0.007   22.170    0.000 #>    .att3   (Vr_t3)    0.147    0.006   23.582    0.000 #>    .sn1    (Vr_s1)    0.168    0.008   20.991    0.000 #>    .sn2    (Vr_s2)    0.168    0.007   24.105    0.000 #>    .sn3    (Vr_s3)    0.149    0.006   25.303    0.000 #>    .pbc1   (Vr_p1)    0.293    0.009   30.965    0.000 #>    .pbc2   (Vr_p2)    0.340    0.009   38.979    0.000 #>    .pbc3   (Vr_p3)    0.327    0.007   44.262    0.000 #>    .b1     (Vr_b1)    0.144    0.024    6.051    0.000 #>    .b2     (Vr_b2)    0.181    0.018    9.880    0.000 #>    .att11 (Vr_t11)    0.389    0.011   34.052    0.000 #>    .att22 (Vr_t22)    0.378    0.010   39.469    0.000 #>    .att33 (Vr_t33)    0.285    0.007   41.921    0.000 #>    .sn1p1 (Vr_s11)    0.279    0.008   35.023    0.000 #>    .sn2p2 (Vr_s22)    0.256    0.006   39.790    0.000 #>    .sn3p3 (Vr_s33)    0.191    0.005   41.982    0.000 #>    .pbc11 (Vr_p11)    0.423    0.015   28.080    0.000 #>    .pbc22 (Vr_p22)    0.432    0.013   33.193    0.000 #>    .pbc33 (Vr_p33)    0.334    0.009   35.936    0.000 #>  #> Constraints: #>                                                |Slack| #>     V_ATTPBC-((_ATT_INT^2*V_INT+V_ATT)*(_PBC_    0.000 #>     V_11-(_1_ATT^2*(_ATT_INT^2*V_INT+V_ATT)*V    0.000 #>     V_22-(_2_ATT^2*(_ATT_INT^2*V_INT+V_ATT)*V    0.000 #>     V_33-(_3_ATT^2*(_ATT_INT^2*V_INT+V_ATT)*V    0.000 #>     V_SNPBC-((_SN_INT^2*V_INT+V_SN)*(_PBC_INT    0.000 #>     V_11-(_1_SN^2*(_SN_INT^2*V_INT+V_SN)*V_1+    0.000 #>     V_22-(_2_SN^2*(_SN_INT^2*V_INT+V_SN)*V_2+    0.000 #>     V_33-(_3_SN^2*(_SN_INT^2*V_INT+V_SN)*V_3+    0.000 #>     V_PBCPBC-((_PBC_INT^2*V_INT+V_PBC)*(_PBC_    0.000 #>     V_11-(_1_PBC^2*(_PBC_INT^2*V_INT+V_PBC)*V    0.000 #>     V_22-(_2_PBC^2*(_PBC_INT^2*V_INT+V_PBC)*V    0.000 #>     V_33-(_3_PBC^2*(_PBC_INT^2*V_INT+V_PBC)*V    0.000 #>     lmbd_tt1pbc1_ATTPBC-(lmbd_tt1_ATT*_1_PBC)    0.000 #>     lmbd_tt2pbc2_ATTPBC-(lmbd_tt2_ATT*_2_PBC)    0.000 #>     lmbd_tt3pbc3_ATTPBC-(lmbd_tt3_ATT*_3_PBC)    0.000 #>     lmbd_sn1pbc1_SNPBC-(lmbd_sn1_SN*lm_1_PBC)    0.000 #>     lmbd_sn2pbc2_SNPBC-(lmbd_sn2_SN*lm_2_PBC)    0.000 #>     lmbd_sn3pbc3_SNPBC-(lmbd_sn3_SN*lm_3_PBC)    0.000 #>     lmbd_pbc1pbc1_PBCPBC-(lmbd_p1_PBC*_1_PBC)    0.000 #>     lmbd_pbc2pbc2_PBCPBC-(lmbd_p2_PBC*_2_PBC)    0.000 #>     lmbd_pbc3pbc3_PBCPBC-(lmbd_p3_PBC*_3_PBC)    0.000 #>     Mn_ATTPBC-((lmbd_ATT_INT*_PBC_INT*V_INT))    0.000 #>     Mn_SNPBC-((lmbd_PBC_INT*lm_SN_INT*V_INT))    0.000 #>     Mn_PBCPBC-((lmbd_PBC_INT^2*Vr_INT+V_PBC))    0.000  est_dblcent  <- modsem(tpb, data = TPB_1SO, method = \"dblcent\") summary(est_dblcent) #> modsem (version 1.0.9, approach = dblcent): #> lavaan 0.6-19 ended normally after 339 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                       125 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                              6227.020 #>   Degrees of freedom                               505 #>   P-value (Chi-square)                           0.000 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   ATT =~                                               #>     att1              1.000                            #>     att2              0.909    0.011   82.767    0.000 #>     att3              0.802    0.010   80.426    0.000 #>   SN =~                                                #>     sn1               1.000                            #>     sn2               0.891    0.016   54.218    0.000 #>     sn3               0.790    0.015   52.448    0.000 #>   PBC =~                                               #>     pbc1              1.000                            #>     pbc2              0.909    0.014   66.751    0.000 #>     pbc3              0.793    0.013   63.368    0.000 #>   BEH =~                                               #>     b1                1.000                            #>     b2                0.864    0.029   30.237    0.000 #>   INT =~                                               #>     ATT               1.000                            #>     PBC               0.819    0.024   33.977    0.000 #>     SN                0.702    0.021   33.482    0.000 #>   INTxPBC =~                                           #>     ATTPBC            1.000                            #>     SNPBC             0.717    0.017   42.130    0.000 #>     PBCPBC            1.003    0.024   42.678    0.000 #>   ATTPBC =~                                            #>     att1pbc1          1.000                            #>     att2pbc1          0.896    0.010   94.261    0.000 #>     att3pbc1          0.808    0.009   92.565    0.000 #>     att1pbc2          0.899    0.011   79.087    0.000 #>     att2pbc2          0.804    0.013   61.655    0.000 #>     att3pbc2          0.727    0.012   61.499    0.000 #>     att1pbc3          0.752    0.011   70.229    0.000 #>     att2pbc3          0.675    0.012   55.856    0.000 #>     att3pbc3          0.614    0.011   56.951    0.000 #>   SNPBC =~                                             #>     sn1pbc1           1.000                            #>     sn2pbc1           0.884    0.013   65.689    0.000 #>     sn3pbc1           0.783    0.012   63.016    0.000 #>     sn1pbc2           0.893    0.012   76.169    0.000 #>     sn2pbc2           0.791    0.015   51.434    0.000 #>     sn3pbc2           0.693    0.014   49.947    0.000 #>     sn1pbc3           0.771    0.011   70.139    0.000 #>     sn2pbc3           0.673    0.014   48.082    0.000 #>     sn3pbc3           0.601    0.013   47.729    0.000 #>   PBCPBC =~                                            #>     pbc1pbc1          1.000                            #>     pbc2pbc1          0.902    0.010   86.187    0.000 #>     pbc3pbc1          0.764    0.010   79.520    0.000 #>     pbc2pbc2          0.812    0.018   44.917    0.000 #>     pbc3pbc2          0.689    0.013   51.106    0.000 #>     pbc3pbc3          0.590    0.015   40.172    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   BEH ~                                                #>     PBC               0.189    0.043    4.359    0.000 #>     INT               0.187    0.045    4.140    0.000 #>     INTxPBC           0.203    0.015   13.754    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>  .att1pbc1 ~~                                          #>    .att2pbc2          0.000                            #>    .att2pbc3          0.000                            #>    .att3pbc2          0.000                            #>    .att3pbc3          0.000                            #>  .att2pbc1 ~~                                          #>    .att1pbc2          0.000                            #>  .att1pbc2 ~~                                          #>    .att2pbc3          0.000                            #>  .att3pbc1 ~~                                          #>    .att1pbc2          0.000                            #>  .att1pbc2 ~~                                          #>    .att3pbc3          0.000                            #>  .att2pbc1 ~~                                          #>    .att1pbc3          0.000                            #>  .att2pbc2 ~~                                          #>    .att1pbc3          0.000                            #>  .att3pbc1 ~~                                          #>    .att1pbc3          0.000                            #>  .att3pbc2 ~~                                          #>    .att1pbc3          0.000                            #>  .att2pbc1 ~~                                          #>    .att3pbc2          0.000                            #>    .att3pbc3          0.000                            #>  .att3pbc1 ~~                                          #>    .att2pbc2          0.000                            #>  .att2pbc2 ~~                                          #>    .att3pbc3          0.000                            #>  .att3pbc1 ~~                                          #>    .att2pbc3          0.000                            #>  .att3pbc2 ~~                                          #>    .att2pbc3          0.000                            #>  .att1pbc1 ~~                                          #>    .att1pbc2          0.123    0.008   15.877    0.000 #>    .att1pbc3          0.108    0.007   15.606    0.000 #>    .att2pbc1          0.188    0.011   16.599    0.000 #>    .att3pbc1          0.166    0.010   16.500    0.000 #>  .att1pbc2 ~~                                          #>    .att1pbc3          0.098    0.006   15.298    0.000 #>    .att2pbc2          0.211    0.011   19.889    0.000 #>    .att3pbc2          0.194    0.010   20.282    0.000 #>  .att1pbc3 ~~                                          #>    .att2pbc3          0.237    0.010   23.982    0.000 #>    .att3pbc3          0.204    0.009   23.565    0.000 #>  .att2pbc1 ~~                                          #>    .att2pbc2          0.156    0.008   20.453    0.000 #>    .att2pbc3          0.144    0.007   20.721    0.000 #>    .att3pbc1          0.153    0.009   16.556    0.000 #>  .att2pbc2 ~~                                          #>    .att2pbc3          0.130    0.006   20.338    0.000 #>    .att3pbc2          0.174    0.009   19.943    0.000 #>  .att2pbc3 ~~                                          #>    .att3pbc3          0.185    0.008   23.276    0.000 #>  .att3pbc1 ~~                                          #>    .att3pbc2          0.133    0.006   20.972    0.000 #>    .att3pbc3          0.119    0.006   20.773    0.000 #>  .att3pbc2 ~~                                          #>    .att3pbc3          0.107    0.005   20.310    0.000 #>  .sn1pbc1 ~~                                           #>    .sn2pbc2           0.000                            #>    .sn2pbc3           0.000                            #>    .sn3pbc2           0.000                            #>    .sn3pbc3           0.000                            #>  .sn2pbc1 ~~                                           #>    .sn1pbc2           0.000                            #>  .sn1pbc2 ~~                                           #>    .sn2pbc3           0.000                            #>  .sn3pbc1 ~~                                           #>    .sn1pbc2           0.000                            #>  .sn1pbc2 ~~                                           #>    .sn3pbc3           0.000                            #>  .sn2pbc1 ~~                                           #>    .sn1pbc3           0.000                            #>  .sn2pbc2 ~~                                           #>    .sn1pbc3           0.000                            #>  .sn3pbc1 ~~                                           #>    .sn1pbc3           0.000                            #>  .sn3pbc2 ~~                                           #>    .sn1pbc3           0.000                            #>  .sn2pbc1 ~~                                           #>    .sn3pbc2           0.000                            #>    .sn3pbc3           0.000                            #>  .sn3pbc1 ~~                                           #>    .sn2pbc2           0.000                            #>  .sn2pbc2 ~~                                           #>    .sn3pbc3           0.000                            #>  .sn3pbc1 ~~                                           #>    .sn2pbc3           0.000                            #>  .sn3pbc2 ~~                                           #>    .sn2pbc3           0.000                            #>  .sn1pbc1 ~~                                           #>    .sn1pbc2           0.163    0.008   19.281    0.000 #>    .sn1pbc3           0.140    0.007   18.855    0.000 #>    .sn2pbc1           0.092    0.006   15.534    0.000 #>    .sn3pbc1           0.082    0.005   15.167    0.000 #>  .sn1pbc2 ~~                                           #>    .sn1pbc3           0.128    0.007   18.607    0.000 #>    .sn2pbc2           0.103    0.006   18.569    0.000 #>    .sn3pbc2           0.097    0.005   19.080    0.000 #>  .sn1pbc3 ~~                                           #>    .sn2pbc3           0.110    0.005   21.785    0.000 #>    .sn3pbc3           0.099    0.005   21.584    0.000 #>  .sn2pbc1 ~~                                           #>    .sn2pbc2           0.137    0.007   19.800    0.000 #>    .sn2pbc3           0.122    0.006   19.734    0.000 #>    .sn3pbc1           0.074    0.005   15.077    0.000 #>  .sn2pbc2 ~~                                           #>    .sn2pbc3           0.110    0.006   19.347    0.000 #>    .sn3pbc2           0.084    0.005   18.558    0.000 #>  .sn2pbc3 ~~                                           #>    .sn3pbc3           0.087    0.004   21.102    0.000 #>  .sn3pbc1 ~~                                           #>    .sn3pbc2           0.121    0.006   20.829    0.000 #>    .sn3pbc3           0.106    0.005   20.481    0.000 #>  .sn3pbc2 ~~                                           #>    .sn3pbc3           0.094    0.005   20.111    0.000 #>  .pbc1pbc1 ~~                                          #>    .pbc2pbc2          0.000                            #>    .pbc3pbc2          0.000                            #>    .pbc3pbc3          0.000                            #>  .pbc2pbc1 ~~                                          #>    .pbc3pbc3          0.000                            #>  .pbc3pbc1 ~~                                          #>    .pbc2pbc2          0.000                            #>  .pbc2pbc2 ~~                                          #>    .pbc3pbc3          0.000                            #>  .pbc1pbc1 ~~                                          #>    .pbc2pbc1          0.268    0.014   19.031    0.000 #>    .pbc3pbc1          0.240    0.012   19.187    0.000 #>  .pbc2pbc1 ~~                                          #>    .pbc2pbc2          0.302    0.014   22.286    0.000 #>    .pbc3pbc1          0.106    0.006   17.710    0.000 #>    .pbc3pbc2          0.132    0.006   20.914    0.000 #>  .pbc2pbc2 ~~                                          #>    .pbc3pbc2          0.244    0.011   21.890    0.000 #>  .pbc3pbc1 ~~                                          #>    .pbc3pbc2          0.152    0.006   23.891    0.000 #>    .pbc3pbc3          0.272    0.011   24.933    0.000 #>  .pbc3pbc2 ~~                                          #>    .pbc3pbc3          0.243    0.010   24.501    0.000 #>   INT ~~                                               #>     INTxPBC          -0.038    0.033   -1.150    0.250 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .att1              0.152    0.008   18.217    0.000 #>    .att2              0.168    0.008   21.469    0.000 #>    .att3              0.147    0.006   22.691    0.000 #>    .sn1               0.171    0.009   19.842    0.000 #>    .sn2               0.165    0.008   21.850    0.000 #>    .sn3               0.151    0.006   23.313    0.000 #>    .pbc1              0.162    0.009   18.804    0.000 #>    .pbc2              0.167    0.008   21.285    0.000 #>    .pbc3              0.159    0.007   23.501    0.000 #>    .b1                0.144    0.021    6.755    0.000 #>    .b2                0.181    0.017   10.910    0.000 #>    .att1pbc1          0.363    0.016   23.326    0.000 #>    .att2pbc1          0.370    0.014   26.472    0.000 #>    .att3pbc1          0.305    0.011   26.846    0.000 #>    .att1pbc2          0.378    0.014   26.203    0.000 #>    .att2pbc2          0.366    0.013   28.665    0.000 #>    .att3pbc2          0.303    0.010   29.105    0.000 #>    .att1pbc3          0.369    0.013   29.040    0.000 #>    .att2pbc3          0.361    0.011   31.610    0.000 #>    .att3pbc3          0.281    0.009   31.219    0.000 #>    .sn1pbc1           0.306    0.012   25.602    0.000 #>    .sn2pbc1           0.256    0.010   26.184    0.000 #>    .sn3pbc1           0.228    0.008   27.105    0.000 #>    .sn1pbc2           0.300    0.011   27.855    0.000 #>    .sn2pbc2           0.243    0.009   27.943    0.000 #>    .sn3pbc2           0.209    0.007   29.007    0.000 #>    .sn1pbc3           0.260    0.009   29.414    0.000 #>    .sn2pbc3           0.225    0.007   30.173    0.000 #>    .sn3pbc3           0.185    0.006   30.379    0.000 #>    .pbc1pbc1          0.646    0.030   21.568    0.000 #>    .pbc2pbc1          0.306    0.011   27.014    0.000 #>    .pbc3pbc1          0.290    0.010   29.693    0.000 #>    .pbc2pbc2          0.618    0.025   24.778    0.000 #>    .pbc3pbc2          0.271    0.009   30.899    0.000 #>    .pbc3pbc3          0.482    0.018   27.155    0.000 #>    .ATT               0.389    0.025   15.717    0.000 #>    .SN                0.199    0.014   14.732    0.000 #>    .PBC               0.300    0.018   16.350    0.000 #>    .BEH               0.521    0.027   19.503    0.000 #>     INT               0.995    0.049   20.233    0.000 #>     INTxPBC           1.701    0.074   22.836    0.000 #>    .ATTPBC            0.309    0.025   12.116    0.000 #>    .SNPBC             0.193    0.015   12.939    0.000 #>    .PBCPBC            0.206    0.027    7.713    0.000"},{"path":"/articles/interaction_two_etas.html","id":"the-problem","dir":"Articles","previous_headings":"","what":"The Problem","title":"interaction effects between endogenous variables","text":"Interaction effects two endogenous (.e., dependent) variables work expect product indicator methods (\"dblcent\", \"rca\", \"ca\", \"uca\"). However, lms qml approaches, straightforward. lms qml approaches can (default) handle interaction effects endogenous exogenous (.e., independent) variables, natively support interaction effects two endogenous variables. interaction effect exists two endogenous variables, equations easily written “reduced” form, meaning normal estimation procedures won’t work.","code":""},{"path":"/articles/interaction_two_etas.html","id":"the-solution","dir":"Articles","previous_headings":"","what":"The Solution","title":"interaction effects between endogenous variables","text":"Despite limitations, workaround lms qml approaches. Essentially, model can split two parts: one linear one non-linear. can replace covariance matrix used estimation non-linear model model-implied covariance matrix linear model. allows treat endogenous variable exogenous—provided can expressed linear model.","code":""},{"path":"/articles/interaction_two_etas.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"interaction effects between endogenous variables","text":"Let’s consider theory planned behavior (TPB), wish estimate quadratic effect INT BEH (INT:INT). can use following model: Since INT endogenous variable, quadratic term (.e., interaction effect ) involve two endogenous variables. result, normally able estimate model using lms qml approaches. However, can split model two parts: one linear one non-linear. INT endogenous variable, can expressed linear model since affected interaction terms: can remove part original model, giving us: Now, can estimate non-linear model since INT treated exogenous variable. However, incorporate structural model INT. address , can instruct modsem replace covariance matrix (phi) (INT, PBC, ATT, SN) model-implied covariance matrix linear model estimating models simultaneously. achieve , use cov.syntax argument modsem:","code":"tpb <- '  # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC    BEH ~ INT:INT ' tpb_linear <- 'INT ~ PBC + ATT + SN' tpb_nonlinear <- '  # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   BEH ~ INT + PBC    BEH ~ INT:INT ' est_lms <- modsem(tpb_nonlinear, data = TPB, cov.syntax = tpb_linear,                    method = \"lms\") #> Warning: It is recommended that you have at least 48 nodes for interaction #> effects between endogenous variables in the lms approach 'nodes = 24' summary(est_lms) #> Estimating baseline model (H0) #>  #> modsem (version 1.0.9): #>   Estimator                                         LMS #>   Optimization method                         EM-NLMINB #>   Number of observations                           2000 #>   Number of iterations                               52 #>   Loglikelihood                               -23780.97 #>   Akaike (AIC)                                 47669.94 #>   Bayesian (BIC)                               47972.38 #>   #> Numerical Integration: #>   Points of integration (per dim)                    24 #>   Dimensions                                          1 #>   Total points of integration                        24 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -26393 #>   Akaike (AIC)                                 52892.45 #>   Bayesian (BIC)                               53189.29 #>   Chi-square                                      66.27 #>   Degrees of Freedom (Chi-square)                    82 #>   P-value (Chi-square)                            0.897 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                          2612.25 #>   Difference test (D)                           5224.51 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   BEH                                             0.235 #>   INT                                             0.364 #> R-Squared Null-Model (H0): #>   BEH                                             0.210 #>   INT                                             0.367 #> R-Squared Change: #>   BEH                                             0.025 #>   INT                                            -0.002 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   INT =~  #>     int1             1.000                              #>     int2             0.915      0.016    58.36    0.000 #>     int3             0.807      0.015    55.23    0.000 #>   ATT =~  #>     att1             1.000                              #>     att2             0.878      0.012    71.58    0.000 #>     att3             0.789      0.012    66.38    0.000 #>     att4             0.695      0.011    61.01    0.000 #>     att5             0.887      0.013    70.86    0.000 #>   SN =~  #>     sn1              1.000                              #>     sn2              0.888      0.017    52.60    0.000 #>   PBC =~  #>     pbc1             1.000                              #>     pbc2             0.913      0.013    69.38    0.000 #>     pbc3             0.801      0.012    66.07    0.000 #>   BEH =~  #>     b1               1.000                              #>     b2               0.960      0.032    29.93    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   BEH ~  #>     INT              0.197      0.026     7.65    0.000 #>     PBC              0.238      0.023    10.57    0.000 #>     INT:INT          0.128      0.016     7.90    0.000 #>   INT ~  #>     PBC              0.219      0.029     7.48    0.000 #>     ATT              0.210      0.026     8.16    0.000 #>     SN               0.171      0.027     6.28    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     int1             1.008      0.023    43.42    0.000 #>     int2             1.007      0.022    46.74    0.000 #>     int3             1.000      0.020    51.07    0.000 #>     att1             1.011      0.025    40.95    0.000 #>     att2             1.005      0.022    45.83    0.000 #>     att3             1.014      0.020    50.28    0.000 #>     att4             0.997      0.018    54.46    0.000 #>     att5             0.990      0.022    44.57    0.000 #>     sn1              1.003      0.025    40.68    0.000 #>     sn2              1.008      0.022    45.64    0.000 #>     pbc1             0.995      0.024    41.28    0.000 #>     pbc2             0.982      0.022    43.79    0.000 #>     pbc3             0.989      0.020    49.23    0.000 #>     b1               0.997      0.024    42.37    0.000 #>     b2               1.016      0.022    45.94    0.000 #>     BEH              0.000                              #>     INT              0.000                              #>     ATT              0.000                              #>     SN               0.000                              #>     PBC              0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC ~~  #>     ATT              0.673      0.028    23.68    0.000 #>     SN               0.673      0.029    23.31    0.000 #>   ATT ~~  #>     SN               0.624      0.029    21.89    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     int1             0.161      0.009    18.38    0.000 #>     int2             0.161      0.008    20.16    0.000 #>     int3             0.170      0.007    23.72    0.000 #>     att1             0.167      0.007    23.54    0.000 #>     att2             0.150      0.006    24.73    0.000 #>     att3             0.159      0.006    26.39    0.000 #>     att4             0.162      0.006    27.66    0.000 #>     att5             0.159      0.006    24.94    0.000 #>     sn1              0.178      0.015    12.07    0.000 #>     sn2              0.157      0.012    13.27    0.000 #>     pbc1             0.145      0.008    18.45    0.000 #>     pbc2             0.160      0.007    21.42    0.000 #>     pbc3             0.154      0.006    23.80    0.000 #>     b1               0.185      0.020     9.42    0.000 #>     b2               0.135      0.018     7.61    0.000 #>     BEH              0.475      0.024    19.74    0.000 #>     PBC              0.956      0.035    27.28    0.000 #>     ATT              0.993      0.037    27.14    0.000 #>     SN               0.983      0.039    25.41    0.000 #>     INT              0.481      0.020    24.35    0.000  est_qml <- modsem(tpb_nonlinear, data = TPB, cov.syntax = tpb_linear,                    method = \"qml\") summary(est_qml) #> Estimating baseline model (H0) #>  #> modsem (version 1.0.9): #>   Estimator                                         QML #>   Optimization method                            NLMINB #>   Number of observations                           2000 #>   Number of iterations                               66 #>   Loglikelihood                               -26360.52 #>   Akaike (AIC)                                 52829.04 #>   Bayesian (BIC)                               53131.49 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -26393 #>   Akaike (AIC)                                 52892.45 #>   Bayesian (BIC)                               53189.29 #>   Chi-square                                      66.27 #>   Degrees of Freedom (Chi-square)                    82 #>   P-value (Chi-square)                            0.897 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                            32.70 #>   Difference test (D)                             65.41 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   BEH                                             0.239 #>   INT                                             0.370 #> R-Squared Null-Model (H0): #>   BEH                                             0.210 #>   INT                                             0.367 #> R-Squared Change: #>   BEH                                             0.029 #>   INT                                             0.003 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   INT =~  #>     int1             1.000                              #>     int2             0.914      0.015    59.03    0.000 #>     int3             0.807      0.015    55.65    0.000 #>   ATT =~  #>     att1             1.000                              #>     att2             0.878      0.012    71.56    0.000 #>     att3             0.789      0.012    66.38    0.000 #>     att4             0.695      0.011    61.00    0.000 #>     att5             0.887      0.013    70.85    0.000 #>   SN =~  #>     sn1              1.000                              #>     sn2              0.888      0.017    52.62    0.000 #>   PBC =~  #>     pbc1             1.000                              #>     pbc2             0.913      0.013    69.38    0.000 #>     pbc3             0.801      0.012    66.08    0.000 #>   BEH =~  #>     b1               1.000                              #>     b2               0.960      0.032    29.90    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   BEH ~  #>     INT              0.197      0.025     7.76    0.000 #>     PBC              0.239      0.023    10.59    0.000 #>     INT:INT          0.128      0.016     7.88    0.000 #>   INT ~  #>     PBC              0.222      0.030     7.51    0.000 #>     ATT              0.213      0.026     8.17    0.000 #>     SN               0.175      0.028     6.33    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     int1             1.014      0.022    46.96    0.000 #>     int2             1.012      0.020    50.40    0.000 #>     int3             1.005      0.018    54.80    0.000 #>     att1             1.014      0.024    42.01    0.000 #>     att2             1.007      0.021    46.97    0.000 #>     att3             1.016      0.020    51.45    0.000 #>     att4             0.999      0.018    55.65    0.000 #>     att5             0.992      0.022    45.67    0.000 #>     sn1              1.006      0.024    41.66    0.000 #>     sn2              1.010      0.022    46.71    0.000 #>     pbc1             0.998      0.024    42.41    0.000 #>     pbc2             0.985      0.022    44.93    0.000 #>     pbc3             0.991      0.020    50.45    0.000 #>     b1               0.999      0.023    42.63    0.000 #>     b2               1.017      0.022    46.24    0.000 #>     BEH              0.000                              #>     INT              0.000                              #>     ATT              0.000                              #>     SN               0.000                              #>     PBC              0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC ~~  #>     ATT              0.678      0.029    23.45    0.000 #>     SN               0.678      0.029    23.08    0.000 #>   ATT ~~  #>     SN               0.629      0.029    21.70    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     int1             0.158      0.009    18.22    0.000 #>     int2             0.160      0.008    20.38    0.000 #>     int3             0.168      0.007    23.63    0.000 #>     att1             0.167      0.007    23.53    0.000 #>     att2             0.150      0.006    24.71    0.000 #>     att3             0.160      0.006    26.38    0.000 #>     att4             0.162      0.006    27.65    0.000 #>     att5             0.159      0.006    24.93    0.000 #>     sn1              0.178      0.015    12.09    0.000 #>     sn2              0.157      0.012    13.26    0.000 #>     pbc1             0.145      0.008    18.44    0.000 #>     pbc2             0.160      0.007    21.42    0.000 #>     pbc3             0.154      0.006    23.80    0.000 #>     b1               0.185      0.020     9.42    0.000 #>     b2               0.135      0.018     7.60    0.000 #>     BEH              0.475      0.024    19.74    0.000 #>     PBC              0.962      0.036    27.04    0.000 #>     ATT              0.998      0.037    26.93    0.000 #>     SN               0.988      0.039    25.23    0.000 #>     INT              0.488      0.020    24.59    0.000"},{"path":"/articles/lms_qml.html","id":"the-latent-moderated-structural-equations-lms-and-the-quasi-maximum-likelihood-qml-approach","dir":"Articles","previous_headings":"","what":"The Latent Moderated Structural Equations (LMS) and the Quasi Maximum Likelihood (QML) Approach","title":"LMS and QML approaches","text":"LMS QML approaches work models, interaction effects endogenous variables can tricky estimate (see vignette). approaches, particularly LMS approach, computationally intensive partially implemented C++ (using Rcpp RcppArmadillo). Additionally, starting parameters estimated using double-centering approach, means observed variables used generate good starting parameters faster convergence. want monitor progress estimation process, can use verbose = TRUE.","code":""},{"path":"/articles/lms_qml.html","id":"a-simple-example","dir":"Articles","previous_headings":"The Latent Moderated Structural Equations (LMS) and the Quasi Maximum Likelihood (QML) Approach","what":"A Simple Example","title":"LMS and QML approaches","text":"example LMS approach simple model. default, summary() function calculates fit measures compared null model (.e., model without interaction term). example using QML approach:","code":"library(modsem) m1 <- ' # Outer Model   X =~ x1 + x2 + x3   Z =~ z1 + z2 + z3   Y =~ y1 + y2 + y3  # Inner Model   Y ~ X + Z + X:Z '  lms1 <- modsem(m1, oneInt, method = \"lms\") # Standardized estimates summary(lms1, standardized = TRUE) #> Estimating baseline model (H0) #>  #> modsem (version 1.0.9): #>   Estimator                                         LMS #>   Optimization method                         EM-NLMINB #>   Number of observations                           2000 #>   Number of iterations                              119 #>   Loglikelihood                               -14687.74 #>   Akaike (AIC)                                 29437.48 #>   Bayesian (BIC)                               29611.11 #>   #> Numerical Integration: #>   Points of integration (per dim)                    24 #>   Dimensions                                          1 #>   Total points of integration                        24 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -17832 #>   Akaike (AIC)                                 35723.75 #>   Bayesian (BIC)                               35891.78 #>   Chi-square                                      17.52 #>   Degrees of Freedom (Chi-square)                    24 #>   P-value (Chi-square)                            0.826 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                          3144.13 #>   Difference test (D)                           6288.27 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   Y                                               0.595 #> R-Squared Null-Model (H0): #>   Y                                               0.395 #> R-Squared Change: #>   Y                                               0.200 #>  #> Parameter Estimates: #>   Coefficients                             standardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X =~  #>     x1               0.926      0.004   211.25    0.000 #>     x2               0.891      0.005   166.74    0.000 #>     x3               0.912      0.005   191.35    0.000 #>   Z =~  #>     z1               0.927      0.005   201.87    0.000 #>     z2               0.898      0.005   166.70    0.000 #>     z3               0.913      0.005   183.65    0.000 #>   Y =~  #>     y1               0.961      0.003   369.42    0.000 #>     y2               0.942      0.003   288.63    0.000 #>     y3               0.951      0.003   325.98    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   Y ~  #>     X                0.481      0.018    26.07    0.000 #>     Z                0.416      0.019    21.41    0.000 #>     X:Z              0.513      0.023    22.63    0.000 #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X ~~  #>     Z                0.199      0.023     8.72    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               0.142      0.008    17.63    0.000 #>     x2               0.206      0.009    21.70    0.000 #>     x3               0.169      0.009    19.50    0.000 #>     z1               0.141      0.009    16.44    0.000 #>     z2               0.193      0.010    19.86    0.000 #>     z3               0.167      0.009    18.24    0.000 #>     y1               0.077      0.005    15.19    0.000 #>     y2               0.113      0.006    18.41    0.000 #>     y3               0.096      0.006    17.23    0.000 #>     X                1.000                              #>     Z                1.000                              #>     Y                0.516      0.020    25.71    0.000 qml1 <- modsem(m1, oneInt, method = \"qml\") summary(qml1) #> Estimating baseline model (H0) #>  #> modsem (version 1.0.9): #>   Estimator                                         QML #>   Optimization method                            NLMINB #>   Number of observations                           2000 #>   Number of iterations                              110 #>   Loglikelihood                               -17496.22 #>   Akaike (AIC)                                 35054.43 #>   Bayesian (BIC)                               35228.06 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -17832 #>   Akaike (AIC)                                 35723.75 #>   Bayesian (BIC)                               35891.78 #>   Chi-square                                      17.52 #>   Degrees of Freedom (Chi-square)                    24 #>   P-value (Chi-square)                            0.826 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                           335.66 #>   Difference test (D)                            671.32 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   Y                                               0.607 #> R-Squared Null-Model (H0): #>   Y                                               0.395 #> R-Squared Change: #>   Y                                               0.211 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X =~  #>     x1               1.000                              #>     x2               0.803      0.013    63.96    0.000 #>     x3               0.914      0.013    67.80    0.000 #>   Z =~  #>     z1               1.000                              #>     z2               0.810      0.012    65.12    0.000 #>     z3               0.881      0.013    67.62    0.000 #>   Y =~  #>     y1               1.000                              #>     y2               0.798      0.007   107.57    0.000 #>     y3               0.899      0.008   112.55    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   Y ~  #>     X                0.674      0.032    20.94    0.000 #>     Z                0.566      0.030    18.96    0.000 #>     X:Z              0.712      0.028    25.46    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               1.023      0.024    42.89    0.000 #>     x2               1.215      0.020    60.99    0.000 #>     x3               0.919      0.022    41.48    0.000 #>     z1               1.012      0.024    41.57    0.000 #>     z2               1.206      0.020    59.27    0.000 #>     z3               0.916      0.022    42.06    0.000 #>     y1               1.038      0.033    31.45    0.000 #>     y2               1.221      0.027    45.49    0.000 #>     y3               0.955      0.030    31.86    0.000 #>     Y                0.000                              #>     X                0.000                              #>     Z                0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X ~~  #>     Z                0.200      0.024     8.24    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               0.158      0.009    18.14    0.000 #>     x2               0.162      0.007    23.19    0.000 #>     x3               0.165      0.008    20.82    0.000 #>     z1               0.166      0.009    18.34    0.000 #>     z2               0.159      0.007    22.62    0.000 #>     z3               0.158      0.008    20.71    0.000 #>     y1               0.159      0.009    17.98    0.000 #>     y2               0.154      0.007    22.67    0.000 #>     y3               0.164      0.008    20.71    0.000 #>     X                0.983      0.036    26.99    0.000 #>     Z                1.019      0.038    26.95    0.000 #>     Y                0.943      0.038    24.87    0.000"},{"path":"/articles/lms_qml.html","id":"a-more-complicated-example","dir":"Articles","previous_headings":"The Latent Moderated Structural Equations (LMS) and the Quasi Maximum Likelihood (QML) Approach","what":"A More Complicated Example","title":"LMS and QML approaches","text":"example complex model based theory planned behavior (TPB), includes two endogenous variables interaction endogenous exogenous variable. estimating complex models LMS approach, recommended increase number nodes used numerical integration. default, number nodes set 16, can increased using nodes argument. nodes argument effect QML approach. interaction effect endogenous exogenous variable, recommended use least 32 nodes LMS approach. can also obtain robust standard errors setting robust.se = TRUE modsem() function. Note: want LMS approach produce results similar possible Mplus, increase number nodes (e.g., nodes = 100).","code":"# ATT = Attitude # PBC = Perceived Behavioral Control # INT = Intention # SN = Subjective Norms # BEH = Behavior tpb <- '  # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC    BEH ~ INT:PBC   '  lms2 <- modsem(tpb, TPB, method = \"lms\", nodes = 32) summary(lms2) #> Estimating baseline model (H0) #>  #> modsem (version 1.0.9): #>   Estimator                                         LMS #>   Optimization method                         EM-NLMINB #>   Number of observations                           2000 #>   Number of iterations                               46 #>   Loglikelihood                               -23439.19 #>   Akaike (AIC)                                 46986.39 #>   Bayesian (BIC)                               47288.84 #>   #> Numerical Integration: #>   Points of integration (per dim)                    32 #>   Dimensions                                          1 #>   Total points of integration                        32 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -26393 #>   Akaike (AIC)                                 52892.45 #>   Bayesian (BIC)                               53189.29 #>   Chi-square                                      66.27 #>   Degrees of Freedom (Chi-square)                    82 #>   P-value (Chi-square)                            0.897 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                          2954.03 #>   Difference test (D)                           5908.06 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   INT                                             0.364 #>   BEH                                             0.259 #> R-Squared Null-Model (H0): #>   INT                                             0.367 #>   BEH                                             0.210 #> R-Squared Change: #>   INT                                            -0.003 #>   BEH                                             0.049 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC =~  #>     pbc1             1.000                              #>     pbc2             0.914      0.013    69.44    0.000 #>     pbc3             0.802      0.012    65.99    0.000 #>   ATT =~  #>     att1             1.000                              #>     att2             0.878      0.012    71.56    0.000 #>     att3             0.789      0.012    66.38    0.000 #>     att4             0.695      0.011    61.00    0.000 #>     att5             0.887      0.013    70.85    0.000 #>   SN =~  #>     sn1              1.000                              #>     sn2              0.889      0.017    52.61    0.000 #>   INT =~  #>     int1             1.000                              #>     int2             0.913      0.015    59.06    0.000 #>     int3             0.807      0.014    55.74    0.000 #>   BEH =~  #>     b1               1.000                              #>     b2               0.959      0.030    31.76    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   INT ~  #>     PBC              0.217      0.030     7.33    0.000 #>     ATT              0.214      0.026     8.18    0.000 #>     SN               0.177      0.028     6.38    0.000 #>   BEH ~  #>     PBC              0.233      0.022    10.40    0.000 #>     INT              0.188      0.025     7.61    0.000 #>     PBC:INT          0.205      0.018    11.29    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     pbc1             0.992      0.024    41.31    0.000 #>     pbc2             0.980      0.022    43.82    0.000 #>     pbc3             0.987      0.020    49.27    0.000 #>     att1             1.011      0.024    41.46    0.000 #>     att2             1.004      0.022    46.39    0.000 #>     att3             1.014      0.020    50.86    0.000 #>     att4             0.997      0.018    55.06    0.000 #>     att5             0.989      0.022    45.11    0.000 #>     sn1              1.002      0.024    41.11    0.000 #>     sn2              1.007      0.022    46.12    0.000 #>     int1             1.012      0.022    46.58    0.000 #>     int2             1.010      0.020    50.01    0.000 #>     int3             1.003      0.018    54.41    0.000 #>     b1               1.000      0.021    46.83    0.000 #>     b2               1.018      0.020    50.91    0.000 #>     INT              0.000                              #>     BEH              0.000                              #>     PBC              0.000                              #>     ATT              0.000                              #>     SN               0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC ~~  #>     ATT              0.668      0.028    23.55    0.000 #>     SN               0.668      0.029    23.21    0.000 #>   ATT ~~  #>     SN               0.623      0.029    21.84    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     pbc1             0.148      0.008    19.19    0.000 #>     pbc2             0.159      0.007    21.26    0.000 #>     pbc3             0.155      0.006    23.85    0.000 #>     att1             0.167      0.007    23.54    0.000 #>     att2             0.150      0.006    24.72    0.000 #>     att3             0.159      0.006    26.39    0.000 #>     att4             0.162      0.006    27.65    0.000 #>     att5             0.159      0.006    24.93    0.000 #>     sn1              0.178      0.015    12.12    0.000 #>     sn2              0.156      0.012    13.23    0.000 #>     int1             0.157      0.009    18.11    0.000 #>     int2             0.160      0.008    20.41    0.000 #>     int3             0.168      0.007    23.55    0.000 #>     b1               0.185      0.018    10.08    0.000 #>     b2               0.136      0.017     8.18    0.000 #>     PBC              0.947      0.035    27.24    0.000 #>     ATT              0.992      0.037    27.12    0.000 #>     SN               0.981      0.039    25.39    0.000 #>     INT              0.491      0.020    24.64    0.000 #>     BEH              0.456      0.023    20.14    0.000  qml2 <- modsem(tpb, TPB, method = \"qml\") summary(qml2, standardized = TRUE) # Standardized estimates #> Estimating baseline model (H0) #>  #> modsem (version 1.0.9): #>   Estimator                                         QML #>   Optimization method                            NLMINB #>   Number of observations                           2000 #>   Number of iterations                               73 #>   Loglikelihood                               -26326.25 #>   Akaike (AIC)                                  52760.5 #>   Bayesian (BIC)                               53062.95 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -26393 #>   Akaike (AIC)                                 52892.45 #>   Bayesian (BIC)                               53189.29 #>   Chi-square                                      66.27 #>   Degrees of Freedom (Chi-square)                    82 #>   P-value (Chi-square)                            0.897 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                            66.97 #>   Difference test (D)                            133.95 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   INT                                             0.366 #>   BEH                                             0.263 #> R-Squared Null-Model (H0): #>   INT                                             0.367 #>   BEH                                             0.210 #> R-Squared Change: #>   INT                                             0.000 #>   BEH                                             0.053 #>  #> Parameter Estimates: #>   Coefficients                             standardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC =~  #>     pbc1             0.933      0.004   217.38    0.000 #>     pbc2             0.913      0.005   189.94    0.000 #>     pbc3             0.894      0.005   163.46    0.000 #>   ATT =~  #>     att1             0.925      0.004   240.19    0.000 #>     att2             0.915      0.004   211.80    0.000 #>     att3             0.892      0.005   173.63    0.000 #>     att4             0.865      0.006   138.97    0.000 #>     att5             0.912      0.004   207.47    0.000 #>   SN =~  #>     sn1              0.921      0.007   128.23    0.000 #>     sn2              0.913      0.007   125.71    0.000 #>   INT =~  #>     int1             0.912      0.006   163.04    0.000 #>     int2             0.895      0.006   146.66    0.000 #>     int3             0.866      0.007   125.52    0.000 #>   BEH =~  #>     b1               0.870      0.014    62.27    0.000 #>     b2               0.894      0.014    64.03    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   INT ~  #>     PBC              0.243      0.032     7.47    0.000 #>     ATT              0.242      0.029     8.27    0.000 #>     SN               0.199      0.031     6.43    0.000 #>   BEH ~  #>     PBC              0.299      0.027    10.99    0.000 #>     INT              0.219      0.028     7.89    0.000 #>     PBC:INT          0.235      0.021    11.01    0.000 #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC ~~  #>     ATT              0.692      0.013    53.44    0.000 #>     SN               0.695      0.014    51.47    0.000 #>   ATT ~~  #>     SN               0.634      0.015    42.01    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     pbc1             0.130      0.008    16.25    0.000 #>     pbc2             0.166      0.009    18.71    0.000 #>     pbc3             0.201      0.010    20.49    0.000 #>     att1             0.144      0.007    20.09    0.000 #>     att2             0.164      0.008    20.87    0.000 #>     att3             0.204      0.009    22.08    0.000 #>     att4             0.252      0.011    23.48    0.000 #>     att5             0.168      0.008    20.96    0.000 #>     sn1              0.153      0.013    11.49    0.000 #>     sn2              0.167      0.013    12.53    0.000 #>     int1             0.168      0.010    16.45    0.000 #>     int2             0.199      0.011    18.27    0.000 #>     int3             0.249      0.012    20.82    0.000 #>     b1               0.244      0.024    10.05    0.000 #>     b2               0.202      0.025     8.03    0.000 #>     PBC              1.000                              #>     ATT              1.000                              #>     SN               1.000                              #>     INT              0.634      0.019    33.92    0.000 #>     BEH              0.790      0.019    41.41    0.000"},{"path":"/articles/methods.html","id":"product-indicator-pi-approaches","dir":"Articles","previous_headings":"","what":"Product Indicator (PI) Approaches:","title":"methods","text":"Note constraints can become quite complicated complex models, particularly interaction including enodgenous variables. method can therefore quite slow. \"uca\" = unconstrained approach (Marsh, 2004) \"rca\" = residual centering approach (Little et al., 2006) default \"pind\" = basic product indicator approach (recommended)","code":""},{"path":"/articles/methods.html","id":"distribution-analytic-da-approaches","dir":"Articles","previous_headings":"","what":"Distribution Analytic (DA) Approaches","title":"methods","text":"\"lms\" = Latent Moderated Structural equations (LMS) approach, see vignette \"qml\" = Quasi Maximum Likelihood (QML) approach, see vignette estimates model Mplus, installed","code":"m1 <- ' # Outer Model X =~ x1 + x2 + x3 Y =~ y1 + y2 + y3 Z =~ z1 + z2 + z3  # Inner model Y ~ X + Z + X:Z  '  # Product Indicator Approaches modsem(m1, data = oneInt, method = \"ca\") modsem(m1, data = oneInt, method = \"uca\") modsem(m1, data = oneInt, method = \"rca\") modsem(m1, data = oneInt, method = \"dblcent\")  # Distribution Analytic Approaches modsem(m1, data = oneInt, method = \"mplus\") modsem(m1, data = oneInt, method = \"lms\") modsem(m1, data = oneInt, method = \"qml\")"},{"path":"/articles/modsem.html","id":"the-basic-syntax","dir":"Articles","previous_headings":"","what":"The Basic Syntax","title":"modsem","text":"modsem introduces new feature lavaan syntax—semicolon operator (:). semicolon operator works way lm() function. specify interaction effect two variables, join Var1:Var2. Models can estimated using one product indicator approaches (\"ca\", \"rca\", \"dblcent\", \"pind\") using latent moderated structural equations approach (\"lms\") quasi maximum likelihood approach (\"qml\"). product indicator approaches estimated via lavaan, lms qml approaches estimated via modsem .","code":""},{"path":"/articles/modsem.html","id":"a-simple-example","dir":"Articles","previous_headings":"The Basic Syntax","what":"A Simple Example","title":"modsem","text":"simple example specify interaction effect two latent variables lavaan. default, model estimated using \"dblcent\" method. want use another method, can change using method argument.","code":"m1 <- '   # Outer Model   X =~ x1 + x2 + x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3      # Inner Model   Y ~ X + Z + X:Z  '  est1 <- modsem(m1, oneInt) summary(est1) #> modsem (version 1.0.9, approach = dblcent): #> lavaan 0.6-19 ended normally after 161 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        60 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                               122.924 #>   Degrees of freedom                               111 #>   P-value (Chi-square)                           0.207 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   X =~                                                 #>     x1                1.000                            #>     x2                0.804    0.013   63.612    0.000 #>     x3                0.916    0.014   67.144    0.000 #>   Y =~                                                 #>     y1                1.000                            #>     y2                0.798    0.007  107.428    0.000 #>     y3                0.899    0.008  112.453    0.000 #>   Z =~                                                 #>     z1                1.000                            #>     z2                0.812    0.013   64.763    0.000 #>     z3                0.882    0.013   67.014    0.000 #>   XZ =~                                                #>     x1z1              1.000                            #>     x2z1              0.805    0.013   60.636    0.000 #>     x3z1              0.877    0.014   62.680    0.000 #>     x1z2              0.793    0.013   59.343    0.000 #>     x2z2              0.646    0.015   43.672    0.000 #>     x3z2              0.706    0.016   44.292    0.000 #>     x1z3              0.887    0.014   63.700    0.000 #>     x2z3              0.716    0.016   45.645    0.000 #>     x3z3              0.781    0.017   45.339    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   Y ~                                                  #>     X                 0.675    0.027   25.379    0.000 #>     Z                 0.561    0.026   21.606    0.000 #>     XZ                0.702    0.027   26.360    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>  .x1z1 ~~                                              #>    .x2z2              0.000                            #>    .x2z3              0.000                            #>    .x3z2              0.000                            #>    .x3z3              0.000                            #>  .x2z1 ~~                                              #>    .x1z2              0.000                            #>  .x1z2 ~~                                              #>    .x2z3              0.000                            #>  .x3z1 ~~                                              #>    .x1z2              0.000                            #>  .x1z2 ~~                                              #>    .x3z3              0.000                            #>  .x2z1 ~~                                              #>    .x1z3              0.000                            #>  .x2z2 ~~                                              #>    .x1z3              0.000                            #>  .x3z1 ~~                                              #>    .x1z3              0.000                            #>  .x3z2 ~~                                              #>    .x1z3              0.000                            #>  .x2z1 ~~                                              #>    .x3z2              0.000                            #>    .x3z3              0.000                            #>  .x3z1 ~~                                              #>    .x2z2              0.000                            #>  .x2z2 ~~                                              #>    .x3z3              0.000                            #>  .x3z1 ~~                                              #>    .x2z3              0.000                            #>  .x3z2 ~~                                              #>    .x2z3              0.000                            #>  .x1z1 ~~                                              #>    .x1z2              0.115    0.008   14.802    0.000 #>    .x1z3              0.114    0.008   13.947    0.000 #>    .x2z1              0.125    0.008   16.095    0.000 #>    .x3z1              0.140    0.009   16.135    0.000 #>  .x1z2 ~~                                              #>    .x1z3              0.103    0.007   14.675    0.000 #>    .x2z2              0.128    0.006   20.850    0.000 #>    .x3z2              0.146    0.007   21.243    0.000 #>  .x1z3 ~~                                              #>    .x2z3              0.116    0.007   17.818    0.000 #>    .x3z3              0.135    0.007   18.335    0.000 #>  .x2z1 ~~                                              #>    .x2z2              0.135    0.006   20.905    0.000 #>    .x2z3              0.145    0.007   21.145    0.000 #>    .x3z1              0.114    0.007   16.058    0.000 #>  .x2z2 ~~                                              #>    .x2z3              0.117    0.006   20.419    0.000 #>    .x3z2              0.116    0.006   20.586    0.000 #>  .x2z3 ~~                                              #>    .x3z3              0.109    0.006   18.059    0.000 #>  .x3z1 ~~                                              #>    .x3z2              0.138    0.007   19.331    0.000 #>    .x3z3              0.158    0.008   20.269    0.000 #>  .x3z2 ~~                                              #>    .x3z3              0.131    0.007   19.958    0.000 #>   X ~~                                                 #>     Z                 0.201    0.024    8.271    0.000 #>     XZ                0.016    0.025    0.628    0.530 #>   Z ~~                                                 #>     XZ                0.062    0.025    2.449    0.014 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .x1                0.160    0.009   17.871    0.000 #>    .x2                0.162    0.007   22.969    0.000 #>    .x3                0.163    0.008   20.161    0.000 #>    .y1                0.159    0.009   17.896    0.000 #>    .y2                0.154    0.007   22.640    0.000 #>    .y3                0.164    0.008   20.698    0.000 #>    .z1                0.168    0.009   18.143    0.000 #>    .z2                0.158    0.007   22.264    0.000 #>    .z3                0.158    0.008   20.389    0.000 #>    .x1z1              0.311    0.014   22.227    0.000 #>    .x2z1              0.292    0.011   27.287    0.000 #>    .x3z1              0.327    0.012   26.275    0.000 #>    .x1z2              0.290    0.011   26.910    0.000 #>    .x2z2              0.239    0.008   29.770    0.000 #>    .x3z2              0.270    0.009   29.117    0.000 #>    .x1z3              0.272    0.012   23.586    0.000 #>    .x2z3              0.245    0.009   27.979    0.000 #>    .x3z3              0.297    0.011   28.154    0.000 #>     X                 0.981    0.036   26.895    0.000 #>    .Y                 0.990    0.038   25.926    0.000 #>     Z                 1.016    0.038   26.856    0.000 #>     XZ                1.045    0.044   24.004    0.000 est1 <- modsem(m1, oneInt, method = \"lms\") summary(est1) #> Estimating baseline model (H0) #>  #> modsem (version 1.0.9): #>   Estimator                                         LMS #>   Optimization method                         EM-NLMINB #>   Number of observations                           2000 #>   Number of iterations                              119 #>   Loglikelihood                               -14687.74 #>   Akaike (AIC)                                 29437.48 #>   Bayesian (BIC)                               29611.11 #>   #> Numerical Integration: #>   Points of integration (per dim)                    24 #>   Dimensions                                          1 #>   Total points of integration                        24 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -17832 #>   Akaike (AIC)                                 35723.75 #>   Bayesian (BIC)                               35891.78 #>   Chi-square                                      17.52 #>   Degrees of Freedom (Chi-square)                    24 #>   P-value (Chi-square)                            0.826 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                          3144.13 #>   Difference test (D)                           6288.27 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   Y                                               0.595 #> R-Squared Null-Model (H0): #>   Y                                               0.395 #> R-Squared Change: #>   Y                                               0.200 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X =~  #>     x1               1.000                              #>     x2               0.804      0.012    64.31    0.000 #>     x3               0.915      0.013    67.94    0.000 #>   Z =~  #>     z1               1.000                              #>     z2               0.810      0.012    65.09    0.000 #>     z3               0.881      0.013    67.60    0.000 #>   Y =~  #>     y1               1.000                              #>     y2               0.799      0.007   107.55    0.000 #>     y3               0.899      0.008   112.54    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   Y ~  #>     X                0.674      0.031    21.78    0.000 #>     Z                0.570      0.030    19.09    0.000 #>     X:Z              0.712      0.028    25.70    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               1.023      0.021    47.69    0.000 #>     x2               1.216      0.018    67.22    0.000 #>     x3               0.920      0.020    45.95    0.000 #>     z1               1.013      0.024    41.80    0.000 #>     z2               1.207      0.020    59.54    0.000 #>     z3               0.917      0.022    42.28    0.000 #>     y1               1.041      0.032    32.39    0.000 #>     y2               1.223      0.026    46.73    0.000 #>     y3               0.957      0.029    32.80    0.000 #>     Y                0.000                              #>     X                0.000                              #>     Z                0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X ~~  #>     Z                0.198      0.024     8.31    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               0.160      0.008    19.30    0.000 #>     x2               0.163      0.007    23.88    0.000 #>     x3               0.165      0.008    21.23    0.000 #>     z1               0.166      0.009    18.47    0.000 #>     z2               0.160      0.007    22.67    0.000 #>     z3               0.158      0.008    20.79    0.000 #>     y1               0.160      0.009    18.00    0.000 #>     y2               0.154      0.007    22.67    0.000 #>     y3               0.163      0.008    20.68    0.000 #>     X                0.972      0.033    29.84    0.000 #>     Z                1.017      0.038    26.95    0.000 #>     Y                0.984      0.038    25.99    0.000"},{"path":"/articles/modsem.html","id":"interactions-between-two-observed-variables","dir":"Articles","previous_headings":"The Basic Syntax","what":"Interactions Between Two Observed Variables","title":"modsem","text":"modsem allows estimate interactions latent variables also observed variables. , first run regression observed variables, interaction x1 z2, run equivalent model using modsem().","code":""},{"path":"/articles/modsem.html","id":"using-a-regression","dir":"Articles","previous_headings":"The Basic Syntax > Interactions Between Two Observed Variables","what":"Using a Regression","title":"modsem","text":"","code":"reg1 <- lm(y1 ~ x1*z1, oneInt) summary(reg1) #>  #> Call: #> lm(formula = y1 ~ x1 * z1, data = oneInt) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -3.7155 -0.8087 -0.0367  0.8078  4.6531  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  0.51422    0.04618  11.135   <2e-16 *** #> x1           0.05477    0.03387   1.617   0.1060     #> z1          -0.06575    0.03461  -1.900   0.0576 .   #> x1:z1        0.54361    0.02272  23.926   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 1.184 on 1996 degrees of freedom #> Multiple R-squared:  0.4714, Adjusted R-squared:  0.4706  #> F-statistic: 593.3 on 3 and 1996 DF,  p-value: < 2.2e-16"},{"path":"/articles/modsem.html","id":"using-modsem","dir":"Articles","previous_headings":"The Basic Syntax > Interactions Between Two Observed Variables","what":"Using modsem","title":"modsem","text":"interactions observed variables, generally recommended use method = \"pind\". Interaction effects observed variables supported LMS QML approaches. cases, can define latent variable single indicator estimate interaction effect two observed variables LMS QML approaches, generally recommended.","code":"# Using \"pind\" as the method (see Chapter 3) est2 <- modsem('y1 ~ x1 + z1 + x1:z1', data = oneInt, method = \"pind\") summary(est2) #> modsem (version 1.0.9, approach = pind): #> lavaan 0.6-19 ended normally after 1 iteration #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                         4 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                                 0.000 #>   Degrees of freedom                                 0 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   y1 ~                                                 #>     x1                0.055    0.034    1.619    0.105 #>     z1               -0.066    0.035   -1.902    0.057 #>     x1z1              0.544    0.023   23.950    0.000 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .y1                1.399    0.044   31.623    0.000"},{"path":"/articles/modsem.html","id":"interactions-between-latent-and-observed-variables","dir":"Articles","previous_headings":"The Basic Syntax","what":"Interactions Between Latent and Observed Variables","title":"modsem","text":"modsem also allows estimate interaction effects latent observed variables. , simply join latent observed variable colon (e.g., 'latent:observer'). interactions observed variables, generally recommended use method = \"pind\" estimating effect latent observed variables.","code":"m3 <- '   # Outer Model   X =~ x1 + x2 + x3   Y =~ y1 + y2 + y3      # Inner Model   Y ~ X + z1 + X:z1  '  est3 <- modsem(m3, oneInt, method = \"pind\") summary(est3) #> modsem (version 1.0.9, approach = pind): #> lavaan 0.6-19 ended normally after 45 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        22 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                              4468.171 #>   Degrees of freedom                                32 #>   P-value (Chi-square)                           0.000 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   X =~                                                 #>     x1                1.000                            #>     x2                0.803    0.013   63.697    0.000 #>     x3                0.915    0.014   67.548    0.000 #>   Y =~                                                 #>     y1                1.000                            #>     y2                0.798    0.007  115.375    0.000 #>     y3                0.899    0.007  120.783    0.000 #>   Xz1 =~                                               #>     x1z1              1.000                            #>     x2z1              0.947    0.010   96.034    0.000 #>     x3z1              0.902    0.009   99.512    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   Y ~                                                  #>     X                 0.021    0.034    0.614    0.540 #>     z1               -0.185    0.023   -8.096    0.000 #>     Xz1               0.646    0.017   37.126    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   X ~~                                                 #>     Xz1               1.243    0.055   22.523    0.000 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .x1                0.158    0.009   17.976    0.000 #>    .x2                0.164    0.007   23.216    0.000 #>    .x3                0.162    0.008   20.325    0.000 #>    .y1                0.158    0.009   17.819    0.000 #>    .y2                0.154    0.007   22.651    0.000 #>    .y3                0.164    0.008   20.744    0.000 #>    .x1z1              0.315    0.017   18.328    0.000 #>    .x2z1              0.428    0.019   22.853    0.000 #>    .x3z1              0.337    0.016   21.430    0.000 #>     X                 0.982    0.036   26.947    0.000 #>    .Y                 1.112    0.040   27.710    0.000 #>     Xz1               3.965    0.136   29.217    0.000"},{"path":"/articles/modsem.html","id":"quadratic-effects","dir":"Articles","previous_headings":"The Basic Syntax","what":"Quadratic Effects","title":"modsem","text":"Quadratic effects essentially special case interaction effects. Thus, modsem can also used estimate quadratic effects.","code":"m4 <- ' # Outer Model X =~ x1 + x2 + x3 Y =~ y1 + y2 + y3 Z =~ z1 + z2 + z3  # Inner Model Y ~ X + Z + Z:X + X:X '  est4 <- modsem(m4, oneInt, method = \"qml\") summary(est4) #> Estimating baseline model (H0) #>  #> modsem (version 1.0.9): #>   Estimator                                         QML #>   Optimization method                            NLMINB #>   Number of observations                           2000 #>   Number of iterations                              108 #>   Loglikelihood                                -17496.2 #>   Akaike (AIC)                                  35056.4 #>   Bayesian (BIC)                               35235.63 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -17832 #>   Akaike (AIC)                                 35723.75 #>   Bayesian (BIC)                               35891.78 #>   Chi-square                                      17.52 #>   Degrees of Freedom (Chi-square)                    24 #>   P-value (Chi-square)                            0.826 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                           335.68 #>   Difference test (D)                            671.35 #>   Degrees of freedom (D)                              2 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   Y                                               0.607 #> R-Squared Null-Model (H0): #>   Y                                               0.395 #> R-Squared Change: #>   Y                                               0.212 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X =~  #>     x1               1.000                              #>     x2               0.803      0.013   63.962    0.000 #>     x3               0.914      0.013   67.796    0.000 #>   Z =~  #>     z1               1.000                              #>     z2               0.810      0.012   65.122    0.000 #>     z3               0.881      0.013   67.620    0.000 #>   Y =~  #>     y1               1.000                              #>     y2               0.798      0.007  107.574    0.000 #>     y3               0.899      0.008  112.548    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   Y ~  #>     X                0.674      0.032   20.887    0.000 #>     Z                0.566      0.030   18.947    0.000 #>     X:X             -0.005      0.023   -0.208    0.835 #>     X:Z              0.713      0.029   24.554    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               1.023      0.024   42.894    0.000 #>     x2               1.216      0.020   60.996    0.000 #>     x3               0.919      0.022   41.485    0.000 #>     z1               1.012      0.024   41.576    0.000 #>     z2               1.206      0.020   59.270    0.000 #>     z3               0.916      0.022   42.064    0.000 #>     y1               1.042      0.038   27.684    0.000 #>     y2               1.224      0.030   40.160    0.000 #>     y3               0.958      0.034   28.101    0.000 #>     Y                0.000                              #>     X                0.000                              #>     Z                0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X ~~  #>     Z                0.200      0.024    8.239    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               0.158      0.009   18.144    0.000 #>     x2               0.162      0.007   23.188    0.000 #>     x3               0.165      0.008   20.821    0.000 #>     z1               0.166      0.009   18.340    0.000 #>     z2               0.159      0.007   22.620    0.000 #>     z3               0.158      0.008   20.713    0.000 #>     y1               0.159      0.009   17.978    0.000 #>     y2               0.154      0.007   22.673    0.000 #>     y3               0.164      0.008   20.713    0.000 #>     X                0.983      0.036   26.995    0.000 #>     Z                1.019      0.038   26.951    0.000 #>     Y                0.943      0.038   24.819    0.000"},{"path":"/articles/modsem.html","id":"more-complicated-examples","dir":"Articles","previous_headings":"The Basic Syntax","what":"More Complicated Examples","title":"modsem","text":"complex example using theory planned behavior (TPB) model. example includes two quadratic effects one interaction effect, using jordan dataset. dataset subset PISA 2006 dataset. Note: approaches also work may quite slow depending number interaction effects, particularly LMS constrained approaches.","code":"tpb <- '  # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC + INT:PBC   '  # The double-centering approach est_tpb <- modsem(tpb, TPB)  # Using the LMS approach est_tpb_lms <- modsem(tpb, TPB, method = \"lms\") #> Warning: It is recommended that you have at least 32 nodes for interaction #> effects between exogenous and endogenous variables in the lms approach 'nodes = #> 24' summary(est_tpb_lms) #> Estimating baseline model (H0) #>  #> modsem (version 1.0.9): #>   Estimator                                         LMS #>   Optimization method                         EM-NLMINB #>   Number of observations                           2000 #>   Number of iterations                               78 #>   Loglikelihood                               -23463.97 #>   Akaike (AIC)                                 47035.95 #>   Bayesian (BIC)                                47338.4 #>   #> Numerical Integration: #>   Points of integration (per dim)                    24 #>   Dimensions                                          1 #>   Total points of integration                        24 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -26393 #>   Akaike (AIC)                                 52892.45 #>   Bayesian (BIC)                               53189.29 #>   Chi-square                                      66.27 #>   Degrees of Freedom (Chi-square)                    82 #>   P-value (Chi-square)                            0.897 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                          2929.25 #>   Difference test (D)                           5858.50 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   INT                                             0.361 #>   BEH                                             0.249 #> R-Squared Null-Model (H0): #>   INT                                             0.367 #>   BEH                                             0.210 #> R-Squared Change: #>   INT                                            -0.006 #>   BEH                                             0.039 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC =~  #>     pbc1             1.000                              #>     pbc2             0.911      0.013    69.09    0.000 #>     pbc3             0.802      0.012    66.23    0.000 #>   ATT =~  #>     att1             1.000                              #>     att2             0.877      0.012    71.56    0.000 #>     att3             0.789      0.012    66.39    0.000 #>     att4             0.695      0.011    61.00    0.000 #>     att5             0.887      0.013    70.86    0.000 #>   SN =~  #>     sn1              1.000                              #>     sn2              0.889      0.017    52.58    0.000 #>   INT =~  #>     int1             1.000                              #>     int2             0.913      0.015    59.06    0.000 #>     int3             0.807      0.014    55.74    0.000 #>   BEH =~  #>     b1               1.000                              #>     b2               0.961      0.030    31.67    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   INT ~  #>     PBC              0.217      0.030     7.33    0.000 #>     ATT              0.213      0.026     8.17    0.000 #>     SN               0.177      0.028     6.40    0.000 #>   BEH ~  #>     PBC              0.228      0.022    10.20    0.000 #>     INT              0.183      0.025     7.43    0.000 #>     PBC:INT          0.204      0.018    11.24    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     pbc1             0.961      0.021    45.54    0.000 #>     pbc2             0.951      0.020    48.17    0.000 #>     pbc3             0.961      0.018    54.09    0.000 #>     att1             0.989      0.023    42.99    0.000 #>     att2             0.985      0.020    48.16    0.000 #>     att3             0.996      0.019    52.76    0.000 #>     att4             0.981      0.017    57.02    0.000 #>     att5             0.970      0.021    46.79    0.000 #>     sn1              0.980      0.023    42.61    0.000 #>     sn2              0.988      0.021    47.89    0.000 #>     int1             0.996      0.021    47.48    0.000 #>     int2             0.996      0.020    50.98    0.000 #>     int3             0.991      0.018    55.43    0.000 #>     b1               0.990      0.021    47.15    0.000 #>     b2               1.008      0.020    51.32    0.000 #>     INT              0.000                              #>     BEH              0.000                              #>     PBC              0.000                              #>     ATT              0.000                              #>     SN               0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   PBC ~~  #>     ATT              0.658      0.026    25.63    0.000 #>     SN               0.657      0.026    25.11    0.000 #>   ATT ~~  #>     SN               0.616      0.027    22.65    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     pbc1             0.147      0.008    19.09    0.000 #>     pbc2             0.164      0.007    22.39    0.000 #>     pbc3             0.154      0.006    23.94    0.000 #>     att1             0.167      0.007    23.53    0.000 #>     att2             0.150      0.006    24.72    0.000 #>     att3             0.159      0.006    26.39    0.000 #>     att4             0.163      0.006    27.66    0.000 #>     att5             0.159      0.006    24.93    0.000 #>     sn1              0.178      0.015    12.10    0.000 #>     sn2              0.156      0.012    13.22    0.000 #>     int1             0.157      0.009    18.11    0.000 #>     int2             0.160      0.008    20.40    0.000 #>     int3             0.168      0.007    23.55    0.000 #>     b1               0.186      0.018    10.11    0.000 #>     b2               0.135      0.017     8.10    0.000 #>     PBC              0.933      0.031    30.15    0.000 #>     ATT              0.985      0.035    27.80    0.000 #>     SN               0.974      0.038    25.93    0.000 #>     INT              0.491      0.020    24.65    0.000 #>     BEH              0.456      0.023    20.13    0.000 m2 <- ' ENJ =~ enjoy1 + enjoy2 + enjoy3 + enjoy4 + enjoy5 CAREER =~ career1 + career2 + career3 + career4 SC =~ academic1 + academic2 + academic3 + academic4 + academic5 + academic6 CAREER ~ ENJ + SC + ENJ:ENJ + SC:SC + ENJ:SC '  est_jordan <- modsem(m2, data = jordan) est_jordan_qml <- modsem(m2, data = jordan, method = \"qml\") #> Warning: SE's for some coefficients could not be computed. summary(est_jordan_qml) #> Estimating baseline model (H0) #>  #> modsem (version 1.0.9): #>   Estimator                                         QML #>   Optimization method                            NLMINB #>   Number of observations                           6038 #>   Number of iterations                               71 #>   Loglikelihood                              -110520.23 #>   Akaike (AIC)                                221142.45 #>   Bayesian (BIC)                              221484.45 #>   #> Fit Measures for H0: #>   Loglikelihood                                 -110521 #>   Akaike (AIC)                                221138.58 #>   Bayesian (BIC)                              221460.46 #>   Chi-square                                    1016.34 #>   Degrees of Freedom (Chi-square)                    87 #>   P-value (Chi-square)                            0.000 #>   RMSEA                                           0.042 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                             1.06 #>   Difference test (D)                              2.13 #>   Degrees of freedom (D)                              3 #>   P-value (D)                                     0.546 #>   #> R-Squared: #>   CAREER                                          0.513 #> R-Squared Null-Model (H0): #>   CAREER                                          0.510 #> R-Squared Change: #>   CAREER                                          0.003 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   ENJ =~  #>     enjoy1           1.000                              #>     enjoy2           1.002      0.020   50.583    0.000 #>     enjoy3           0.894      0.020   43.667    0.000 #>     enjoy4           0.999      0.021   48.224    0.000 #>     enjoy5           1.047      0.021   50.398    0.000 #>   SC =~  #>     academic1        1.000                              #>     academic2        1.104      0.028   38.949    0.000 #>     academic3        1.235      0.030   41.723    0.000 #>     academic4        1.254      0.030   41.832    0.000 #>     academic5        1.113      0.029   38.651    0.000 #>     academic6        1.198      0.030   40.360    0.000 #>   CAREER =~  #>     career1          1.000                              #>     career2          1.040      0.016   65.180    0.000 #>     career3          0.952      0.016   57.839    0.000 #>     career4          0.818      0.017   48.357    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   CAREER ~  #>     ENJ              0.524      0.020   26.422    0.000 #>     SC               0.467      0.023   19.886    0.000 #>     ENJ:ENJ          0.027      0.022    1.225    0.220 #>     ENJ:SC          -0.040      0.046   -0.873    0.383 #>     SC:SC           -0.001      0.035   -0.043    0.966 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     enjoy1           0.000                              #>     enjoy2           0.000                              #>     enjoy3           0.000                              #>     enjoy4           0.000                              #>     enjoy5           0.000                              #>     academic1        0.000      0.012   -0.011    0.991 #>     academic2        0.000                              #>     academic3        0.000      0.011   -0.039    0.969 #>     academic4        0.000      0.009   -0.027    0.979 #>     academic5       -0.001      0.011   -0.056    0.955 #>     academic6        0.001      0.008    0.086    0.931 #>     career1         -0.004                              #>     career2         -0.005                              #>     career3         -0.004                              #>     career4         -0.004      0.006   -0.643    0.520 #>     CAREER           0.000                              #>     ENJ              0.000                              #>     SC               0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   ENJ ~~  #>     SC               0.218      0.009   25.477    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     enjoy1           0.487      0.011   44.335    0.000 #>     enjoy2           0.488      0.011   44.404    0.000 #>     enjoy3           0.596      0.012   48.232    0.000 #>     enjoy4           0.488      0.011   44.561    0.000 #>     enjoy5           0.442      0.010   42.470    0.000 #>     academic1        0.645      0.013   49.812    0.000 #>     academic2        0.566      0.012   47.864    0.000 #>     academic3        0.473      0.011   44.318    0.000 #>     academic4        0.455      0.010   43.579    0.000 #>     academic5        0.565      0.012   47.696    0.000 #>     academic6        0.502      0.011   45.435    0.000 #>     career1          0.373      0.009   40.391    0.000 #>     career2          0.328      0.009   37.018    0.000 #>     career3          0.436      0.010   43.271    0.000 #>     career4          0.576      0.012   48.373    0.000 #>     ENJ              0.500      0.017   29.546    0.000 #>     SC               0.338      0.015   23.198    0.000 #>     CAREER           0.302      0.010   29.712    0.000"},{"path":"/articles/observed_lms_qml.html","id":"the-latent-moderated-structural-equations-lms-and-the-quasi-maximum-likelihood-qml-approach","dir":"Articles","previous_headings":"","what":"The Latent Moderated Structural Equations (LMS) and the Quasi Maximum Likelihood (QML) Approach","title":"observed variables in the LMS- and QML approach","text":"contrast approaches, LMS QML approaches designed handle latent variables . Thus, observed variables used easily approaches. One way get around specifying observed variable latent variable single indicator. modsem() , default, constrain factor loading 1 residual variance indicator 0. difference latent variable indicator, assuming exogenous variable, zero-mean. approach works LMS QML methods cases, two exceptions.","code":""},{"path":"/articles/observed_lms_qml.html","id":"the-lms-approach","dir":"Articles","previous_headings":"The Latent Moderated Structural Equations (LMS) and the Quasi Maximum Likelihood (QML) Approach","what":"The LMS Approach","title":"observed variables in the LMS- and QML approach","text":"LMS approach, can use -mentioned method almost cases, except using observed variable moderating variable. LMS approach, typically select one variable interaction term moderator. interaction effect estimated via numerical integration n quadrature nodes moderating variable. However, process requires moderating variable error term, distribution moderating variable modeled X∼N(Az,ε)X \\sim N(Az, \\varepsilon), AzAz expected value XX quadrature point k, ε\\varepsilon error term. error term zero, probability observing given value XX computable. instances, first variable interaction term chosen moderator. example, interaction term \"X:Z\", \"X\" usually chosen moderator. Therefore, one variables latent, place latent variable first interaction term. variables observed, must specify measurement error (e.g., \"x1 ~~ 0.1 * x1\") indicator first variable interaction term. forget specify measurement error indicator first variable interaction term, receive error message. Note: get error message X/x1, since Z modelled moderating variable example.","code":"library(modsem)  # Interaction effect between a latent and an observed variable m1 <- ' # Outer Model   X =~ x1 # X is observed   Z =~ z1 + z2 # Z is latent   Y =~ y1 # Y is observed  # Inner model   Y ~ X + Z   Y ~ Z:X '  lms1 <- modsem(m1, oneInt, method = \"lms\")  # Interaction effect between two observed variables m2 <- ' # Outer Model   X =~ x1 # X is observed   Z =~ z1 # Z is observed   Y =~ y1 # Y is observed   x1 ~~ 0.1 * x1 # Specify a variance for the measurement error  # Inner model   Y ~ X + Z   Y ~ X:Z '  lms2 <- modsem(m2, oneInt, method = \"lms\") summary(lms2) #> Estimating baseline model (H0) #>  #> modsem (version 1.0.9): #>   Estimator                                         LMS #>   Optimization method                         EM-NLMINB #>   Number of observations                           2000 #>   Number of iterations                               23 #>   Loglikelihood                                -6632.88 #>   Akaike (AIC)                                 13285.75 #>   Bayesian (BIC)                               13341.76 #>   #> Numerical Integration: #>   Points of integration (per dim)                    24 #>   Dimensions                                          1 #>   Total points of integration                        24 #>   #> Fit Measures for H0: #>   Loglikelihood                                   -9369 #>   Akaike (AIC)                                 18756.46 #>   Bayesian (BIC)                               18806.87 #>   Chi-square                                       0.00 #>   Degrees of Freedom (Chi-square)                     0 #>   P-value (Chi-square)                            0.000 #>   RMSEA                                             Inf #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                          2736.36 #>   Difference test (D)                           5472.71 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   Y                                               0.494 #> R-Squared Null-Model (H0): #>   Y                                               0.335 #> R-Squared Change: #>   Y                                               0.160 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X =~  #>     x1               1.000                              #>   Z =~  #>     z1               1.000                              #>   Y =~  #>     y1               1.000                              #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   Y ~  #>     X                0.663      0.031    21.30    0.000 #>     Z                0.482      0.029    16.86    0.000 #>     X:Z              0.586      0.025    23.44    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               1.023      0.024    41.86    0.000 #>     z1               1.012      0.024    41.53    0.000 #>     y1               1.057      0.034    31.13    0.000 #>     Y                0.000                              #>     X                0.000                              #>     Z                0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X ~~  #>     Z                0.208      0.026     7.98    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               0.100                              #>     z1               0.000                              #>     y1               0.000                              #>     X                1.028      0.035    29.35    0.000 #>     Z                1.184      0.037    31.64    0.000 #>     Y                1.323      0.044    29.88    0.000 m2 <- ' # Outer Model   X =~ x1 # X is observed   Z =~ z1 # Z is observed   Y =~ y1 # Y is observed  # Inner model   Y ~ X + Z   Y ~ X:Z '  lms3 <- modsem(m2, oneInt, method = \"lms\") #> Error: The variance of a moderating variable of integration has an indicator with zero residual variance!  #> This will likely not work with the LMS approach, see:  #>    `vignette('observed_lms_qml', 'modsem')` for more information.  #>  #> The following indicators have zero residual variance: #>   -> x1"},{"path":"/articles/observed_lms_qml.html","id":"the-qml-approach","dir":"Articles","previous_headings":"The Latent Moderated Structural Equations (LMS) and the Quasi Maximum Likelihood (QML) Approach","what":"The QML Approach","title":"observed variables in the LMS- and QML approach","text":"estimation process QML approach differs LMS approach, encounter issue LMS approach. Therefore, don’t need specify measurement error moderating variables.","code":"m3 <- ' # Outer Model   X =~ x1 # X is observed   Z =~ z1 # Z is observed   Y =~ y1 # Y is observed  # Inner model   Y ~ X + Z   Y ~ X:Z '  qml3 <- modsem(m3, oneInt, method = \"qml\") summary(qml3) #> Estimating baseline model (H0) #>  #> modsem (version 1.0.9): #>   Estimator                                         QML #>   Optimization method                            NLMINB #>   Number of observations                           2000 #>   Number of iterations                               11 #>   Loglikelihood                                -9117.07 #>   Akaike (AIC)                                 18254.13 #>   Bayesian (BIC)                               18310.14 #>   #> Fit Measures for H0: #>   Loglikelihood                                   -9369 #>   Akaike (AIC)                                 18756.46 #>   Bayesian (BIC)                               18806.87 #>   Chi-square                                       0.00 #>   Degrees of Freedom (Chi-square)                     0 #>   P-value (Chi-square)                            0.000 #>   RMSEA                                             Inf #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                           252.17 #>   Difference test (D)                            504.33 #>   Degrees of freedom (D)                              1 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   Y                                               0.470 #> R-Squared Null-Model (H0): #>   Y                                               0.320 #> R-Squared Change: #>   Y                                               0.150 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X =~  #>     x1               1.000                              #>   Z =~  #>     z1               1.000                              #>   Y =~  #>     y1               1.000                              #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   Y ~  #>     X                0.605      0.028    21.26    0.000 #>     Z                0.490      0.028    17.55    0.000 #>     X:Z              0.544      0.023    23.95    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               1.023      0.024    42.83    0.000 #>     z1               1.011      0.024    41.56    0.000 #>     y1               1.066      0.034    31.64    0.000 #>     Y                0.000                              #>     X                0.000                              #>     Z                0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X ~~  #>     Z                0.210      0.026     7.95    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               0.000                              #>     z1               0.000                              #>     y1               0.000                              #>     X                1.141      0.036    31.62    0.000 #>     Z                1.184      0.037    31.62    0.000 #>     Y                1.399      0.044    31.62    0.000"},{"path":"/articles/plot_interactions.html","id":"plotting-interaction-effects","dir":"Articles","previous_headings":"","what":"Plotting Interaction Effects","title":"plotting interaction effects","text":"Interaction effects can plotted using included plot_interaction() function. function takes fitted model object names two variables interacting. function plot interaction effect two variables, : x-variable plotted x-axis. y-variable plotted y-axis. z-variable determines points effect x y plotted. function also plot 95% confidence interval interaction effect. Note vals_z argument (well values x) scaled mean standard deviation variables. Unless rescale argument set FALSE. simple example using double-centering approach:  different example using lms approach theory planned behavior model:","code":"m1 <- \" # Outer Model   X =~ x1   X =~ x2 + x3   Z =~ z1 + z2 + z3   Y =~ y1 + y2 + y3  # Inner Model   Y ~ X + Z + X:Z \" est1 <- modsem(m1, data = oneInt) plot_interaction(x = \"X\", z = \"Z\", y = \"Y\",                  vals_z = -3:3, model = est1) tpb <- \" # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ PBC:INT \"  est2 <- modsem(tpb, TPB, method = \"lms\") #> Warning: It is recommended that you have at least 32 nodes for interaction #> effects between exogenous and endogenous variables in the lms approach 'nodes = #> 24' plot_interaction(x = \"INT\", z = \"PBC\", y = \"BEH\",                  vals_z = c(-0.5, 0.5), model = est2)"},{"path":"/articles/plot_interactions.html","id":"plotting-johnson-neyman-regions","dir":"Articles","previous_headings":"","what":"Plotting Johnson-Neyman Regions","title":"plotting interaction effects","text":"plot_jn() function can used plot Johnson-Neyman regions given interaction effect. function takes fitted model object, names two variables interacting, name interaction effect. function plot Johnson-Neyman regions interaction effect. plot_jn() function also plot 95% confidence interval interaction effect. x name x-variable, z name z-variable, y name y-variable. model fitted model object. argument min_z max_z used specify range values moderating variable. example using ca approach Holzinger-Swineford (1939) dataset:  another example using qml approach theory planned behavior model:","code":"m1 <-  '    visual  =~ x1 + x2 + x3    textual =~ x4 + x5 + x6   speed   =~ x7 + x8 + x9    visual ~ speed + textual + speed:textual '  est1 <- modsem(m1, data = lavaan::HolzingerSwineford1939, method = \"ca\") plot_jn(x = \"speed\", z = \"textual\", y = \"visual\", model = est1, max_z = 6) tpb <- \" # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ PBC:INT \"  est2 <- modsem(tpb, TPB, method = \"qml\") plot_jn(x = \"INT\", z = \"PBC\", y = \"BEH\", model = est2,          min_z = -1.5, max_z = -0.5) #> Warning: Truncating SD-range on the right and left!"},{"path":"/articles/plot_interactions.html","id":"plotting-3d-surface-plots","dir":"Articles","previous_headings":"","what":"Plotting (3D) Surface Plots","title":"plotting interaction effects","text":"plot_surface() function can used plot 3D surface plots given interaction effect. function takes fitted model object, names two variables interacting, name dependent variable. function plot 3D surface plot interaction effect.","code":"tpb <- \" # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ PBC:INT \"  est2 <- modsem(tpb, TPB, method = \"qml\") plot_surface(x = \"INT\", z = \"PBC\", y = \"BEH\", model = est2)"},{"path":"/articles/quadratic.html","id":"quadratic-effects-and-interaction-effects","dir":"Articles","previous_headings":"","what":"Quadratic Effects and Interaction Effects","title":"quadratic effects","text":"Quadratic effects essentially special case interaction effects—variable interacts . , methods modsem can also used estimate quadratic effects. simple example using LMS approach. example, simple model two quadratic effects one interaction effect. estimate model using QML double-centering approaches, data subset PISA 2006 dataset. Note: approaches (e.g., LMS constrained methods) can also used may slower depending number interaction effects, especially LMS constrained approaches.","code":"library(modsem) m1 <- ' # Outer Model X =~ x1 + x2 + x3 Y =~ y1 + y2 + y3 Z =~ z1 + z2 + z3  # Inner model Y ~ X + Z + Z:X + X:X '  est1Lms <- modsem(m1, data = oneInt, method = \"lms\") summary(est1Lms) #> Estimating baseline model (H0) #>  #> modsem (version 1.0.9): #>   Estimator                                         LMS #>   Optimization method                         EM-NLMINB #>   Number of observations                           2000 #>   Number of iterations                              103 #>   Loglikelihood                               -14687.62 #>   Akaike (AIC)                                 29439.25 #>   Bayesian (BIC)                               29618.48 #>   #> Numerical Integration: #>   Points of integration (per dim)                    24 #>   Dimensions                                          1 #>   Total points of integration                        24 #>   #> Fit Measures for H0: #>   Loglikelihood                                  -17832 #>   Akaike (AIC)                                 35723.75 #>   Bayesian (BIC)                               35891.78 #>   Chi-square                                      17.52 #>   Degrees of Freedom (Chi-square)                    24 #>   P-value (Chi-square)                            0.826 #>   RMSEA                                           0.000 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                          3144.25 #>   Difference test (D)                           6288.50 #>   Degrees of freedom (D)                              2 #>   P-value (D)                                     0.000 #>   #> R-Squared: #>   Y                                               0.596 #> R-Squared Null-Model (H0): #>   Y                                               0.395 #> R-Squared Change: #>   Y                                               0.201 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X =~  #>     x1               1.000                              #>     x2               0.804      0.012   64.317    0.000 #>     x3               0.915      0.013   67.937    0.000 #>   Z =~  #>     z1               1.000                              #>     z2               0.810      0.012   65.090    0.000 #>     z3               0.881      0.013   67.603    0.000 #>   Y =~  #>     y1               1.000                              #>     y2               0.799      0.007  107.551    0.000 #>     y3               0.899      0.008  112.536    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   Y ~  #>     X                0.673      0.031   21.735    0.000 #>     Z                0.570      0.030   19.063    0.000 #>     X:X             -0.008      0.021   -0.357    0.721 #>     X:Z              0.715      0.029   24.737    0.000 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               1.023      0.021   47.704    0.000 #>     x2               1.216      0.018   67.240    0.000 #>     x3               0.920      0.020   45.964    0.000 #>     z1               1.013      0.024   41.784    0.000 #>     z2               1.207      0.020   59.532    0.000 #>     z3               0.917      0.022   42.269    0.000 #>     y1               1.047      0.037   28.203    0.000 #>     y2               1.228      0.030   40.816    0.000 #>     y3               0.963      0.034   28.631    0.000 #>     Y                0.000                              #>     X                0.000                              #>     Z                0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   X ~~  #>     Z                0.199      0.024    8.315    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     x1               0.160      0.008   19.300    0.000 #>     x2               0.163      0.007   23.883    0.000 #>     x3               0.165      0.008   21.223    0.000 #>     z1               0.167      0.009   18.479    0.000 #>     z2               0.160      0.007   22.673    0.000 #>     z3               0.158      0.008   20.797    0.000 #>     y1               0.160      0.009   18.007    0.000 #>     y2               0.154      0.007   22.664    0.000 #>     y3               0.163      0.008   20.682    0.000 #>     X                0.972      0.033   29.859    0.000 #>     Z                1.017      0.038   26.944    0.000 #>     Y                0.983      0.038   25.984    0.000 m2 <- ' ENJ =~ enjoy1 + enjoy2 + enjoy3 + enjoy4 + enjoy5 CAREER =~ career1 + career2 + career3 + career4 SC =~ academic1 + academic2 + academic3 + academic4 + academic5 + academic6 CAREER ~ ENJ + SC + ENJ:ENJ + SC:SC + ENJ:SC '  est2Dblcent <- modsem(m2, data = jordan) est2Qml <- modsem(m2, data = jordan, method = \"qml\") #> Warning: SE's for some coefficients could not be computed. summary(est2Qml) #> Estimating baseline model (H0) #>  #> modsem (version 1.0.9): #>   Estimator                                         QML #>   Optimization method                            NLMINB #>   Number of observations                           6038 #>   Number of iterations                               71 #>   Loglikelihood                              -110520.23 #>   Akaike (AIC)                                221142.45 #>   Bayesian (BIC)                              221484.45 #>   #> Fit Measures for H0: #>   Loglikelihood                                 -110521 #>   Akaike (AIC)                                221138.58 #>   Bayesian (BIC)                              221460.46 #>   Chi-square                                    1016.34 #>   Degrees of Freedom (Chi-square)                    87 #>   P-value (Chi-square)                            0.000 #>   RMSEA                                           0.042 #>   #> Comparative fit to H0 (no interaction effect) #>   Loglikelihood change                             1.06 #>   Difference test (D)                              2.13 #>   Degrees of freedom (D)                              3 #>   P-value (D)                                     0.546 #>   #> R-Squared: #>   CAREER                                          0.513 #> R-Squared Null-Model (H0): #>   CAREER                                          0.510 #> R-Squared Change: #>   CAREER                                          0.003 #>  #> Parameter Estimates: #>   Coefficients                           unstandardized #>   Information                                  observed #>   Standard errors                              standard #>   #> Latent Variables: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   ENJ =~  #>     enjoy1           1.000                              #>     enjoy2           1.002      0.020   50.583    0.000 #>     enjoy3           0.894      0.020   43.667    0.000 #>     enjoy4           0.999      0.021   48.224    0.000 #>     enjoy5           1.047      0.021   50.398    0.000 #>   SC =~  #>     academic1        1.000                              #>     academic2        1.104      0.028   38.949    0.000 #>     academic3        1.235      0.030   41.723    0.000 #>     academic4        1.254      0.030   41.832    0.000 #>     academic5        1.113      0.029   38.651    0.000 #>     academic6        1.198      0.030   40.360    0.000 #>   CAREER =~  #>     career1          1.000                              #>     career2          1.040      0.016   65.180    0.000 #>     career3          0.952      0.016   57.839    0.000 #>     career4          0.818      0.017   48.357    0.000 #>  #> Regressions: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   CAREER ~  #>     ENJ              0.524      0.020   26.422    0.000 #>     SC               0.467      0.023   19.886    0.000 #>     ENJ:ENJ          0.027      0.022    1.225    0.220 #>     ENJ:SC          -0.040      0.046   -0.873    0.383 #>     SC:SC           -0.001      0.035   -0.043    0.966 #>  #> Intercepts: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     enjoy1           0.000                              #>     enjoy2           0.000                              #>     enjoy3           0.000                              #>     enjoy4           0.000                              #>     enjoy5           0.000                              #>     academic1        0.000      0.012   -0.011    0.991 #>     academic2        0.000                              #>     academic3        0.000      0.011   -0.039    0.969 #>     academic4        0.000      0.009   -0.027    0.979 #>     academic5       -0.001      0.011   -0.056    0.955 #>     academic6        0.001      0.008    0.086    0.931 #>     career1         -0.004                              #>     career2         -0.005                              #>     career3         -0.004                              #>     career4         -0.004      0.006   -0.643    0.520 #>     CAREER           0.000                              #>     ENJ              0.000                              #>     SC               0.000                              #>  #> Covariances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>   ENJ ~~  #>     SC               0.218      0.009   25.477    0.000 #>  #> Variances: #>                   Estimate  Std.Error  z.value  P(>|z|) #>     enjoy1           0.487      0.011   44.335    0.000 #>     enjoy2           0.488      0.011   44.404    0.000 #>     enjoy3           0.596      0.012   48.232    0.000 #>     enjoy4           0.488      0.011   44.561    0.000 #>     enjoy5           0.442      0.010   42.470    0.000 #>     academic1        0.645      0.013   49.812    0.000 #>     academic2        0.566      0.012   47.864    0.000 #>     academic3        0.473      0.011   44.318    0.000 #>     academic4        0.455      0.010   43.579    0.000 #>     academic5        0.565      0.012   47.696    0.000 #>     academic6        0.502      0.011   45.435    0.000 #>     career1          0.373      0.009   40.391    0.000 #>     career2          0.328      0.009   37.018    0.000 #>     career3          0.436      0.010   43.271    0.000 #>     career4          0.576      0.012   48.373    0.000 #>     ENJ              0.500      0.017   29.546    0.000 #>     SC               0.338      0.015   23.198    0.000 #>     CAREER           0.302      0.010   29.712    0.000"},{"path":"/articles/simple_slopes.html","id":"simple-slopes-analysis","dir":"Articles","previous_headings":"","what":"Simple Slopes Analysis","title":"simple slopes analysis","text":"Simple slope effects can plotted using included plot_interaction() function. function takes fitted model object names two variables interacting. function plot interaction effect two variables, : x-variable plotted x-axis. y-variable plotted y-axis. z-variable determines points effect x y plotted. function also plot 95% confidence interval interaction effect. Note vals_z argument (well values x) scaled mean standard deviation variables. Unless rescale argument set FALSE. simple example using double-centering approach:  want see numerical values simple slopes, can use simple_slopes() function: simple_slopes() function returns simple_slopes object. two methods/generics: print.simple_slopes(), prints simple slopes easy--read format .data.frame.simple_slopes(). print() method print predicted values, also significance tests difference slope lowest value z slope highest value z, well significance tests slope x different values vals_z. example , can see significant difference slope -1 * sd(Z) +1 * sd(Z). Note default vals_z rescaled mean standard deviation variable, unless rescale = FALSE set. means values vals_z interpreted standard deviations mean Z. want extract simple slopes data.frame, can use .data.frame() function:","code":"m1 <- \" # Outer Model   X =~ x1   X =~ x2 + x3   Z =~ z1 + z2 + z3   Y =~ y1 + y2 + y3  # Inner Model   Y ~ X + Z + X:Z \" est1 <- modsem(m1, data = oneInt) plot_interaction(x = \"X\", z = \"Z\", y = \"Y\", vals_z = c(-1, 1), model = est1) m1 <- \" # Outer Model   X =~ x1   X =~ x2 + x3   Z =~ z1 + z2 + z3   Y =~ y1 + y2 + y3  # Inner Model   Y ~ X + Z + X:Z \"  est1 <- modsem(m1, data = oneInt) simple_slopes(x = \"X\", z = \"Z\", y = \"Y\", vals_z = c(-1, 1), model = est1) #>  #> Difference test of Y~X|Z at Z = -1.008 and 1.008: #> ┌───────────┬───────────┬─────────┬─────────┬───────────────┐ #> │Difference │ Std.Error │ z.value │ p.value │ Conf.Interval │ #> ╞═══════════╪═══════════╪═════════╪═════════╪═══════════════╡ #> │      1.42 │     0.054 │   26.36 │   0.000 │  [1.31, 1.52] │ #> └───────────┴───────────┴─────────┴─────────┴───────────────┘ #>  #> Effect of Y~X|Z given values of Z: #> ┌────────┬────────┬───────────┬─────────┬─────────┬────────────────┐ #> │    Y~X │      Z │ Std.Error │ z.value │ p.value │  Conf.Interval │ #> ╞════════╪════════╪═══════════╪═════════╪═════════╪════════════════╡ #> │ -0.033 │  -1.01 │     0.038 │   -0.88 │   0.377 │  [-0.11, 0.04] │ #> │  1.382 │   1.01 │     0.038 │   36.34 │   0.000 │  [ 1.31, 1.46] │ #> └────────┴────────┴───────────┴─────────┴─────────┴────────────────┘ #>  #>  #> Predicted Y, given Z = -1.01: #> ┌───────┬─────────────┬───────────┬─────────┬─────────┬─────────────────┐ #> │     X │ Predicted Y │ Std.Error │ z.value │ p.value │   Conf.Interval │ #> ╞═══════╪═════════════╪═══════════╪═════════╪═════════╪═════════════════╡ #> │ -2.97 │       -0.47 │     0.112 │   -4.17 │   0.000 │  [-0.69, -0.25] │ #> │ -1.98 │       -0.50 │     0.076 │   -6.55 │   0.000 │  [-0.65, -0.35] │ #> │ -0.99 │       -0.53 │     0.043 │  -12.33 │   0.000 │  [-0.62, -0.45] │ #> │  0.00 │       -0.57 │     0.026 │  -21.61 │   0.000 │  [-0.62, -0.51] │ #> │  0.99 │       -0.60 │     0.048 │  -12.56 │   0.000 │  [-0.69, -0.50] │ #> │  1.98 │       -0.63 │     0.081 │   -7.76 │   0.000 │  [-0.79, -0.47] │ #> │  2.97 │       -0.66 │     0.117 │   -5.67 │   0.000 │  [-0.89, -0.43] │ #> └───────┴─────────────┴───────────┴─────────┴─────────┴─────────────────┘ #>  #>  #> Predicted Y, given Z = 1.01: #> ┌───────┬─────────────┬───────────┬─────────┬─────────┬─────────────────┐ #> │     X │ Predicted Y │ Std.Error │ z.value │ p.value │   Conf.Interval │ #> ╞═══════╪═════════════╪═══════════╪═════════╪═════════╪═════════════════╡ #> │ -2.97 │       -3.54 │     0.120 │  -29.48 │   0.000 │  [-3.78, -3.31] │ #> │ -1.98 │       -2.17 │     0.084 │  -25.94 │   0.000 │  [-2.34, -2.01] │ #> │ -0.99 │       -0.80 │     0.049 │  -16.30 │   0.000 │  [-0.90, -0.71] │ #> │  0.00 │        0.57 │     0.026 │   21.61 │   0.000 │  [ 0.51,  0.62] │ #> │  0.99 │        1.93 │     0.042 │   45.91 │   0.000 │  [ 1.85,  2.02] │ #> │  1.98 │        3.30 │     0.076 │   43.74 │   0.000 │  [ 3.16,  3.45] │ #> │  2.97 │        4.67 │     0.112 │   41.84 │   0.000 │  [ 4.45,  4.89] │ #> └───────┴─────────────┴───────────┴─────────┴─────────┴─────────────────┘ m1 <- \" # Outer Model   X =~ x1   X =~ x2 + x3   Z =~ z1 + z2 + z3   Y =~ y1 + y2 + y3  # Inner Model   Y ~ X + Z + X:Z \"  est1 <- modsem(m1, data = oneInt) slopes <- simple_slopes(x = \"X\", z = \"Z\", y = \"Y\",                          vals_z = c(0, 1), model = est1) as.data.frame(slopes) #>        vals_x   vals_z  predicted  std.error   z.value       p.value   ci.upper #> 1  -2.9713704 0.000000 -2.0043501 0.07897710 -25.37887 4.315370e-142 -1.8495578 #> 2  -1.9809136 0.000000 -1.3362334 0.05265140 -25.37887 4.315370e-142 -1.2330385 #> 3  -0.9904568 0.000000 -0.6681167 0.02632570 -25.37887 4.315370e-142 -0.6165193 #> 4   0.0000000 0.000000  0.0000000 0.00000000       NaN           NaN  0.0000000 #> 5   0.9904568 0.000000  0.6681167 0.02632570  25.37887 4.315370e-142  0.7197141 #> 6   1.9809136 0.000000  1.3362334 0.05265140  25.37887 4.315370e-142  1.4394282 #> 7   2.9713704 0.000000  2.0043501 0.07897710  25.37887 4.315370e-142  2.1591423 #> 8  -2.9713704 1.008084 -3.5419750 0.12016032 -29.47708 5.664083e-191 -3.3064651 #> 9  -1.9809136 1.008084 -2.1729185 0.08376085 -25.94194 2.242150e-148 -2.0087503 #> 10 -0.9904568 1.008084 -0.8038620 0.04930659 -16.30334  9.344238e-60 -0.7072229 #> 11  0.0000000 1.008084  0.5651944 0.02615878  21.60630 1.567068e-103  0.6164647 #> 12  0.9904568 1.008084  1.9342509 0.04213438  45.90671  0.000000e+00  2.0168328 #> 13  1.9809136 1.008084  3.3033074 0.07552624  43.73721  0.000000e+00  3.4513362 #> 14  2.9713704 1.008084  4.6723639 0.11167365  41.83945  0.000000e+00  4.8912403 #>      ci.lower #> 1  -2.1591423 #> 2  -1.4394282 #> 3  -0.7197141 #> 4   0.0000000 #> 5   0.6165193 #> 6   1.2330385 #> 7   1.8495578 #> 8  -3.7774849 #> 9  -2.3370868 #> 10 -0.9005012 #> 11  0.5139242 #> 12  1.8516691 #> 13  3.1552787 #> 14  4.4534876"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kjell Solem Slupphaug. Author, maintainer. Mehmet Mehmetoglu. Contributor. Matthias Mittner. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Slupphaug, K. S., Mehmetoglu, M., & Mittner, M. (2024). modsem: R package estimating latent interactions quadratic effects. Structural Equation Modeling: Multidisciplinary Journal https://doi.org/10.1080/10705511.2024.2417409","code":"@Article{,   title = {modsem: An R package for estimating latent interactions and quadratic effects},   author = {Kjell Solem Slupphaug and Mehmet Mehmetoglu and Matthias Mittner},   journal = {Structural Equation Modeling: A Multidisciplinary Journal},   year = {2024},   doi = {10.1080/10705511.2024.2417409}, }"},{"path":[]},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"modsem available CRAN GitHub, can installed follows: Note: package needs compiled source macOS Linux. issues installing package macOS, might need install gfortran compiler. C++ compiler also required, installed default systems. See R macOs page information.","code":"# From CRAN  install.packages(\"modsem\")  # Latest version from GitHub install.packages(\"devtools\") devtools::install_github(\"kss2k/modsem\", build_vignettes = TRUE)"},{"path":"/index.html","id":"methodsapproaches","dir":"","previous_headings":"","what":"Methods/Approaches","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"number approaches estimating interaction effects SEM. modsem(), method = \"method\" argument allows choose use. Different approaches can categorized two groups: Product Indicator (PI) Distribution Analytic (DA) approaches.","code":""},{"path":"/index.html","id":"product-indicator-pi-approaches","dir":"","previous_headings":"","what":"Product Indicator (PI) Approaches:","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"Note constraints can become quite complicated complex models, particularly interaction including enodgenous variables. method can therefore quite slow. \"uca\" = unconstrained approach (Marsh, 2004) \"rca\" = residual centering approach (Little et al., 2006) default \"pind\" = basic product indicator approach (recommended)","code":""},{"path":"/index.html","id":"distribution-analytic-da-approaches","dir":"","previous_headings":"","what":"Distribution Analytic (DA) Approaches","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"\"lms\" = Latent Moderated Structural equations (LMS) approach, see vignette \"qml\" = Quasi Maximum Likelihood (QML) approach, see vignette estimates model Mplus, installed","code":""},{"path":[]},{"path":"/index.html","id":"elementary-interaction-model-kenny--judd-1984-jaccard--wan-1995","dir":"","previous_headings":"","what":"Elementary Interaction Model (Kenny & Judd, 1984; Jaccard & Wan, 1995)","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"","code":"library(modsem) m1 <- '   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3      # Inner model   Y ~ X + Z + X:Z  '  # Double centering approach est1_dca <- modsem(m1, oneInt) summary(est1_dca)  # Constrained approach est1_ca <- modsem(m1, oneInt, method = \"ca\") summary(est1_ca)  # QML approach  est1_qml <- modsem(m1, oneInt, method = \"qml\") summary(est1_qml, standardized = TRUE)   # LMS approach  est1_lms <- modsem(m1, oneInt, method = \"lms\")  summary(est1_lms)"},{"path":"/index.html","id":"theory-of-planned-behavior","dir":"","previous_headings":"","what":"Theory Of Planned Behavior","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"","code":"tpb <- \" # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ PBC:INT \"  # double centering approach est_tpb_dca <- modsem(tpb, data = TPB, method = \"dblcent\") summary(est_tpb_dca)  # Constrained approach using Wrigths path tracing rules for generating # the appropriate constraints est_tpb_ca <- modsem(tpb, data = TPB, method = \"ca\")  summary(est_tpb_ca)  # LMS approach  est_tpb_lms <- modsem(tpb, data = TPB, method = \"lms\") summary(est_tpb_lms, standardized = TRUE)   # QML approach  est_tpb_qml <- modsem(tpb, data = TPB, method = \"qml\")  summary(est_tpb_qml, standardized = TRUE)"},{"path":"/index.html","id":"interactions-between-two-observed-variables","dir":"","previous_headings":"","what":"Interactions between two observed variables","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"","code":"est2 <- modsem('y1 ~ x1 + z1 + x1:z1', data = oneInt, method = \"pind\") summary(est2)"},{"path":"/index.html","id":"interaction-between-an-obsereved-and-a-latent-variable","dir":"","previous_headings":"","what":"Interaction between an obsereved and a latent variable","title":"Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)","text":"","code":"m3 <- '   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3      # Inner model   Y ~ X + z1 + X:z1  '  est3 <- modsem(m3, oneInt, method = \"pind\") summary(est3)"},{"path":"/reference/TPB.html","id":null,"dir":"Reference","previous_headings":"","what":"TPB — TPB","title":"TPB — TPB","text":"simulated dataset based Theory Planned Behaviour","code":""},{"path":"/reference/TPB.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"TPB — TPB","text":"","code":"tpb <- \" # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC + INT:PBC \"  est <- modsem(tpb, data = TPB)"},{"path":"/reference/TPB_1SO.html","id":null,"dir":"Reference","previous_headings":"","what":"TPB_1SO — TPB_1SO","title":"TPB_1SO — TPB_1SO","text":"simulated dataset based Theory Planned Behaviour, INT higher order construct ATT, SN, PBC.","code":""},{"path":"/reference/TPB_1SO.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"TPB_1SO — TPB_1SO","text":"","code":"tpb <- '   # First order constructs   ATT =~ att1 + att2 + att3   SN  =~ sn1 + sn2 + sn3   PBC =~ pbc1 + pbc2 + pbc3   BEH =~ b1 + b2    # Higher order constructs   INT =~ ATT + PBC + SN    # Higher order interaction   INTxPBC =~ ATT:PBC + SN:PBC + PBC:PBC      # Structural model   BEH ~ PBC + INT + INTxPBC '  if (FALSE) { # \\dontrun{ est <- modsem(tpb, data = TPB_2SO, method = \"ca\") summary(est) } # }"},{"path":"/reference/TPB_2SO.html","id":null,"dir":"Reference","previous_headings":"","what":"TPB_2SO — TPB_2SO","title":"TPB_2SO — TPB_2SO","text":"simulated dataset based Theory Planned Behaviour, INT higher order construct ATT SN, PBC higher order construct PC PB.","code":""},{"path":"/reference/TPB_2SO.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"TPB_2SO — TPB_2SO","text":"","code":"tpb <- \"   # First order constructs   ATT =~ att1 + att2 + att3   SN  =~ sn1 + sn2 + sn3   PB =~ pb1 + pb2 + pb3   PC =~ pc1 + pc2 + pc3   BEH =~ b1 + b2    # Higher order constructs   INT =~ ATT + SN   PBC =~ PC + PB    # Higher order interaction   INTxPBC =~ ATT:PC + ATT:PB + SN:PC + SN:PB    # Structural model   BEH ~ PBC + INT + INTxPBC \"  if (FALSE) { # \\dontrun{ est <- modsem(tpb, data = TPB_2SO, method = \"ca\") summary(est) } # }"},{"path":"/reference/TPB_UK.html","id":null,"dir":"Reference","previous_headings":"","what":"TPB_UK — TPB_UK","title":"TPB_UK — TPB_UK","text":"dataset based Theory Planned Behaviour UK sample. 4 variables high communality selected latent variable (ATT, SN, PBC, INT, BEH), two time points (t1 t2).","code":""},{"path":"/reference/TPB_UK.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"TPB_UK — TPB_UK","text":"Gathered replciation study original Hagger et al. (2023). Obtained https://doi.org/10.23668/psycharchives.12187","code":""},{"path":"/reference/TPB_UK.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"TPB_UK — TPB_UK","text":"","code":"tpb_uk <- \" # Outer Model (Based on Hagger et al., 2007)  ATT =~ att3 + att2 + att1 + att4  SN =~ sn4 + sn2 + sn3 + sn1  PBC =~ pbc2 + pbc1 + pbc3 + pbc4  INT =~ int2 + int1 + int3 + int4  BEH =~ beh3 + beh2 + beh1 + beh4  # Inner Model (Based on Steinmetz et al., 2011)  # Causal Relationsships  INT ~ ATT + SN + PBC  BEH ~ INT + PBC  BEH ~ INT:PBC \"  est <- modsem(tpb_uk, data = TPB_UK)"},{"path":"/reference/coef_modsem_da.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper for coef — coef_modsem_da","title":"Wrapper for coef — coef_modsem_da","text":"wrapper coef, used modsem::coef_modsem_da, since coef namespace modsem, stats","code":""},{"path":"/reference/coef_modsem_da.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper for coef — coef_modsem_da","text":"","code":"coef_modsem_da(object, ...)"},{"path":"/reference/coef_modsem_da.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper for coef — coef_modsem_da","text":"object fittet model inspect ... additional arguments","code":""},{"path":"/reference/compare_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"compare model fit for qml and lms models — compare_fit","title":"compare model fit for qml and lms models — compare_fit","text":"Compare fit two models using likelihood ratio test. `est_h0` representing null hypothesis model, `est_h1` alternative hypothesis model. Importantly, function assumes `est_h0` free parameters (.e., degrees freedom) `est_h1`. alternative hypothesis model","code":""},{"path":"/reference/compare_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"compare model fit for qml and lms models — compare_fit","text":"","code":"compare_fit(est_h0, est_h1)"},{"path":"/reference/compare_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"compare model fit for qml and lms models — compare_fit","text":"est_h0 object class `modsem_da` representing null hypothesis model est_h1 object class `modsem_da` representing ","code":""},{"path":"/reference/compare_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"compare model fit for qml and lms models — compare_fit","text":"","code":"if (FALSE) { # \\dontrun{ m1 <- \"  # Outer Model  X =~ x1 + x2 + x3  Y =~ y1 + y2 + y3  Z =~ z1 + z2 + z3   # Inner model  Y ~ X + Z + X:Z \"  est_h1 <- modsem(m1, oneInt, \"lms\") est_h0 <- estimate_h0(est_h1, calc.se=FALSE) # std.errors are not needed compare_fit(est_h0, est_h1) } # }"},{"path":"/reference/default_settings_da.html","id":null,"dir":"Reference","previous_headings":"","what":"default arguments fro LMS and QML approach — default_settings_da","title":"default arguments fro LMS and QML approach — default_settings_da","text":"function returns default settings LMS QML approach.","code":""},{"path":"/reference/default_settings_da.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"default arguments fro LMS and QML approach — default_settings_da","text":"","code":"default_settings_da(method = c(\"lms\", \"qml\"))"},{"path":"/reference/default_settings_da.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"default arguments fro LMS and QML approach — default_settings_da","text":"method method get settings ","code":""},{"path":"/reference/default_settings_da.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"default arguments fro LMS and QML approach — default_settings_da","text":"list","code":""},{"path":"/reference/default_settings_da.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"default arguments fro LMS and QML approach — default_settings_da","text":"","code":"library(modsem) default_settings_da() #> $lms #> $lms$verbose #> [1] FALSE #>  #> $lms$optimize #> [1] TRUE #>  #> $lms$nodes #> [1] 24 #>  #> $lms$convergence.abs #> [1] 1e-04 #>  #> $lms$convergence.rel #> [1] 1e-10 #>  #> $lms$optimizer #> [1] \"nlminb\" #>  #> $lms$center.data #> [1] FALSE #>  #> $lms$standardize.data #> [1] FALSE #>  #> $lms$standardize.out #> [1] FALSE #>  #> $lms$standardize #> [1] FALSE #>  #> $lms$mean.observed #> [1] TRUE #>  #> $lms$double #> [1] FALSE #>  #> $lms$calc.se #> [1] TRUE #>  #> $lms$FIM #> [1] \"observed\" #>  #> $lms$OFIM.hessian #> [1] TRUE #>  #> $lms$EFIM.S #> [1] 100 #>  #> $lms$EFIM.parametric #> [1] TRUE #>  #> $lms$robust.se #> [1] FALSE #>  #> $lms$R.max #> [1] 1e+05 #>  #> $lms$max.iter #> [1] 500 #>  #> $lms$max.step #> [1] 1 #>  #> $lms$epsilon #> [1] 1e-04 #>  #> $lms$quad.range #> [1] Inf #>  #> $lms$adaptive.quad #> [1] FALSE #>  #> $lms$adaptive.quad.tol #> [1] 1e-04 #>  #> $lms$n.threads #> NULL #>  #> $lms$algorithm #> [1] \"EM\" #>  #> $lms$em.control #> list() #>  #>  #> $qml #> $qml$verbose #> [1] FALSE #>  #> $qml$optimize #> [1] TRUE #>  #> $qml$nodes #> [1] 0 #>  #> $qml$convergence.rel #> [1] 1e-06 #>  #> $qml$convergence.abs #> NULL #>  #> $qml$optimizer #> [1] \"nlminb\" #>  #> $qml$center.data #> [1] FALSE #>  #> $qml$standardize #> [1] FALSE #>  #> $qml$standardize.data #> [1] FALSE #>  #> $qml$standardize.out #> [1] FALSE #>  #> $qml$mean.observed #> [1] TRUE #>  #> $qml$double #> [1] FALSE #>  #> $qml$calc.se #> [1] TRUE #>  #> $qml$FIM #> [1] \"observed\" #>  #> $qml$OFIM.hessian #> [1] TRUE #>  #> $qml$EFIM.S #> [1] 100 #>  #> $qml$EFIM.parametric #> [1] TRUE #>  #> $qml$robust.se #> [1] FALSE #>  #> $qml$R.max #> [1] 1e+05 #>  #> $qml$max.iter #> [1] 500 #>  #> $qml$max.step #> NULL #>  #> $qml$epsilon #> [1] 1e-08 #>  #> $qml$quad.range #> [1] Inf #>  #> $qml$adaptive.quad #> [1] FALSE #>  #> $qml$adaptive.quad.tol #> [1] 1e-04 #>  #> $qml$n.threads #> NULL #>  #> $qml$adaptive.quad #> [1] FALSE #>  #> $qml$em.control #> NULL #>  #> $qml$algorithm #> NULL #>  #>"},{"path":"/reference/default_settings_pi.html","id":null,"dir":"Reference","previous_headings":"","what":"default arguments for product indicator approaches — default_settings_pi","title":"default arguments for product indicator approaches — default_settings_pi","text":"function returns default settings product indicator approaches","code":""},{"path":"/reference/default_settings_pi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"default arguments for product indicator approaches — default_settings_pi","text":"","code":"default_settings_pi(method = c(\"rca\", \"uca\", \"pind\", \"dblcent\", \"ca\"))"},{"path":"/reference/default_settings_pi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"default arguments for product indicator approaches — default_settings_pi","text":"method method get settings ","code":""},{"path":"/reference/default_settings_pi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"default arguments for product indicator approaches — default_settings_pi","text":"list","code":""},{"path":"/reference/default_settings_pi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"default arguments for product indicator approaches — default_settings_pi","text":"","code":"library(modsem) default_settings_pi() #> $rca #> $rca$center.before #> [1] FALSE #>  #> $rca$center.after #> [1] FALSE #>  #> $rca$residuals.prods #> [1] TRUE #>  #> $rca$residual.cov.syntax #> [1] TRUE #>  #> $rca$constrained.prod.mean #> [1] FALSE #>  #> $rca$constrained.loadings #> [1] FALSE #>  #> $rca$constrained.var #> [1] FALSE #>  #> $rca$constrained.res.cov.method #> [1] \"simple\" #>  #> $rca$match #> [1] FALSE #>  #>  #> $uca #> $uca$center.before #> [1] TRUE #>  #> $uca$center.after #> [1] FALSE #>  #> $uca$residuals.prods #> [1] FALSE #>  #> $uca$residual.cov.syntax #> [1] TRUE #>  #> $uca$constrained.prod.mean #> [1] TRUE #>  #> $uca$constrained.loadings #> [1] FALSE #>  #> $uca$constrained.var #> [1] FALSE #>  #> $uca$constrained.res.cov.method #> [1] \"simple\" #>  #> $uca$match #> [1] FALSE #>  #>  #> $pind #> $pind$center.before #> [1] FALSE #>  #> $pind$center.after #> [1] FALSE #>  #> $pind$residuals.prods #> [1] FALSE #>  #> $pind$residual.cov.syntax #> [1] FALSE #>  #> $pind$constrained.prod.mean #> [1] FALSE #>  #> $pind$constrained.loadings #> [1] FALSE #>  #> $pind$constrained.var #> [1] FALSE #>  #> $pind$constrained.res.cov.method #> [1] \"simple\" #>  #> $pind$match #> [1] FALSE #>  #>  #> $dblcent #> $dblcent$center.before #> [1] TRUE #>  #> $dblcent$center.after #> [1] TRUE #>  #> $dblcent$residuals.prods #> [1] FALSE #>  #> $dblcent$residual.cov.syntax #> [1] TRUE #>  #> $dblcent$constrained.prod.mean #> [1] FALSE #>  #> $dblcent$constrained.loadings #> [1] FALSE #>  #> $dblcent$constrained.var #> [1] FALSE #>  #> $dblcent$constrained.res.cov.method #> [1] \"simple\" #>  #> $dblcent$match #> [1] FALSE #>  #>  #> $ca #> $ca$center.before #> [1] TRUE #>  #> $ca$center.after #> [1] FALSE #>  #> $ca$residuals.prods #> [1] FALSE #>  #> $ca$residual.cov.syntax #> [1] TRUE #>  #> $ca$constrained.prod.mean #> [1] TRUE #>  #> $ca$constrained.loadings #> [1] TRUE #>  #> $ca$constrained.var #> [1] TRUE #>  #> $ca$constrained.res.cov.method #> [1] \"ca\" #>  #> $ca$match #> [1] TRUE #>  #>"},{"path":"/reference/estimate_h0.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate baseline model for the LMS and QML approach — estimate_h0","title":"Estimate baseline model for the LMS and QML approach — estimate_h0","text":"Estimates baseline model (H0) given model (H1) compares fit models. baseline model estimated removing interaction terms model.","code":""},{"path":"/reference/estimate_h0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate baseline model for the LMS and QML approach — estimate_h0","text":"","code":"estimate_h0(object, warn_no_interaction = TRUE, ...)"},{"path":"/reference/estimate_h0.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate baseline model for the LMS and QML approach — estimate_h0","text":"object object class `modsem_da`. warn_no_interaction Logical. `TRUE`, warning issued interaction terms found model. ... Additional arguments passed `modsem_da` function, overriding arguments original model.","code":""},{"path":"/reference/estimate_h0.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate baseline model for the LMS and QML approach — estimate_h0","text":"","code":"if (FALSE) { # \\dontrun{ m1 <- \"  # Outer Model  X =~ x1 + x2 + x3  Y =~ y1 + y2 + y3  Z =~ z1 + z2 + z3   # Inner model  Y ~ X + Z + X:Z \"  est_h1 <- modsem(m1, oneInt, \"lms\") est_h0 <- estimate_h0(est_h1, calc.se=FALSE) # std.errors are not needed compare_fit(est_h0, est_h1) } # }"},{"path":"/reference/extract_lavaan.html","id":null,"dir":"Reference","previous_headings":"","what":"extract lavaan object from modsem object estimated using product indicators — extract_lavaan","title":"extract lavaan object from modsem object estimated using product indicators — extract_lavaan","text":"extract lavaan object modsem object estimated using product indicators","code":""},{"path":"/reference/extract_lavaan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract lavaan object from modsem object estimated using product indicators — extract_lavaan","text":"","code":"extract_lavaan(object)"},{"path":"/reference/extract_lavaan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract lavaan object from modsem object estimated using product indicators — extract_lavaan","text":"object modsem object","code":""},{"path":"/reference/extract_lavaan.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"extract lavaan object from modsem object estimated using product indicators — extract_lavaan","text":"lavaan object","code":""},{"path":"/reference/extract_lavaan.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"extract lavaan object from modsem object estimated using product indicators — extract_lavaan","text":"","code":"library(modsem) m1 <- '   # Outer Model   X =~ x1 + x2 + x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z ' est <- modsem_pi(m1, oneInt) lav_est <- extract_lavaan(est)"},{"path":"/reference/fit_modsem_da.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit measures for QML and LMS models — fit_modsem_da","title":"Fit measures for QML and LMS models — fit_modsem_da","text":"Calculates chi-sq test p-value, well RMSEA LMS QML models. Note Chi-Square based fit measures calculated baseline model, .e., model without interaction effect","code":""},{"path":"/reference/fit_modsem_da.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit measures for QML and LMS models — fit_modsem_da","text":"","code":"fit_modsem_da(model, chisq = TRUE)"},{"path":"/reference/fit_modsem_da.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit measures for QML and LMS models — fit_modsem_da","text":"model fitted model. Thereafter, can use 'compare_fit()' assess comparative fit models. interaction effect makes model better, e.g., RMSEA good baseline model, interaction model likely good RMSEA well. chisq Chi-Square based fit-measures calculated?","code":""},{"path":"/reference/get_pi_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Get data with product indicators for different approaches — get_pi_data","title":"Get data with product indicators for different approaches — get_pi_data","text":"get_pi_syntax() function creating lavaan syntax used estimating latent interaction models using one product indicators lavaan.","code":""},{"path":"/reference/get_pi_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get data with product indicators for different approaches — get_pi_data","text":"","code":"get_pi_data(model.syntax, data, method = \"dblcent\", match = FALSE, ...)"},{"path":"/reference/get_pi_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get data with product indicators for different approaches — get_pi_data","text":"model.syntax lavaan syntax data data create product indicators method method use: \"rca\" = residual centering approach, \"uca\" = unconstrained approach, \"dblcent\" = double centering approach, \"pind\" = prod ind approach, constraints centering, \"custom\" = use parameters specified function call match product indicators created using match-strategy ... arguments passed functions (e.g., modsem_pi)","code":""},{"path":"/reference/get_pi_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get data with product indicators for different approaches — get_pi_data","text":"data.frame","code":""},{"path":"/reference/get_pi_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get data with product indicators for different approaches — get_pi_data","text":"","code":"library(modsem) library(lavaan) #> This is lavaan 0.6-19 #> lavaan is FREE software! Please report any bugs. m1 <- '   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z ' syntax <- get_pi_syntax(m1) data <- get_pi_data(m1, oneInt) est <- sem(syntax, data)"},{"path":"/reference/get_pi_syntax.html","id":null,"dir":"Reference","previous_headings":"","what":"Get lavaan syntax for product indicator approaches — get_pi_syntax","title":"Get lavaan syntax for product indicator approaches — get_pi_syntax","text":"get_pi_syntax() function creating lavaan syntax used estimating latent interaction models using one product indicators lavaan.","code":""},{"path":"/reference/get_pi_syntax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get lavaan syntax for product indicator approaches — get_pi_syntax","text":"","code":"get_pi_syntax(model.syntax, method = \"dblcent\", match = FALSE, ...)"},{"path":"/reference/get_pi_syntax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get lavaan syntax for product indicator approaches — get_pi_syntax","text":"model.syntax lavaan syntax method method use: \"rca\" = residual centering approach, \"uca\" = unconstrained approach, \"dblcent\" = double centering approach, \"pind\" = prod ind approach, constraints centering, \"custom\" = use parameters specified function call match product indicators created using match-strategy ... arguments passed functions (e.g., modsem_pi)","code":""},{"path":"/reference/get_pi_syntax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get lavaan syntax for product indicator approaches — get_pi_syntax","text":"character vector","code":""},{"path":"/reference/get_pi_syntax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get lavaan syntax for product indicator approaches — get_pi_syntax","text":"","code":"library(modsem) library(lavaan) m1 <- '   # Outer Model   X =~ x1 + x2 + x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z ' syntax <- get_pi_syntax(m1) data <- get_pi_data(m1, oneInt) est <- sem(syntax, data)"},{"path":"/reference/jordan.html","id":null,"dir":"Reference","previous_headings":"","what":"Jordan subset of PISA 2006 data — jordan","title":"Jordan subset of PISA 2006 data — jordan","text":"data stem large-scale assessment study PISA 2006 (Organisation Economic Co-Operation Development, 2009) competencies 15-year-old students reading, mathematics, science assessed using nationally representative samples 3-year cycles. eacademicample, data student background questionnaire Jordan sample PISA 2006 used. data students complete responses 15 items (N = 6,038) considered.","code":""},{"path":"/reference/jordan.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Jordan subset of PISA 2006 data — jordan","text":"data frame fifteen variables 6,038 observations: enjoy1 indicator enjoyment science, item ST16Q01: generally fun learning <broad science> topics. enjoy2 indicator enjoyment science, item ST16Q02: like reading <broad science>. enjoy3 indicator enjoyment science, item ST16Q03: happy <broad science> problems. enjoy4 indicator enjoyment science, item ST16Q04: enjoy acquiring new knowledge <broad science>. enjoy5 indicator enjoyment science, item ST16Q05: interested learning <broad science>. academic1 indicator academic self-concept science, item ST37Q01: can easily understand new ideas <school science>. academic2 indicator academic self-concept science, item ST37Q02: Learning advanced <school science> topics easy . academic3 indicator academic self-concept science, item ST37Q03: can usually give good answers <test questions> <school science> topics. academic4 indicator academic self-concept science, item ST37Q04: learn <school science> topics quickly. academic5 indicator academic self-concept science, item ST37Q05: <School science> topics easy . academic6 indicator academic self-concept science, item ST37Q06: taught <school science>, can understand concepts well. career1 indicator career aspirations science, item ST29Q01: like work career involving <broad science>. career2 indicator career aspirations science, item ST29Q02: like study <broad science> <secondary school>. career3 indicator career aspirations science, item ST29Q03: like spend life advanced <broad science>. career4 indicator career aspirations science, item ST29Q04: like work <broad science> projects adult.","code":""},{"path":"/reference/jordan.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Jordan subset of PISA 2006 data — jordan","text":"version dataset, well description gathered documentation 'nlsem' package (https://cran.r-project.org/package=nlsem), difference names variables changed Originally dataset gathered Organisation Economic Co-Operation Development (2009). Pisa 2006: Science competencies tomorrow's world (Tech. Rep.). Paris, France. Obtained : https://www.oecd.org/pisa/pisaproducts/database-pisa2006.htm","code":""},{"path":"/reference/jordan.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Jordan subset of PISA 2006 data — jordan","text":"","code":"if (FALSE) { # \\dontrun{ m1 <- \"   ENJ =~ enjoy1 + enjoy2 + enjoy3 + enjoy4 + enjoy5   CAREER =~ career1 + career2 + career3 + career4   SC =~ academic1 + academic2 + academic3 + academic4 + academic5 + academic6   CAREER ~ ENJ + SC + ENJ:ENJ + SC:SC + ENJ:SC \"  est <- modsem(m1, data = jordan) } # }"},{"path":"/reference/modsem-package.html","id":null,"dir":"Reference","previous_headings":"","what":"modsem: Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM) — modsem-package","title":"modsem: Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM) — modsem-package","text":"Estimation interaction (.e., moderation) effects latent variables structural equation models (SEM). supported methods : constrained approach (Algina & Moulder, 2001). unconstrained approach (Marsh et al., 2004). residual centering approach (Little et al., 2006). double centering approach (Lin et al., 2010). latent moderated structural equations (LMS) approach (Klein & Moosbrugger, 2000). quasi-maximum likelihood (QML) approach (Klein & Muthén, 2007) (temporarily unavailable) constrained- unconstrained, residual- double centering- approaches estimated via 'lavaan' (Rosseel, 2012), whilst LMS- QML- approaches estimated via 'modsem' self. Alternatively model can estimated via 'Mplus' (Muthén & Muthén, 1998-2017). References: Algina, J., & Moulder, B. C. (2001). doi:10.1207/S15328007SEM0801_3 . \"note estimating Jöreskog-Yang model latent variable interaction using 'LISREL' 8.3.\" Klein, ., & Moosbrugger, H. (2000). doi:10.1007/BF02296338 . \"Maximum likelihood estimation latent interaction effects LMS method.\" Klein, . G., & Muthén, B. O. (2007). doi:10.1080/00273170701710205 . \"Quasi-maximum likelihood estimation structural equation models multiple interaction quadratic effects.\" Lin, G. C., Wen, Z., Marsh, H. W., & Lin, H. S. (2010). doi:10.1080/10705511.2010.488999 . \"Structural equation models latent interactions: Clarification orthogonalizing double-mean-centering strategies.\" Little, T. D., Bovaird, J. ., & Widaman, K. F. (2006). doi:10.1207/s15328007sem1304_1 . \"merits orthogonalizing powered product terms: Implications modeling interactions among latent variables.\" Marsh, H. W., Wen, Z., & Hau, K. T. (2004). doi:10.1037/1082-989X.9.3.275 . \"Structural equation models latent interactions: evaluation alternative estimation strategies indicator construction.\" Muthén, L.K. Muthén, B.O. (1998-2017). \"'Mplus' User’s Guide. Eighth Edition.\" https://www.statmodel.com/. Rosseel Y (2012). doi:10.18637/jss.v048.i02 . \"'lavaan': R Package Structural Equation Modeling.\"","code":""},{"path":[]},{"path":"/reference/modsem-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"modsem: Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM) — modsem-package","text":"Maintainer: Kjell Solem Slupphaug slupphaugkjell@gmail.com (ORCID) contributors: Mehmet Mehmetoglu mehmetm@ntnu.(ORCID) [contributor] Matthias Mittner matthias.mittner@uit.(ORCID) [contributor]","code":""},{"path":"/reference/modsem.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate interaction effects in structural equation models (SEMs) — modsem","title":"Estimate interaction effects in structural equation models (SEMs) — modsem","text":"modsem() function estimating interaction effects latent variables structural equation models (SEMs). Methods estimating interaction effects SEMs can basically split two frameworks: 1. Product Indicator-based approaches (\"dblcent\", \"rca\", \"uca\", \"ca\", \"pind\") 2. Distributionally based approaches (\"lms\", \"qml\"). product indicator-based approaches, modsem() essentially fancy wrapper lavaan::sem() generates necessary syntax variables estimation models latent product indicators. distributionally based approaches implemented separately estimated using lavaan::sem(), rather using custom functions (largely written C++ performance reasons). greater control, advised use one sub-functions (modsem_pi, modsem_da, modsem_mplus) directly, passing additional arguments via modsem() can lead unexpected behavior.","code":""},{"path":"/reference/modsem.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate interaction effects in structural equation models (SEMs) — modsem","text":"","code":"modsem(model.syntax = NULL, data = NULL, method = \"dblcent\", ...)"},{"path":"/reference/modsem.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate interaction effects in structural equation models (SEMs) — modsem","text":"model.syntax lavaan syntax data dataframe method method use: \"rca\" = residual centering approach (passed lavaan), \"uca\" = unconstrained approach (passed lavaan), \"dblcent\" = double centering approach (passed lavaan), \"pind\" = prod ind approach, constraints centering (passed lavaan), \"lms\" = latent model structural equations (passed lavaan), \"qml\" = quasi maximum likelihood estimation latent model structural equations (passed lavaan), \"custom\" = use parameters specified function call (passed lavaan). ... arguments passed functions depending method (see modsem_pi, modsem_da, modsem_mplus)","code":""},{"path":"/reference/modsem.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate interaction effects in structural equation models (SEMs) — modsem","text":"modsem object class modsem_pi, modsem_da, modsem_mplus","code":""},{"path":"/reference/modsem.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate interaction effects in structural equation models (SEMs) — modsem","text":"","code":"library(modsem) # For more examples, check README and/or GitHub. # One interaction m1 <- '   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z '  # Double centering approach est1 <- modsem(m1, oneInt) summary(est1) #> modsem (version 1.0.9, approach = dblcent): #> lavaan 0.6-19 ended normally after 161 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        60 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                               122.924 #>   Degrees of freedom                               111 #>   P-value (Chi-square)                           0.207 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   X =~                                                 #>     x1                1.000                            #>     x2                0.804    0.013   63.612    0.000 #>     x3                0.916    0.014   67.144    0.000 #>   Y =~                                                 #>     y1                1.000                            #>     y2                0.798    0.007  107.428    0.000 #>     y3                0.899    0.008  112.453    0.000 #>   Z =~                                                 #>     z1                1.000                            #>     z2                0.812    0.013   64.763    0.000 #>     z3                0.882    0.013   67.014    0.000 #>   XZ =~                                                #>     x1z1              1.000                            #>     x2z1              0.805    0.013   60.636    0.000 #>     x3z1              0.877    0.014   62.680    0.000 #>     x1z2              0.793    0.013   59.343    0.000 #>     x2z2              0.646    0.015   43.672    0.000 #>     x3z2              0.706    0.016   44.292    0.000 #>     x1z3              0.887    0.014   63.700    0.000 #>     x2z3              0.716    0.016   45.645    0.000 #>     x3z3              0.781    0.017   45.339    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   Y ~                                                  #>     X                 0.675    0.027   25.379    0.000 #>     Z                 0.561    0.026   21.606    0.000 #>     XZ                0.702    0.027   26.360    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>  .x1z1 ~~                                              #>    .x2z2              0.000                            #>    .x2z3              0.000                            #>    .x3z2              0.000                            #>    .x3z3              0.000                            #>  .x2z1 ~~                                              #>    .x1z2              0.000                            #>  .x1z2 ~~                                              #>    .x2z3              0.000                            #>  .x3z1 ~~                                              #>    .x1z2              0.000                            #>  .x1z2 ~~                                              #>    .x3z3              0.000                            #>  .x2z1 ~~                                              #>    .x1z3              0.000                            #>  .x2z2 ~~                                              #>    .x1z3              0.000                            #>  .x3z1 ~~                                              #>    .x1z3              0.000                            #>  .x3z2 ~~                                              #>    .x1z3              0.000                            #>  .x2z1 ~~                                              #>    .x3z2              0.000                            #>    .x3z3              0.000                            #>  .x3z1 ~~                                              #>    .x2z2              0.000                            #>  .x2z2 ~~                                              #>    .x3z3              0.000                            #>  .x3z1 ~~                                              #>    .x2z3              0.000                            #>  .x3z2 ~~                                              #>    .x2z3              0.000                            #>  .x1z1 ~~                                              #>    .x1z2              0.115    0.008   14.802    0.000 #>    .x1z3              0.114    0.008   13.947    0.000 #>    .x2z1              0.125    0.008   16.095    0.000 #>    .x3z1              0.140    0.009   16.135    0.000 #>  .x1z2 ~~                                              #>    .x1z3              0.103    0.007   14.675    0.000 #>    .x2z2              0.128    0.006   20.850    0.000 #>    .x3z2              0.146    0.007   21.243    0.000 #>  .x1z3 ~~                                              #>    .x2z3              0.116    0.007   17.818    0.000 #>    .x3z3              0.135    0.007   18.335    0.000 #>  .x2z1 ~~                                              #>    .x2z2              0.135    0.006   20.905    0.000 #>    .x2z3              0.145    0.007   21.145    0.000 #>    .x3z1              0.114    0.007   16.058    0.000 #>  .x2z2 ~~                                              #>    .x2z3              0.117    0.006   20.419    0.000 #>    .x3z2              0.116    0.006   20.586    0.000 #>  .x2z3 ~~                                              #>    .x3z3              0.109    0.006   18.059    0.000 #>  .x3z1 ~~                                              #>    .x3z2              0.138    0.007   19.331    0.000 #>    .x3z3              0.158    0.008   20.269    0.000 #>  .x3z2 ~~                                              #>    .x3z3              0.131    0.007   19.958    0.000 #>   X ~~                                                 #>     Z                 0.201    0.024    8.271    0.000 #>     XZ                0.016    0.025    0.628    0.530 #>   Z ~~                                                 #>     XZ                0.062    0.025    2.449    0.014 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .x1                0.160    0.009   17.871    0.000 #>    .x2                0.162    0.007   22.969    0.000 #>    .x3                0.163    0.008   20.161    0.000 #>    .y1                0.159    0.009   17.896    0.000 #>    .y2                0.154    0.007   22.640    0.000 #>    .y3                0.164    0.008   20.698    0.000 #>    .z1                0.168    0.009   18.143    0.000 #>    .z2                0.158    0.007   22.264    0.000 #>    .z3                0.158    0.008   20.389    0.000 #>    .x1z1              0.311    0.014   22.227    0.000 #>    .x2z1              0.292    0.011   27.287    0.000 #>    .x3z1              0.327    0.012   26.275    0.000 #>    .x1z2              0.290    0.011   26.910    0.000 #>    .x2z2              0.239    0.008   29.770    0.000 #>    .x3z2              0.270    0.009   29.117    0.000 #>    .x1z3              0.272    0.012   23.586    0.000 #>    .x2z3              0.245    0.009   27.979    0.000 #>    .x3z3              0.297    0.011   28.154    0.000 #>     X                 0.981    0.036   26.895    0.000 #>    .Y                 0.990    0.038   25.926    0.000 #>     Z                 1.016    0.038   26.856    0.000 #>     XZ                1.045    0.044   24.004    0.000 #>   if (FALSE) { # \\dontrun{ # The Constrained Approach est1_ca <- modsem(m1, oneInt, method = \"ca\") summary(est1_ca)  # LMS approach est1_lms <- modsem(m1, oneInt, method = \"lms\", EFIM.S=1000) summary(est1_lms)  # QML approach est1_qml <- modsem(m1, oneInt, method = \"qml\") summary(est1_qml) } # }  # Theory Of Planned Behavior tpb <- ' # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ INT:PBC '  # Double centering approach est_tpb <- modsem(tpb, data = TPB) summary(est_tpb) #> modsem (version 1.0.9, approach = dblcent): #> lavaan 0.6-19 ended normally after 173 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        78 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                               207.615 #>   Degrees of freedom                               222 #>   P-value (Chi-square)                           0.747 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   ATT =~                                               #>     att1              1.000                            #>     att2              0.878    0.012   71.509    0.000 #>     att3              0.789    0.012   66.368    0.000 #>     att4              0.695    0.011   61.017    0.000 #>     att5              0.887    0.013   70.884    0.000 #>   SN =~                                                #>     sn1               1.000                            #>     sn2               0.889    0.017   52.553    0.000 #>   PBC =~                                               #>     pbc1              1.000                            #>     pbc2              0.912    0.013   69.500    0.000 #>     pbc3              0.801    0.012   65.830    0.000 #>   INT =~                                               #>     int1              1.000                            #>     int2              0.914    0.016   58.982    0.000 #>     int3              0.808    0.015   55.547    0.000 #>   BEH =~                                               #>     b1                1.000                            #>     b2                0.960    0.030   31.561    0.000 #>   INTPBC =~                                            #>     int1pbc1          1.000                            #>     int2pbc1          0.931    0.015   63.809    0.000 #>     int3pbc1          0.774    0.013   60.107    0.000 #>     int1pbc2          0.893    0.013   68.173    0.000 #>     int2pbc2          0.826    0.017   48.845    0.000 #>     int3pbc2          0.690    0.015   45.300    0.000 #>     int1pbc3          0.799    0.012   67.008    0.000 #>     int2pbc3          0.738    0.015   47.809    0.000 #>     int3pbc3          0.622    0.014   45.465    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   INT ~                                                #>     ATT               0.213    0.026    8.170    0.000 #>     SN                0.177    0.028    6.416    0.000 #>     PBC               0.217    0.030    7.340    0.000 #>   BEH ~                                                #>     INT               0.191    0.024    7.817    0.000 #>     PBC               0.230    0.022   10.507    0.000 #>     INTPBC            0.204    0.018   11.425    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>  .int1pbc1 ~~                                          #>    .int2pbc2          0.000                            #>    .int2pbc3          0.000                            #>    .int3pbc2          0.000                            #>    .int3pbc3          0.000                            #>  .int2pbc1 ~~                                          #>    .int1pbc2          0.000                            #>  .int1pbc2 ~~                                          #>    .int2pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int1pbc2          0.000                            #>  .int1pbc2 ~~                                          #>    .int3pbc3          0.000                            #>  .int2pbc1 ~~                                          #>    .int1pbc3          0.000                            #>  .int2pbc2 ~~                                          #>    .int1pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int1pbc3          0.000                            #>  .int3pbc2 ~~                                          #>    .int1pbc3          0.000                            #>  .int2pbc1 ~~                                          #>    .int3pbc2          0.000                            #>    .int3pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int2pbc2          0.000                            #>  .int2pbc2 ~~                                          #>    .int3pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int2pbc3          0.000                            #>  .int3pbc2 ~~                                          #>    .int2pbc3          0.000                            #>  .int1pbc1 ~~                                          #>    .int1pbc2          0.126    0.009   14.768    0.000 #>    .int1pbc3          0.102    0.007   13.794    0.000 #>    .int2pbc1          0.104    0.007   14.608    0.000 #>    .int3pbc1          0.091    0.006   14.109    0.000 #>  .int1pbc2 ~~                                          #>    .int1pbc3          0.095    0.007   13.852    0.000 #>    .int2pbc2          0.128    0.007   19.320    0.000 #>    .int3pbc2          0.119    0.006   19.402    0.000 #>  .int1pbc3 ~~                                          #>    .int2pbc3          0.110    0.006   19.911    0.000 #>    .int3pbc3          0.097    0.005   19.415    0.000 #>  .int2pbc1 ~~                                          #>    .int2pbc2          0.152    0.008   18.665    0.000 #>    .int2pbc3          0.138    0.007   18.779    0.000 #>    .int3pbc1          0.082    0.006   13.951    0.000 #>  .int2pbc2 ~~                                          #>    .int2pbc3          0.121    0.007   18.361    0.000 #>    .int3pbc2          0.104    0.005   19.047    0.000 #>  .int2pbc3 ~~                                          #>    .int3pbc3          0.087    0.005   19.180    0.000 #>  .int3pbc1 ~~                                          #>    .int3pbc2          0.139    0.007   21.210    0.000 #>    .int3pbc3          0.123    0.006   21.059    0.000 #>  .int3pbc2 ~~                                          #>    .int3pbc3          0.114    0.005   21.021    0.000 #>   ATT ~~                                               #>     SN                0.629    0.029   21.977    0.000 #>     PBC               0.678    0.029   23.721    0.000 #>     INTPBC            0.086    0.024    3.519    0.000 #>   SN ~~                                                #>     PBC               0.678    0.029   23.338    0.000 #>     INTPBC            0.055    0.025    2.230    0.026 #>   PBC ~~                                               #>     INTPBC            0.087    0.024    3.609    0.000 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .att1              0.167    0.007   23.528    0.000 #>    .att2              0.150    0.006   24.693    0.000 #>    .att3              0.160    0.006   26.378    0.000 #>    .att4              0.163    0.006   27.649    0.000 #>    .att5              0.159    0.006   24.930    0.000 #>    .sn1               0.178    0.015   12.110    0.000 #>    .sn2               0.156    0.012   13.221    0.000 #>    .pbc1              0.145    0.008   18.440    0.000 #>    .pbc2              0.160    0.007   21.547    0.000 #>    .pbc3              0.154    0.007   23.716    0.000 #>    .int1              0.158    0.009   18.152    0.000 #>    .int2              0.160    0.008   20.345    0.000 #>    .int3              0.167    0.007   23.414    0.000 #>    .b1                0.186    0.018   10.058    0.000 #>    .b2                0.135    0.017    8.080    0.000 #>    .int1pbc1          0.266    0.013   20.971    0.000 #>    .int2pbc1          0.292    0.012   24.421    0.000 #>    .int3pbc1          0.251    0.010   26.305    0.000 #>    .int1pbc2          0.290    0.012   24.929    0.000 #>    .int2pbc2          0.269    0.010   26.701    0.000 #>    .int3pbc2          0.253    0.009   29.445    0.000 #>    .int1pbc3          0.223    0.009   24.431    0.000 #>    .int2pbc3          0.234    0.008   27.633    0.000 #>    .int3pbc3          0.203    0.007   29.288    0.000 #>     ATT               0.998    0.037   27.138    0.000 #>     SN                0.987    0.039   25.394    0.000 #>     PBC               0.962    0.035   27.260    0.000 #>    .INT               0.490    0.020   24.638    0.000 #>    .BEH               0.455    0.023   20.068    0.000 #>     INTPBC            1.020    0.041   24.612    0.000 #>   if (FALSE) { # \\dontrun{ # The Constrained Approach est_tpb_ca <- modsem(tpb, data = TPB, method = \"ca\") summary(est_tpb_ca)  # LMS approach est_tpb_lms <- modsem(tpb, data = TPB, method = \"lms\") summary(est_tpb_lms)  # QML approach est_tpb_qml <- modsem(tpb, data = TPB, method = \"qml\") summary(est_tpb_qml) } # }"},{"path":"/reference/modsem_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper for coef — modsem_coef","title":"Wrapper for coef — modsem_coef","text":"wrapper coef, used modsem::modsem_coef, since coef namespace modsem, stats since coef namespace modsem, stats","code":""},{"path":"/reference/modsem_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper for coef — modsem_coef","text":"","code":"modsem_coef(object, ...)"},{"path":"/reference/modsem_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper for coef — modsem_coef","text":"object fittet model inspect ... additional arguments","code":""},{"path":"/reference/modsem_da.html","id":null,"dir":"Reference","previous_headings":"","what":"Interaction between latent variables using lms and qml approaches — modsem_da","title":"Interaction between latent variables using lms and qml approaches — modsem_da","text":"modsem_da() function estimating interaction effects latent variables structural equation models (SEMs) using distributional analytic (DA) approaches. Methods estimating interaction effects SEMs can basically split two frameworks: 1. Product Indicator-based approaches (\"dblcent\", \"rca\", \"uca\", \"ca\", \"pind\") 2. Distributionally based approaches (\"lms\", \"qml\"). modsem_da() handles latter can estimate models using QML LMS, necessary syntax, variables estimation models latent product indicators. NOTE: Run default_settings_da see default arguments.","code":""},{"path":"/reference/modsem_da.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interaction between latent variables using lms and qml approaches — modsem_da","text":"","code":"modsem_da(   model.syntax = NULL,   data = NULL,   method = \"lms\",   verbose = NULL,   optimize = NULL,   nodes = NULL,   convergence.abs = NULL,   convergence.rel = NULL,   optimizer = NULL,   center.data = NULL,   standardize.data = NULL,   standardize.out = NULL,   standardize = NULL,   mean.observed = NULL,   cov.syntax = NULL,   double = NULL,   calc.se = NULL,   FIM = NULL,   EFIM.S = NULL,   OFIM.hessian = NULL,   EFIM.parametric = NULL,   robust.se = NULL,   R.max = NULL,   max.iter = NULL,   max.step = NULL,   start = NULL,   epsilon = NULL,   quad.range = NULL,   adaptive.quad = NULL,   adaptive.quad.tol = NULL,   n.threads = NULL,   algorithm = NULL,   em.control = NULL,   ... )"},{"path":"/reference/modsem_da.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interaction between latent variables using lms and qml approaches — modsem_da","text":"model.syntax lavaan syntax data dataframe method method use: \"lms\" = latent model structural equations (passed lavaan). \"qml\" = quasi maximum likelihood estimation latent model structural equations (passed lavaan). verbose estimation progress shown optimize starting parameters optimized nodes number quadrature nodes (points integration) used lms, increased number gives better estimates slower computation. many needed depends complexity model. simple models, somewhere 16-24 nodes enough; complex models, higher numbers may needed. models interaction effect endogenous exogenous variable, number nodes least 32, practically (e.g., ordinal/skewed data), 32 recommended. cases data non-normal, might better use qml approach instead. large numbers nodes, might want change 'quad.range' argument. convergence.abs Absolute convergence criterion. Lower values give better estimates slower computation. relevant using QML approach. LMS approach EM-algorithm stops whenever relative absolute convergence criterion reached. convergence.rel Relative convergence criterion. Lower values give better estimates slower computation. LMS approach EM-algorithm stops whenever relative absolute convergence criterion reached. optimizer optimizer use, can either \"nlminb\" \"L-BFGS-B\". LMS, \"nlminb\" recommended. QML, \"L-BFGS-B\" may faster large number iterations, slower iterations. center.data data centered fitting model standardize.data data scaled fitting model, overridden standardize standardize set TRUE. NOTE: recommended estimate model normally standardize output using standardize_model standardized_estimates, summary(<modsem_da-object>, standardize=TRUE) standardize.output standardized (note alter relationships parameter constraints since parameters scaled unevenly, even label). alter estimation model, output. NOTE: recommended estimate model normally standardize output using standardized_estimates. standardize standardize data fitting model, remove mean structure observed variables, standardize output. Note standardize.data, mean.observed, standardize.overridden standardize standardize set TRUE. NOTE: recommended estimate model normally standardize output using standardized_estimates. mean.observed mean structure observed variables estimated? overridden standardize standardize set TRUE. NOTE: recommended unless know . cov.syntax model syntax implied covariance matrix (see vignette(\"interaction_two_etas\", \"modsem\")) double try double number dimensions integration used LMS, extremely slow similar mplus. calc.se standard errors computed? NOTE: FALSE, information matrix computed either. FIM Fisher information matrix calculated using observed expected values? Must either \"observed\" \"expected\". EFIM.S expected Fisher information matrix computed, EFIM.S selects number Monte Carlo samples. Defaults 100. NOTE: number likely increased better estimates (e.g., 1000-10000), might drasticly increase computation time. OFIM.hessian observed Fisher information computed using Hessian? FALSE, computed using gradient. EFIM.parametric data calculating expected Fisher information matrix simulated parametrically (simulated based assumptions implied parameters model), non-parametrically (stochastically sampled)? believe normality assumptions violated, EFIM.parametric = FALSE might better option. robust.se robust standard errors computed? Meant used QML, can unreliable LMS approach. R.max Maximum population size (sample size) used calculated expected fischer information matrix. max.iter maximum number iterations. max.step maximum steps M-step EM algorithm (LMS). start starting parameters. epsilon finite difference numerical derivatives. quad.range range z-scores perform numerical integration LMS using Gaussian-Hermite Quadratures. default Inf, f(t) integrated -Inf Inf, likely inefficient pointless large number nodes. Nodes outside +/- quad.range ignored. adaptive.quad quasi adaptive quadrature used? TRUE, quadrature nodes adapted data. FALSE, quadrature nodes fixed. Default FALSE. adaptive quadrature fit adaptive quadrature participant, instead tries place nodes posterior distribution highest. Compared fixed Gauss Hermite quadrature usually means less nodes placed tails distribution. adaptive.quad.tol Relavtive tolerance determining adaptive quadrature accurate enough n.threads number cores use parallel processing. NULL, use <= 2 threads. integer specified, use number threads (e.g., n.threads = 4 use 4 threads). \"default\", use default number threads (2). \"max\", use available threads, \"min\" use 1 thread. algorithm algorithm use EM algorithm. Can either \"EM\" \"EMA\". \"EM\" standard EM algorithm. \"EMA\" accelerated EM procedure uses Quasi-Newton Fisher Scoring optimization steps needed. Default \"EM\". em.control list control parameters EM algorithm. See default_settings_da defaults. ... additional arguments passed estimation function.","code":""},{"path":"/reference/modsem_da.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interaction between latent variables using lms and qml approaches — modsem_da","text":"modsem_da object","code":""},{"path":"/reference/modsem_da.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interaction between latent variables using lms and qml approaches — modsem_da","text":"","code":"library(modsem) # For more examples, check README and/or GitHub. # One interaction m1 <- \"   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z \"  if (FALSE) { # \\dontrun{ # QML Approach est1 <- modsem_da(m1, oneInt, method = \"qml\") summary(est1)  # Theory Of Planned Behavior tpb <- \" # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   # Covariances   ATT ~~ SN + PBC   PBC ~~ SN   # Causal Relationships   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ INT:PBC \"  # LMS Approach estTpb <- modsem_da(tpb, data = TPB, method = lms, EFIM.S = 1000) summary(estTpb) } # }"},{"path":"/reference/modsem_inspect.html","id":null,"dir":"Reference","previous_headings":"","what":"Inspect model information — modsem_inspect","title":"Inspect model information — modsem_inspect","text":"function used inspect fittet object. similar `lavInspect()` argument '' decides inspect","code":""},{"path":"/reference/modsem_inspect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inspect model information — modsem_inspect","text":"","code":"modsem_inspect(object, what = NULL, ...)"},{"path":"/reference/modsem_inspect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inspect model information — modsem_inspect","text":"object fittet model inspect inspect ... Additional arguments passed functions","code":""},{"path":"/reference/modsem_inspect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inspect model information — modsem_inspect","text":"`modsem_da`, `modsem_lavaan` `modsem_lavaan`, just wrapper `lavInspect()` `modsem_da` “ can either \"\", \"matrices\", \"optim\", just name extract.","code":""},{"path":"/reference/modsem_mplus.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation latent interactions through mplus — modsem_mplus","title":"Estimation latent interactions through mplus — modsem_mplus","text":"Estimation latent interactions mplus","code":""},{"path":"/reference/modsem_mplus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation latent interactions through mplus — modsem_mplus","text":"","code":"modsem_mplus(   model.syntax,   data,   estimator = \"ml\",   type = \"random\",   algorithm = \"integration\",   process = \"8\",   ... )"},{"path":"/reference/modsem_mplus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation latent interactions through mplus — modsem_mplus","text":"model.syntax lavaan/modsem syntax data dataset estimator estimator argument passed mplus type type argument passed mplus algorithm algorithm argument passed mplus process process argument passed mplus ... arguments passed functions","code":""},{"path":"/reference/modsem_mplus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation latent interactions through mplus — modsem_mplus","text":"modsem_mplus object","code":""},{"path":"/reference/modsem_mplus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation latent interactions through mplus — modsem_mplus","text":"","code":"# Theory Of Planned Behavior tpb <- ' # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   # Covariances   ATT ~~ SN + PBC   PBC ~~ SN   # Causal Relationsships   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ INT:PBC '  if (FALSE) { # \\dontrun{ estTpbMplus <- modsem_mplus(tpb, data = TPB) summary(estTpbMplus) } # }"},{"path":"/reference/modsem_nobs.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper for nobs — modsem_nobs","title":"Wrapper for nobs — modsem_nobs","text":"wrapper nobs, used modsem::modsem_nobs, since nobs namespace modsem, stats since nobs namespace modsem, stats","code":""},{"path":"/reference/modsem_nobs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper for nobs — modsem_nobs","text":"","code":"modsem_nobs(object, ...)"},{"path":"/reference/modsem_nobs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper for nobs — modsem_nobs","text":"object fittet model inspect ... additional arguments","code":""},{"path":"/reference/modsem_pi.html","id":null,"dir":"Reference","previous_headings":"","what":"Interaction between latent variables using product indicators — modsem_pi","title":"Interaction between latent variables using product indicators — modsem_pi","text":"modsem_pi() function estimating interaction effects latent variables, structural equation models (SEMs), using product indicators. Methods estimating interaction effects SEMs can basically split two frameworks: 1. Product Indicator based approaches (\"dblcent\", \"rca\", \"uca\", \"ca\", \"pind\"), 2. Distributionally based approaches (\"lms\", \"qml\"). modsem_pi() essentially fancy wrapper lavaan::sem() generates necessary syntax variables estimation models latent product indicators. Use default_settings_pi() get default settings different methods.","code":""},{"path":"/reference/modsem_pi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interaction between latent variables using product indicators — modsem_pi","text":"","code":"modsem_pi(   model.syntax = NULL,   data = NULL,   method = \"dblcent\",   match = NULL,   standardize.data = FALSE,   center.data = FALSE,   first.loading.fixed = FALSE,   center.before = NULL,   center.after = NULL,   residuals.prods = NULL,   residual.cov.syntax = NULL,   constrained.prod.mean = NULL,   constrained.loadings = NULL,   constrained.var = NULL,   constrained.res.cov.method = NULL,   auto.scale = \"none\",   auto.center = \"none\",   estimator = \"ML\",   group = NULL,   cluster = NULL,   run = TRUE,   na.rm = FALSE,   suppress.warnings.lavaan = FALSE,   suppress.warnings.match = FALSE,   ... )"},{"path":"/reference/modsem_pi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interaction between latent variables using product indicators — modsem_pi","text":"model.syntax lavaan syntax data dataframe method method use: \"rca\" = residual centering approach (passed lavaan), \"uca\" = unconstrained approach (passed lavaan), \"dblcent\" = double centering approach (passed lavaan), \"pind\" = prod ind approach, constraints centering (passed lavaan), \"custom\" = use parameters specified function call (passed lavaan) match product indicators created using match-strategy standardize.data data scaled fitting model center.data data centered fitting model first.loading.fixed first factor loading latent product fixed one? Defaults FALSE, already happens lavaan default. TRUE, first factor loading latent product fixed one. manually generated syntax (e.g., XZ =~ 1*x1z1).' center.indicators products centered computing products (overwritten method, method != NULL) center.indicator products centered computed? residuals.prods indicator products centered using residuals (overwritten method, method != NULL) residual.cov.syntax syntax residual covariances produced (overwritten method, method != NULL) constrained.prod.mean syntax product mean produced (overwritten method, method != NULL) constrained.loadings syntax constrained loadings produced (overwritten method, method != NULL) constrained.var syntax constrained variances produced (overwritten method, method != NULL) constrained.res.cov.method method constraining residual covariances auto.scale methods scaled automatically (usually useful) auto.center methods centered automatically (usually useful) estimator estimator use lavaan group group variable multigroup analysis cluster cluster variable multilevel models run model run via lavaan, FALSE modified syntax data returned na.rm missing values removed (case-wise)? Defaults FALSE. TRUE, missing values removed case-wise. FALSE removed. suppress.warnings.lavaan warnings lavaan suppressed? suppress.warnings.match warnings match suppressed? ... arguments passed lavaan::sem()","code":""},{"path":"/reference/modsem_pi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interaction between latent variables using product indicators — modsem_pi","text":"modsem object","code":""},{"path":"/reference/modsem_pi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interaction between latent variables using product indicators — modsem_pi","text":"","code":"library(modsem) # For more examples, check README and/or GitHub. # One interaction m1 <- '   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z '  # Double centering approach est1 <- modsem_pi(m1, oneInt) summary(est1) #> modsem (version 1.0.9, approach = dblcent): #> lavaan 0.6-19 ended normally after 161 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        60 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                               122.924 #>   Degrees of freedom                               111 #>   P-value (Chi-square)                           0.207 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   X =~                                                 #>     x1                1.000                            #>     x2                0.804    0.013   63.612    0.000 #>     x3                0.916    0.014   67.144    0.000 #>   Y =~                                                 #>     y1                1.000                            #>     y2                0.798    0.007  107.428    0.000 #>     y3                0.899    0.008  112.453    0.000 #>   Z =~                                                 #>     z1                1.000                            #>     z2                0.812    0.013   64.763    0.000 #>     z3                0.882    0.013   67.014    0.000 #>   XZ =~                                                #>     x1z1              1.000                            #>     x2z1              0.805    0.013   60.636    0.000 #>     x3z1              0.877    0.014   62.680    0.000 #>     x1z2              0.793    0.013   59.343    0.000 #>     x2z2              0.646    0.015   43.672    0.000 #>     x3z2              0.706    0.016   44.292    0.000 #>     x1z3              0.887    0.014   63.700    0.000 #>     x2z3              0.716    0.016   45.645    0.000 #>     x3z3              0.781    0.017   45.339    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   Y ~                                                  #>     X                 0.675    0.027   25.379    0.000 #>     Z                 0.561    0.026   21.606    0.000 #>     XZ                0.702    0.027   26.360    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>  .x1z1 ~~                                              #>    .x2z2              0.000                            #>    .x2z3              0.000                            #>    .x3z2              0.000                            #>    .x3z3              0.000                            #>  .x2z1 ~~                                              #>    .x1z2              0.000                            #>  .x1z2 ~~                                              #>    .x2z3              0.000                            #>  .x3z1 ~~                                              #>    .x1z2              0.000                            #>  .x1z2 ~~                                              #>    .x3z3              0.000                            #>  .x2z1 ~~                                              #>    .x1z3              0.000                            #>  .x2z2 ~~                                              #>    .x1z3              0.000                            #>  .x3z1 ~~                                              #>    .x1z3              0.000                            #>  .x3z2 ~~                                              #>    .x1z3              0.000                            #>  .x2z1 ~~                                              #>    .x3z2              0.000                            #>    .x3z3              0.000                            #>  .x3z1 ~~                                              #>    .x2z2              0.000                            #>  .x2z2 ~~                                              #>    .x3z3              0.000                            #>  .x3z1 ~~                                              #>    .x2z3              0.000                            #>  .x3z2 ~~                                              #>    .x2z3              0.000                            #>  .x1z1 ~~                                              #>    .x1z2              0.115    0.008   14.802    0.000 #>    .x1z3              0.114    0.008   13.947    0.000 #>    .x2z1              0.125    0.008   16.095    0.000 #>    .x3z1              0.140    0.009   16.135    0.000 #>  .x1z2 ~~                                              #>    .x1z3              0.103    0.007   14.675    0.000 #>    .x2z2              0.128    0.006   20.850    0.000 #>    .x3z2              0.146    0.007   21.243    0.000 #>  .x1z3 ~~                                              #>    .x2z3              0.116    0.007   17.818    0.000 #>    .x3z3              0.135    0.007   18.335    0.000 #>  .x2z1 ~~                                              #>    .x2z2              0.135    0.006   20.905    0.000 #>    .x2z3              0.145    0.007   21.145    0.000 #>    .x3z1              0.114    0.007   16.058    0.000 #>  .x2z2 ~~                                              #>    .x2z3              0.117    0.006   20.419    0.000 #>    .x3z2              0.116    0.006   20.586    0.000 #>  .x2z3 ~~                                              #>    .x3z3              0.109    0.006   18.059    0.000 #>  .x3z1 ~~                                              #>    .x3z2              0.138    0.007   19.331    0.000 #>    .x3z3              0.158    0.008   20.269    0.000 #>  .x3z2 ~~                                              #>    .x3z3              0.131    0.007   19.958    0.000 #>   X ~~                                                 #>     Z                 0.201    0.024    8.271    0.000 #>     XZ                0.016    0.025    0.628    0.530 #>   Z ~~                                                 #>     XZ                0.062    0.025    2.449    0.014 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .x1                0.160    0.009   17.871    0.000 #>    .x2                0.162    0.007   22.969    0.000 #>    .x3                0.163    0.008   20.161    0.000 #>    .y1                0.159    0.009   17.896    0.000 #>    .y2                0.154    0.007   22.640    0.000 #>    .y3                0.164    0.008   20.698    0.000 #>    .z1                0.168    0.009   18.143    0.000 #>    .z2                0.158    0.007   22.264    0.000 #>    .z3                0.158    0.008   20.389    0.000 #>    .x1z1              0.311    0.014   22.227    0.000 #>    .x2z1              0.292    0.011   27.287    0.000 #>    .x3z1              0.327    0.012   26.275    0.000 #>    .x1z2              0.290    0.011   26.910    0.000 #>    .x2z2              0.239    0.008   29.770    0.000 #>    .x3z2              0.270    0.009   29.117    0.000 #>    .x1z3              0.272    0.012   23.586    0.000 #>    .x2z3              0.245    0.009   27.979    0.000 #>    .x3z3              0.297    0.011   28.154    0.000 #>     X                 0.981    0.036   26.895    0.000 #>    .Y                 0.990    0.038   25.926    0.000 #>     Z                 1.016    0.038   26.856    0.000 #>     XZ                1.045    0.044   24.004    0.000 #>   if (FALSE) { # \\dontrun{ # The Constrained Approach est1Constrained <- modsem_pi(m1, oneInt, method = \"ca\") summary(est1Constrained) } # }  # Theory Of Planned Behavior tpb <- ' # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   # Covariances   ATT ~~ SN + PBC   PBC ~~ SN   # Causal Relationships   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ INT:PBC '  # Double centering approach estTpb <- modsem_pi(tpb, data = TPB) summary(estTpb) #> modsem (version 1.0.9, approach = dblcent): #> lavaan 0.6-19 ended normally after 171 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        78 #>  #>   Number of observations                          2000 #>  #> Model Test User Model: #>                                                        #>   Test statistic                               207.615 #>   Degrees of freedom                               222 #>   P-value (Chi-square)                           0.747 #>  #> Parameter Estimates: #>  #>   Standard errors                             Standard #>   Information                                 Expected #>   Information saturated (h1) model          Structured #>  #> Latent Variables: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   ATT =~                                               #>     att1              1.000                            #>     att2              0.878    0.012   71.509    0.000 #>     att3              0.789    0.012   66.368    0.000 #>     att4              0.695    0.011   61.017    0.000 #>     att5              0.887    0.013   70.884    0.000 #>   SN =~                                                #>     sn1               1.000                            #>     sn2               0.889    0.017   52.553    0.000 #>   PBC =~                                               #>     pbc1              1.000                            #>     pbc2              0.912    0.013   69.500    0.000 #>     pbc3              0.801    0.012   65.830    0.000 #>   INT =~                                               #>     int1              1.000                            #>     int2              0.914    0.016   58.982    0.000 #>     int3              0.808    0.015   55.547    0.000 #>   BEH =~                                               #>     b1                1.000                            #>     b2                0.960    0.030   31.561    0.000 #>   INTPBC =~                                            #>     int1pbc1          1.000                            #>     int2pbc1          0.931    0.015   63.809    0.000 #>     int3pbc1          0.774    0.013   60.107    0.000 #>     int1pbc2          0.893    0.013   68.173    0.000 #>     int2pbc2          0.826    0.017   48.845    0.000 #>     int3pbc2          0.690    0.015   45.300    0.000 #>     int1pbc3          0.799    0.012   67.008    0.000 #>     int2pbc3          0.738    0.015   47.809    0.000 #>     int3pbc3          0.622    0.014   45.465    0.000 #>  #> Regressions: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   INT ~                                                #>     ATT               0.213    0.026    8.170    0.000 #>     SN                0.177    0.028    6.416    0.000 #>     PBC               0.217    0.030    7.340    0.000 #>   BEH ~                                                #>     INT               0.191    0.024    7.817    0.000 #>     PBC               0.230    0.022   10.507    0.000 #>     INTPBC            0.204    0.018   11.425    0.000 #>  #> Covariances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>   ATT ~~                                               #>     SN                0.629    0.029   21.977    0.000 #>     PBC               0.678    0.029   23.721    0.000 #>   SN ~~                                                #>     PBC               0.678    0.029   23.338    0.000 #>  .int1pbc1 ~~                                          #>    .int2pbc2          0.000                            #>    .int2pbc3          0.000                            #>    .int3pbc2          0.000                            #>    .int3pbc3          0.000                            #>  .int2pbc1 ~~                                          #>    .int1pbc2          0.000                            #>  .int1pbc2 ~~                                          #>    .int2pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int1pbc2          0.000                            #>  .int1pbc2 ~~                                          #>    .int3pbc3          0.000                            #>  .int2pbc1 ~~                                          #>    .int1pbc3          0.000                            #>  .int2pbc2 ~~                                          #>    .int1pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int1pbc3          0.000                            #>  .int3pbc2 ~~                                          #>    .int1pbc3          0.000                            #>  .int2pbc1 ~~                                          #>    .int3pbc2          0.000                            #>    .int3pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int2pbc2          0.000                            #>  .int2pbc2 ~~                                          #>    .int3pbc3          0.000                            #>  .int3pbc1 ~~                                          #>    .int2pbc3          0.000                            #>  .int3pbc2 ~~                                          #>    .int2pbc3          0.000                            #>  .int1pbc1 ~~                                          #>    .int1pbc2          0.126    0.009   14.768    0.000 #>    .int1pbc3          0.102    0.007   13.794    0.000 #>    .int2pbc1          0.104    0.007   14.608    0.000 #>    .int3pbc1          0.091    0.006   14.109    0.000 #>  .int1pbc2 ~~                                          #>    .int1pbc3          0.095    0.007   13.852    0.000 #>    .int2pbc2          0.128    0.007   19.320    0.000 #>    .int3pbc2          0.119    0.006   19.402    0.000 #>  .int1pbc3 ~~                                          #>    .int2pbc3          0.110    0.006   19.911    0.000 #>    .int3pbc3          0.097    0.005   19.415    0.000 #>  .int2pbc1 ~~                                          #>    .int2pbc2          0.152    0.008   18.665    0.000 #>    .int2pbc3          0.138    0.007   18.779    0.000 #>    .int3pbc1          0.082    0.006   13.951    0.000 #>  .int2pbc2 ~~                                          #>    .int2pbc3          0.121    0.007   18.361    0.000 #>    .int3pbc2          0.104    0.005   19.047    0.000 #>  .int2pbc3 ~~                                          #>    .int3pbc3          0.087    0.005   19.180    0.000 #>  .int3pbc1 ~~                                          #>    .int3pbc2          0.139    0.007   21.210    0.000 #>    .int3pbc3          0.123    0.006   21.059    0.000 #>  .int3pbc2 ~~                                          #>    .int3pbc3          0.114    0.005   21.021    0.000 #>   ATT ~~                                               #>     INTPBC            0.086    0.024    3.519    0.000 #>   SN ~~                                                #>     INTPBC            0.055    0.025    2.230    0.026 #>   PBC ~~                                               #>     INTPBC            0.087    0.024    3.609    0.000 #>  #> Variances: #>                    Estimate  Std.Err  z-value  P(>|z|) #>    .att1              0.167    0.007   23.528    0.000 #>    .att2              0.150    0.006   24.693    0.000 #>    .att3              0.160    0.006   26.378    0.000 #>    .att4              0.163    0.006   27.649    0.000 #>    .att5              0.159    0.006   24.930    0.000 #>    .sn1               0.178    0.015   12.110    0.000 #>    .sn2               0.156    0.012   13.221    0.000 #>    .pbc1              0.145    0.008   18.440    0.000 #>    .pbc2              0.160    0.007   21.547    0.000 #>    .pbc3              0.154    0.007   23.716    0.000 #>    .int1              0.158    0.009   18.152    0.000 #>    .int2              0.160    0.008   20.345    0.000 #>    .int3              0.167    0.007   23.414    0.000 #>    .b1                0.186    0.018   10.058    0.000 #>    .b2                0.135    0.017    8.080    0.000 #>    .int1pbc1          0.266    0.013   20.971    0.000 #>    .int2pbc1          0.292    0.012   24.421    0.000 #>    .int3pbc1          0.251    0.010   26.305    0.000 #>    .int1pbc2          0.290    0.012   24.929    0.000 #>    .int2pbc2          0.269    0.010   26.701    0.000 #>    .int3pbc2          0.253    0.009   29.445    0.000 #>    .int1pbc3          0.223    0.009   24.431    0.000 #>    .int2pbc3          0.234    0.008   27.633    0.000 #>    .int3pbc3          0.203    0.007   29.288    0.000 #>     ATT               0.998    0.037   27.138    0.000 #>     SN                0.987    0.039   25.394    0.000 #>     PBC               0.962    0.035   27.260    0.000 #>    .INT               0.490    0.020   24.638    0.000 #>    .BEH               0.455    0.023   20.068    0.000 #>     INTPBC            1.020    0.041   24.612    0.000 #>   if (FALSE) { # \\dontrun{ # The Constrained Approach estTpbConstrained <- modsem_pi(tpb, data = TPB, method = \"ca\") summary(estTpbConstrained) } # }"},{"path":"/reference/modsem_vcov.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper for vcov — modsem_vcov","title":"Wrapper for vcov — modsem_vcov","text":"wrapper vcov, used modsem::modsem_vcov, since vcov namespace modsem, stats since vcov namespace modsem, stats","code":""},{"path":"/reference/modsem_vcov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper for vcov — modsem_vcov","text":"","code":"modsem_vcov(object, ...)"},{"path":"/reference/modsem_vcov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper for vcov — modsem_vcov","text":"object fittet model inspect ... additional arguments","code":""},{"path":"/reference/modsemify.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate parameter table for lavaan syntax — modsemify","title":"Generate parameter table for lavaan syntax — modsemify","text":"Generate parameter table lavaan syntax","code":""},{"path":"/reference/modsemify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate parameter table for lavaan syntax — modsemify","text":"","code":"modsemify(syntax)"},{"path":"/reference/modsemify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate parameter table for lavaan syntax — modsemify","text":"syntax model syntax","code":""},{"path":"/reference/modsemify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate parameter table for lavaan syntax — modsemify","text":"data.frame columns lhs, op, rhs, mod","code":""},{"path":"/reference/modsemify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate parameter table for lavaan syntax — modsemify","text":"","code":"library(modsem) m1 <- '   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z ' modsemify(m1) #>    lhs op rhs mod #> 1    X =~  x1     #> 2    X =~  x2     #> 3    X =~  x3     #> 4    Y =~  y1     #> 5    Y =~  y2     #> 6    Y =~  y3     #> 7    Z =~  z1     #> 8    Z =~  z2     #> 9    Z =~  z3     #> 10   Y  ~   X     #> 11   Y  ~   Z     #> 12   Y  ~ X:Z"},{"path":"/reference/multiplyIndicatorsCpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiply indicators — multiplyIndicatorsCpp","title":"Multiply indicators — multiplyIndicatorsCpp","text":"Multiply indicators","code":""},{"path":"/reference/multiplyIndicatorsCpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiply indicators — multiplyIndicatorsCpp","text":"","code":"multiplyIndicatorsCpp(df)"},{"path":"/reference/multiplyIndicatorsCpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiply indicators — multiplyIndicatorsCpp","text":"df data DataFrame","code":""},{"path":"/reference/multiplyIndicatorsCpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiply indicators — multiplyIndicatorsCpp","text":"NumericVector","code":""},{"path":"/reference/oneInt.html","id":null,"dir":"Reference","previous_headings":"","what":"oneInt — oneInt","title":"oneInt — oneInt","text":"simulated dataset one interaction effect","code":""},{"path":"/reference/parameter_estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract parameterEstimates from an estimated model — parameter_estimates","title":"Extract parameterEstimates from an estimated model — parameter_estimates","text":"Extract parameterEstimates estimated model","code":""},{"path":"/reference/parameter_estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract parameterEstimates from an estimated model — parameter_estimates","text":"","code":"parameter_estimates(object, ...)"},{"path":"/reference/parameter_estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract parameterEstimates from an estimated model — parameter_estimates","text":"object object class modsem_pi, modsem_da, modsem_mplus ... Additional arguments passed functions","code":""},{"path":"/reference/plot_interaction.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Interaction Effects in a SEM Model — plot_interaction","title":"Plot Interaction Effects in a SEM Model — plot_interaction","text":"function creates interaction plot outcome variable (y) function focal predictor (x) multiple values moderator (z). designed use structural equation modeling (SEM) objects (e.g., modsem). Predicted means (predicted individual values) calculated via simple_slopes, plotted ggplot2 display multiple regression lines confidence/prediction bands.","code":""},{"path":"/reference/plot_interaction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Interaction Effects in a SEM Model — plot_interaction","text":"","code":"plot_interaction(   x,   z,   y,   xz = NULL,   vals_x = seq(-3, 3, 0.001),   vals_z,   model,   alpha_se = 0.15,   digits = 2,   ci_width = 0.95,   ci_type = \"confidence\",   rescale = TRUE,   standardized = FALSE,   ... )"},{"path":"/reference/plot_interaction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Interaction Effects in a SEM Model — plot_interaction","text":"x character string specifying focal predictor (x-axis variable). z character string specifying moderator variable. y character string specifying outcome (dependent) variable. xz character string specifying interaction term (x:z). NULL, term created automatically paste(x, z, sep = \":\"). SEM backends may handle interaction term differently (instance, removing modifying colon), function attempts reconcile internally. vals_x numeric vector values compute plot focal predictor x. default seq(-3, 3, .001), provides relatively fine grid smooth lines. rescale=TRUE, values standardized (mean-centered scaled) units, converted back original metric internal computation predicted means. vals_z numeric vector values moderator z draw separate regression lines. distinct value vals_z defines separate group (plotted different color). rescale=TRUE, values also assumed standardized units. model object class modsem_pi, modsem_da, modsem_mplus, possibly lavaan object. Must fitted SEM model containing paths y ~ x + z + x:z. alpha_se numeric value \\([0, 1]\\) specifying transparency confidence/prediction interval ribbon. Default 0.15. digits integer specifying number decimal places moderator values (z) rounded labeling/grouping plot. ci_width numeric value \\((0,1)\\) indicating coverage confidence (prediction) interval. default 0.95 95% interval. ci_type character string specifying whether compute \"confidence\" intervals (mean predicted values, default) \"prediction\" intervals (include residual variance). rescale Logical. TRUE (default), vals_x vals_z interpreted standardized units, mapped back raw scale computing predictions. FALSE, vals_x vals_z taken raw-scale values directly. standardized coefficients standardized beforehand? ... Additional arguments passed simple_slopes.","code":""},{"path":"/reference/plot_interaction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Interaction Effects in a SEM Model — plot_interaction","text":"ggplot object can customized (e.g.,   additional + theme(...) layers). default, shows lines   moderator value shaded region corresponding interval type   (confidence prediction).","code":""},{"path":"/reference/plot_interaction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Interaction Effects in a SEM Model — plot_interaction","text":"Computation Steps: Calls simple_slopes compute predicted values y         specified grid x z values. Groups resulting predictions unique z-values (rounded         digits) create colored lines. Plots lines using ggplot2, adding ribbons confidence         (prediction) intervals, transparency controlled alpha_se. Interpretation: line plot corresponds regression y x given level z. shaded region around line (ribbon) shows either confidence interval predicted mean (ci_type = \"confidence\") prediction interval individual observations (ci_type = \"prediction\"). ribbons overlap, evidence lines differ significantly range x.","code":""},{"path":"/reference/plot_interaction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Interaction Effects in a SEM Model — plot_interaction","text":"","code":"if (FALSE) { # \\dontrun{ library(modsem)  # Example 1: Interaction of X and Z in a simple SEM m1 <- \" # Outer Model   X =~ x1 + x2 + x3   Z =~ z1 + z2 + z3   Y =~ y1 + y2 + y3  # Inner Model   Y ~ X + Z + X:Z \" est1 <- modsem(m1, data = oneInt)  # Plot interaction using a moderate range of X and two values of Z plot_interaction(x = \"X\", z = \"Z\", y = \"Y\", xz = \"X:Z\",                  vals_x = -3:3, vals_z = c(-0.2, 0), model = est1)  # Example 2: Interaction in a theory-of-planned-behavior-style model tpb <- \" # Outer Model   ATT =~ att1 + att2 + att3 + att4 + att5   SN  =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   BEH ~ PBC:INT \" est2 <- modsem(tpb, data = TPB, method = \"lms\")  # Plot with custom Z values and a denser X grid plot_interaction(x = \"INT\", z = \"PBC\", y = \"BEH\",                  xz = \"PBC:INT\",                  vals_x = seq(-3, 3, 0.01),                  vals_z = c(-0.5, 0.5),                  model = est2) } # }"},{"path":"/reference/plot_jn.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Interaction Effect Using the Johnson-Neyman Technique — plot_jn","title":"Plot Interaction Effect Using the Johnson-Neyman Technique — plot_jn","text":"function plots simple slopes interaction effect across different values moderator variable using Johnson-Neyman technique. identifies regions effect predictor outcome statistically significant.","code":""},{"path":"/reference/plot_jn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Interaction Effect Using the Johnson-Neyman Technique — plot_jn","text":"","code":"plot_jn(   x,   z,   y,   xz = NULL,   model,   min_z = -3,   max_z = 3,   sig.level = 0.05,   alpha = 0.2,   detail = 1000,   sd.line = 2,   standardized = FALSE,   ... )"},{"path":"/reference/plot_jn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Interaction Effect Using the Johnson-Neyman Technique — plot_jn","text":"x name predictor variable (character string). z name moderator variable (character string). y name outcome variable (character string). xz name interaction term. specified, created using x z. model fitted model object class modsem_da, modsem_mplus, modsem_pi, lavaan. min_z minimum value moderator variable z used plot (default -3). relative mean z. max_z maximum value moderator variable z used plot (default 3). relative mean z. sig.level significance level confidence intervals (default 0.05). alpha alpha setting used `ggplot` (.e., opposite opacity) detail number generated data points use plot (default 1000). can increase value smoother plots. sd.line thick black line showing +/- sd.line * sd(z). NOTE: line truncated min_z max_z sd.line falls outside [min_z, max_z]. standardized coefficients standardized beforehand? ... Additional arguments (currently used).","code":""},{"path":"/reference/plot_jn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Interaction Effect Using the Johnson-Neyman Technique — plot_jn","text":"ggplot object showing interaction plot regions significance.","code":""},{"path":"/reference/plot_jn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Interaction Effect Using the Johnson-Neyman Technique — plot_jn","text":"function calculates simple slopes predictor variable x outcome variable y different levels moderator variable z. uses Johnson-Neyman technique identify regions z effect x y statistically significant. extracts necessary coefficients variance-covariance information fitted model object. function computes critical t-value solves quadratic equation derived t-statistic equation find Johnson-Neyman points. plot displays: estimated simple slopes across range z. Confidence intervals around slopes. Regions effect significant (shaded areas). Vertical dashed lines indicating Johnson-Neyman points. Text annotations providing exact values Johnson-Neyman points.","code":""},{"path":"/reference/plot_jn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Interaction Effect Using the Johnson-Neyman Technique — plot_jn","text":"","code":"if (FALSE) { # \\dontrun{ library(modsem)  m1 <-  '    visual  =~ x1 + x2 + x3    textual =~ x4 + x5 + x6   speed   =~ x7 + x8 + x9    visual ~ speed + textual + speed:textual '  est <- modsem(m1, data = lavaan::HolzingerSwineford1939, method = \"ca\") plot_jn(x = \"speed\", z = \"textual\", y = \"visual\", model = est, max_z = 6) } # }"},{"path":"/reference/plot_surface.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Surface for Interaction Effects — plot_surface","title":"Plot Surface for Interaction Effects — plot_surface","text":"Generates 3D surface plot visualize interaction effect two variables (`x` `z`) outcome (`y`) using parameter estimates supported model object (e.g., `lavaan` `modsem`). function allows specifying ranges `x` `z` standardized z-scores, transformed back original scale based means standard deviations.","code":""},{"path":"/reference/plot_surface.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Surface for Interaction Effects — plot_surface","text":"","code":"plot_surface(   x,   z,   y,   xz = NULL,   model,   min_x = -3,   max_x = 3,   min_z = -3,   max_z = 3,   standardized = FALSE,   detail = 0.01,   ... )"},{"path":"/reference/plot_surface.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Surface for Interaction Effects — plot_surface","text":"x character string specifying name first predictor variable. z character string specifying name second predictor variable. y character string specifying name outcome variable. xz Optional. character string vector specifying interaction term `x` `z`. `NULL`, interaction term constructed `paste(x, z, sep = \":\")` adjusted specific model classes. model model object class `'modsem_pi'`, `'modsem_da'`, `'modsem_mplus'`, `'lavaan'`. model include paths predictors (`x`, `z`, `xz`) outcome (`y`). min_x Numeric. Minimum value `x` z-scores. Default -3. max_x Numeric. Maximum value `x` z-scores. Default 3. min_z Numeric. Minimum value `z` z-scores. Default -3. max_z Numeric. Maximum value `z` z-scores. Default 3. standardized coefficients standardized beforehand? detail Numeric. Step size grid `x` `z` values, determining resolution surface. Smaller values increase plot resolution. Default `1e-2`. ... Additional arguments passed `plotly::plot_ly`.","code":""},{"path":"/reference/plot_surface.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Surface for Interaction Effects — plot_surface","text":"`plotly` surface plot object displaying predicted values `y` across grid `x` `z` values.   color bar shows values `y`.","code":""},{"path":"/reference/plot_surface.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Surface for Interaction Effects — plot_surface","text":"input `min_x`, `max_x`, `min_z`, `max_z` define range `x` `z` values z-scores. scaled standard deviations shifted means respective variables, obtained model parameter table. resulting surface shows predicted values `y` grid `x` `z`. function supports models class `modsem` (subclasses `modsem_pi`, `modsem_da`, `modsem_mplus`) `lavaan`. `lavaan` models, designed multigroup models, warning issued multiple groups detected.","code":""},{"path":"/reference/plot_surface.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Plot Surface for Interaction Effects — plot_surface","text":"interaction term (`xz`) may need manually specified models. non-`lavaan` models, interaction terms may separator (`:`) removed based circumstances.","code":""},{"path":"/reference/plot_surface.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Surface for Interaction Effects — plot_surface","text":"","code":"if (FALSE) { # \\dontrun{ m1 <- \" # Outer Model   X =~ x1   X =~ x2 + x3   Z =~ z1 + z2 + z3   Y =~ y1 + y2 + y3  # Inner model   Y ~ X + Z + X:Z \" est1 <- modsem(m1, data = oneInt) plot_surface(\"X\", \"Z\", \"Y\", model = est1)  tpb <- \" # Outer Model (Based on Hagger et al., 2007)   ATT =~ att1 + att2 + att3 + att4 + att5   SN =~ sn1 + sn2   PBC =~ pbc1 + pbc2 + pbc3   INT =~ int1 + int2 + int3   BEH =~ b1 + b2  # Inner Model (Based on Steinmetz et al., 2011)   # Causal Relationsships   INT ~ ATT + SN + PBC   BEH ~ INT + PBC   # BEH ~ ATT:PBC   BEH ~ PBC:INT   # BEH ~ PBC:PBC \"  est2 <- modsem(tpb, TPB, method = \"lms\") plot_surface(x = \"INT\", z = \"PBC\", y = \"BEH\", model = est1) } # }"},{"path":"/reference/simple_slopes.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the simple slopes of a SEM model — simple_slopes","title":"Get the simple slopes of a SEM model — simple_slopes","text":"function calculates simple slopes (predicted values outcome variable) user-specified values focal predictor (x) moderator (z) structural equation modeling (SEM) framework. supports interaction terms (xz), computes standard errors (SE), optionally returns confidence prediction intervals predicted values. also provides p-values hypothesis testing. useful visualizing interpreting moderation effects see slope changes different values moderator.","code":""},{"path":"/reference/simple_slopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the simple slopes of a SEM model — simple_slopes","text":"","code":"simple_slopes(   x,   z,   y,   xz = NULL,   model,   vals_x = -3:3,   vals_z = -1:1,   rescale = TRUE,   ci_width = 0.95,   ci_type = \"confidence\",   relative_h0 = TRUE,   standardized = FALSE,   ... )"},{"path":"/reference/simple_slopes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the simple slopes of a SEM model — simple_slopes","text":"x name variable x-axis (focal predictor). z name moderator variable. y name outcome variable. xz name interaction term (x:z). NULL, created combining x z colon (e.g., \"x:z\"). backends may remove alter colon symbol, function tries account internally. model object class modsem_pi, modsem_da, modsem_mplus, lavaan object. fitted SEM model includes paths y ~ x + z + x:z. vals_x Numeric vector values x compute predicted slopes. Defaults -3:3. rescale = TRUE, values taken relative mean standard deviation x. higher density points (e.g., seq(-3, 3, 0.1)) produce smoother curves confidence bands. vals_z Numeric vector values moderator z compute predicted slopes. Defaults -1:1. rescale = TRUE, values taken relative mean standard deviation z. unique value z generates separate regression line y ~ x | z. rescale Logical. TRUE (default), x z standardized according means standard deviations model. values vals_x vals_z interpreted standardized units. raw (unscaled) values corresponding standardized points displayed returned table. ci_width numeric value 0 1 indicating confidence (prediction) interval width. default 0.95 (.e., 95% interval). ci_type string indicating whether compute \"confidence\" interval predicted mean (.e., uncertainty regression line) \"prediction\" interval individual outcomes. default \"confidence\". \"prediction\", residual variance added variance fitted mean, resulting wider interval. relative_h0 Logical. TRUE (default), hypothesis tests predicted values (predicted - h0) assume h0 model-estimated mean y. FALSE, null hypothesis h0 = 0. standardized coefficients standardized beforehand? ... Additional arguments passed lower-level functions internal helpers.","code":""},{"path":"/reference/simple_slopes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the simple slopes of a SEM model — simple_slopes","text":"data.frame (invisibly inheriting class \"simple_slopes\") columns: vals_x, vals_z: requested grid values x z. predicted: predicted value y combination         x z. std.error: standard error predicted value. z.value, p.value: z-statistic corresponding p-value         testing null hypothesis predicted == h0. ci.lower, ci.upper: Lower upper bounds confidence         (prediction) interval. attribute \"variable_names\" (list x, z, y) attached convenience.","code":""},{"path":"/reference/simple_slopes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the simple slopes of a SEM model — simple_slopes","text":"Computation Steps 1. function extracts parameter estimates (, necessary, covariance    matrix) fitted SEM model (model). 2. identifies coefficients x, z, x:z model's    parameter table, well variance x, z, residual. 3. xz provided, constructed combining x    z colon (\":\"). certain SEM software, colon may    removed replaced internally; function attempts reconcile . 4. grid x z values created vals_x    vals_z. rescale = TRUE, values transformed back raw    metric units display output. 5. point grid, predicted value y computed via    (beta0 + beta_x * x + beta_z * z + beta_xz * x * z) , included,    mean offset. 6. standard error (std.error) derived covariance matrix    relevant parameters, ci_type = \"prediction\", adds residual    variance. 7. Confidence (prediction) intervals formed using ci_width (defaulting    95%). result table-like data frame predicted values, CIs,    standard errors, z-values, p-values.","code":""},{"path":"/reference/simple_slopes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the simple slopes of a SEM model — simple_slopes","text":"","code":"if (FALSE) { # \\dontrun{ library(modsem)  m1 <- \" # Outer Model   X =~ x1 + x2 + x3   Z =~ z1 + z2 + z3   Y =~ y1 + y2 + y3  # Inner model   Y ~ X + Z + X:Z \" est1 <- modsem(m1, data = oneInt)  # Simple slopes at X in [-3, 3] and Z in [-1, 1], rescaled to the raw metric. simple_slopes(x = \"X\", z = \"Z\", y = \"Y\", model = est1)  # If the data or user wants unscaled values, set rescale = FALSE, etc. simple_slopes(x = \"X\", z = \"Z\", y = \"Y\", model = est1, rescale = FALSE) } # }"},{"path":"/reference/standardize_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardize a fitted modsem_da model — standardize_model","title":"Standardize a fitted modsem_da model — standardize_model","text":"standardize_model() post-processes output modsem_da() (modsem()) method = \"lms\" / method = \"qml\"), replacing unstandardized coefficient vector ($coefs) variance–covariance matrix ($vcov) fully standardized counterparts (including measurement model).procedure purely algebraic— re-estimation carried —therefore fast deterministic.","code":""},{"path":"/reference/standardize_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardize a fitted modsem_da model — standardize_model","text":"","code":"standardize_model(model, monte.carlo = FALSE, mc.reps = 10000, ...)"},{"path":"/reference/standardize_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardize a fitted modsem_da model — standardize_model","text":"model fitted object class modsem_da. Passing object triggers error. monte.carlo Logical. TRUE, function use Monte Carlo simulation obtain standard errors standardized estimates. FALSE, delta method used. Default FALSE. mc.reps Number Monte Carlo replications. Default 10,000. Ignored monte.carlo = FALSE. ... Arguments passed functions","code":""},{"path":"/reference/standardize_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardize a fitted modsem_da model — standardize_model","text":"object (returned invisibly) three slots overwritten $parTable Parameter table whose columns est std.error         now hold standardized estimates (delta-method)         standard errors, produced standardized_estimates(). $coefs Named numeric vector standardized coefficients.         Intercepts (operator ~1) removed, standardized         variable mean 0 definition. $vcov Variance–covariance matrix corresponding updated         coefficient vector.  Rows/columns intercepts dropped,         sub-matrix associated rescaled parameters adjusted         diagonal equals squared standardized standard errors. object keeps class attributes, allowing seamless use downstream S3 methods summary(), coef(), vcov(). function merely transforms existing estimates, parameter constraints imposed shared labels remain satisfied.","code":""},{"path":[]},{"path":"/reference/standardize_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardize a fitted modsem_da model — standardize_model","text":"","code":"if (FALSE) { # \\dontrun{ # Latent interaction estimated with LMS and standardized afterwards syntax <- \"   X =~ x1 + x2 + x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3   Y ~ X + Z + X:Z \" fit  <- modsem_da(syntax, data = oneInt, method = \"lms\") sfit <- standardize_model(fit, monte.carlo = TRUE)  # Compare unstandardized vs. standardized summaries summary(fit)  # unstandardized summary(sfit) # standardized  } # }"},{"path":"/reference/standardized_estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Get standardized estimates — standardized_estimates","title":"Get standardized estimates — standardized_estimates","text":"Get standardized estimates","code":""},{"path":"/reference/standardized_estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get standardized estimates — standardized_estimates","text":"","code":"standardized_estimates(object, ...)"},{"path":"/reference/standardized_estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get standardized estimates — standardized_estimates","text":"object object class modsem_da, modsem_mplus, parTable class data.frame ... Additional arguments passed functions","code":""},{"path":"/reference/standardized_estimates.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get standardized estimates — standardized_estimates","text":"modsem_da, modsem_mplus objects, interaction term standardized var(xz) = 1. interaction term actual variable model, meaning variance. must therefore calculated parameters model. Assuming normality zero-means, variance calculated var(xz) = var(x) * var(z) + cov(x, z)^2. Thus setting variance interaction term 1 'correct' correlation x z zero. means standardized estimates interaction term different using lavaan, since interaction term actual latent variable model, standardized variance 1.","code":""},{"path":"/reference/standardized_estimates.modsem_da.html","id":null,"dir":"Reference","previous_headings":"","what":"Get standardized estimates with Monte Carlo bootstrapped standard errors — standardized_estimates.modsem_da","title":"Get standardized estimates with Monte Carlo bootstrapped standard errors — standardized_estimates.modsem_da","text":"Get standardized estimates Monte Carlo bootstrapped standard errors","code":""},{"path":"/reference/standardized_estimates.modsem_da.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get standardized estimates with Monte Carlo bootstrapped standard errors — standardized_estimates.modsem_da","text":"","code":"# S3 method for class 'modsem_da' standardized_estimates(   object,   monte.carlo = FALSE,   mc.reps = 10000,   tolerance.zero = 1e-10,   ... )"},{"path":"/reference/standardized_estimates.modsem_da.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get standardized estimates with Monte Carlo bootstrapped standard errors — standardized_estimates.modsem_da","text":"object object class modsem_da monte.carlo standard errors calculated using Monte Carlo simulation. FALSE delta method used instead. Default FALSE. mc.reps Number Monte Carlo repetitions tolerance.zero Tolerance zero values. Standard errors smaller value set NA. ... Additional arguments passed functions","code":""},{"path":"/reference/standardized_estimates.modsem_da.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get standardized estimates with Monte Carlo bootstrapped standard errors — standardized_estimates.modsem_da","text":"interaction term standardized var(xz) = 1. interaction term actual variable model, meaning variance. must therefore calculated parameters model. Assuming normality zero-means, variance calculated var(xz) = var(x) * var(z) + cov(x, z)^2. Thus setting variance interaction term 1 'correct' correlation x z zero. means standardized estimates interaction term different using lavaan, since interaction term actual latent variable model, standardized variance 1.","code":""},{"path":"/reference/standardized_estimates_mc.html","id":null,"dir":"Reference","previous_headings":"","what":"Get standardized estimates with Monte Carlo bootstrapped standard errors — standardized_estimates_mc","title":"Get standardized estimates with Monte Carlo bootstrapped standard errors — standardized_estimates_mc","text":"Get standardized estimates Monte Carlo bootstrapped standard errors","code":""},{"path":"/reference/standardized_estimates_mc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get standardized estimates with Monte Carlo bootstrapped standard errors — standardized_estimates_mc","text":"","code":"standardized_estimates_mc(object, mc.reps = 10000, tolerance.zero = 1e-12, ...)"},{"path":"/reference/standardized_estimates_mc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get standardized estimates with Monte Carlo bootstrapped standard errors — standardized_estimates_mc","text":"object object class modsem_da mc.reps Number Monte Carlo repetitions tolerance.zero Tolerance zero values. Standard errors smaller value set NA. ... Additional arguments passed functions","code":""},{"path":"/reference/standardized_estimates_mc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get standardized estimates with Monte Carlo bootstrapped standard errors — standardized_estimates_mc","text":"interaction term standardized var(xz) = 1. interaction term actual variable model, meaning variance. must therefore calculated parameters model. Assuming normality zero-means, variance calculated var(xz) = var(x) * var(z) + cov(x, z)^2. Thus setting variance interaction term 1 'correct' correlation x z zero. means standardized estimates interaction term different using lavaan, since interaction term actual latent variable model, standardized variance 1.","code":""},{"path":"/reference/summary.html","id":null,"dir":"Reference","previous_headings":"","what":"summary for modsem objects — summary.modsem_da","title":"summary for modsem objects — summary.modsem_da","text":"summary modsem objects summary modsem objects summary modsem objects","code":""},{"path":"/reference/summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summary for modsem objects — summary.modsem_da","text":"","code":"# S3 method for class 'modsem_da' summary(   object,   H0 = TRUE,   verbose = interactive(),   r.squared = TRUE,   adjusted.stat = FALSE,   digits = 3,   scientific = FALSE,   ci = FALSE,   standardized = FALSE,   monte.carlo = FALSE,   mc.reps = 10000,   loadings = TRUE,   regressions = TRUE,   covariances = TRUE,   intercepts = !standardized,   variances = TRUE,   var.interaction = FALSE,   ... )  # S3 method for class 'modsem_mplus' summary(   object,   scientific = FALSE,   standardize = FALSE,   ci = FALSE,   digits = 3,   loadings = TRUE,   regressions = TRUE,   covariances = TRUE,   intercepts = TRUE,   variances = TRUE,   ... )  # S3 method for class 'modsem_pi' summary(object, ...)"},{"path":"/reference/summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summary for modsem objects — summary.modsem_da","text":"object modsem object summarized H0 null model estimated (used comparison) verbose print progress estimation null model r.squared calculate R-squared adjusted.stat sample size corrected/adjustes AIC BIC reported? digits number digits print scientific print p-values scientific notation ci print confidence intervals standardized print standardized estimates monte.carlo Monte Carlo bootstrapped standard errors used? relevant standardized = TRUE. FALSE delta method used instead. mc.reps number Monte Carlo repetitions. relevant monte.carlo = TRUE, standardized = TRUE. loadings print loadings regressions print regressions covariances print covariances intercepts print intercepts variances print variances var.interaction FALSE (default) variances interaction terms removed (present) ... arguments passed lavaan::summary() standardize standardize estimates","code":""},{"path":"/reference/summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"summary for modsem objects — summary.modsem_da","text":"","code":"if (FALSE) { # \\dontrun{ m1 <- \"  # Outer Model  X =~ x1 + x2 + x3  Y =~ y1 + y2 + y3  Z =~ z1 + z2 + z3   # Inner model  Y ~ X + Z + X:Z \"  est1 <- modsem(m1, oneInt, \"qml\") summary(est1, ci = TRUE, scientific = TRUE) } # }"},{"path":"/reference/trace_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate formulas for (co-)variance paths using Wright's path tracing rules — trace_path","title":"Estimate formulas for (co-)variance paths using Wright's path tracing rules — trace_path","text":"function estimates path x y using path tracing rules. Note works structural parameters, \"=~\" ignored, unless measurement.model = TRUE. want use measurement model, \"~\" mod column pt.","code":""},{"path":"/reference/trace_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate formulas for (co-)variance paths using Wright's path tracing rules — trace_path","text":"","code":"trace_path(   pt,   x,   y,   parenthesis = TRUE,   missing.cov = FALSE,   measurement.model = FALSE,   maxlen = 100,   paramCol = \"mod\",   ... )"},{"path":"/reference/trace_path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate formulas for (co-)variance paths using Wright's path tracing rules — trace_path","text":"pt data frame columns lhs, op, rhs, mod, modsemify x Source variable y Destination variable parenthesis TRUE, output enclosed parenthesis missing.cov TRUE, covariances missing model syntax added measurement.model TRUE, function use measurement model maxlen Maximum length path aborting paramCol column name pt contains parameter labels ... Additional arguments passed trace_path","code":""},{"path":"/reference/trace_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate formulas for (co-)variance paths using Wright's path tracing rules — trace_path","text":"string estimated path (simplified possible)","code":""},{"path":"/reference/trace_path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate formulas for (co-)variance paths using Wright's path tracing rules — trace_path","text":"","code":"library(modsem) m1 <- '   # Outer Model   X =~ x1 + x2 +x3   Y =~ y1 + y2 + y3   Z =~ z1 + z2 + z3    # Inner model   Y ~ X + Z + X:Z ' pt <- modsemify(m1) trace_path(pt, x = \"Y\", y = \"Y\", missing.cov = TRUE) # variance of Y #> [1] \"(X~~X * Y~X ^ 2 + 2 * X~~Z * Y~X * Y~Z + Y~Z ^ 2 * Z~~Z + Y~~Y)\""},{"path":"/reference/var_interactions.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract or modify parTable from an estimated model with estimated variances of interaction terms — var_interactions","title":"Extract or modify parTable from an estimated model with estimated variances of interaction terms — var_interactions","text":"Extract modify parTable estimated model estimated variances interaction terms","code":""},{"path":"/reference/var_interactions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract or modify parTable from an estimated model with estimated variances of interaction terms — var_interactions","text":"","code":"var_interactions(object, ...)"},{"path":"/reference/var_interactions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract or modify parTable from an estimated model with estimated variances of interaction terms — var_interactions","text":"object object class modsem_da,  modsem_mplus, parTable class data.frame ... Additional arguments passed functions","code":""},{"path":"/reference/vcov_modsem_da.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper for vcov — vcov_modsem_da","title":"Wrapper for vcov — vcov_modsem_da","text":"wrapper vcov, used modsem::vcov_modsem_da, since vcov namespace modsem, stats","code":""},{"path":"/reference/vcov_modsem_da.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper for vcov — vcov_modsem_da","text":"","code":"vcov_modsem_da(object, ...)"},{"path":"/reference/vcov_modsem_da.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper for vcov — vcov_modsem_da","text":"object fittet model inspect ... additional arguments","code":""}]
